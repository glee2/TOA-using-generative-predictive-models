{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/'\n",
    "master_dir = '/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer, Predictor\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict, to_device\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "analysis_date = \"2023-05-09_0331\"\n",
    "args = argparse.Namespace(\n",
    "#     data_type=\"class+claim\",\n",
    "#     data_file=None,\n",
    "#     target_ipc=None,\n",
    "#     pred_type=\"classification\",\n",
    "#     n_TC = 5,\n",
    "#     use_pretrained_tokenizer=False,\n",
    "#     do_train=None,\n",
    "    do_eval = True,\n",
    "#     do_tune=None,\n",
    "#     n_folds=None,\n",
    "#     batch_size=512,\n",
    "#     max_epochs=20,\n",
    "#     use_accelerator=None,\n",
    "    do_save=False,\n",
    "#     n_gpus=4,\n",
    "#     light=True,\n",
    "    config_file=os.path.join(root_dir, \"configs\", \"USED_configs\", \"[CONFIGS]\"+analysis_date+\".json\"),\n",
    "#     config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "project_data_dir = os.path.join(master_dir, \"data\")\n",
    "data_dir = os.path.join(\"/home2/glee/patent_data/data/\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "## parse configuration file\n",
    "# args = parser.parse_args()\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "if args.do_eval: args.do_train = False\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "# parse command line arguments\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "## assign loss weights\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "## assign devices\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "## extract configurations for dataset\n",
    "config_period = \"[\"+\"-\".join([str(year) for year in configs.data.target_period])+\"]\"\n",
    "config_ipcs = str(configs.data.target_ipc).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "config_keywords = str(configs.data.target_keywords).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "\n",
    "## update configurations\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir,\n",
    "                        \"pretrained_enc\": configs.model.pretrained_enc,\n",
    "                        \"pretrained_dec\": configs.model.pretrained_dec,\n",
    "                        \"data_nrows\": None,\n",
    "                        \"data_file\": \"collection_\" + \"\".join([config_keywords, config_ipcs, config_period]) + \".csv\"})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_enc_hidden = configs.model.d_enc_hidden = None\n",
    "    d_pred_hidden = configs.model.d_pred_hidden = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_enc_hidden = configs.model.d_enc_hidden\n",
    "    d_pred_hidden = configs.model.d_pred_hidden\n",
    "    d_latent = configs.model.d_latent\n",
    "\n",
    "    ## set filename for model\n",
    "    key_components = {\"data\": [\"ipc_level\", \"max_seq_len_class\", \"max_seq_len_claim\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_hidden\", \"d_pred_hidden\", \"d_latent\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    model_config_name = \"\".join([config_keywords, config_ipcs, config_period]) + \"data\"\n",
    "    for key in [\"model\", \"train\"]:\n",
    "        for component in key_components[key]:\n",
    "            model_config_name += f\"[{str(configs[key][component])}]{component}\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[MODEL]{model_config_name}.ckpt\")\n",
    "\n",
    "configs.train.update({\"model_config_name\": model_config_name, \"final_model_path\": final_model_path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' PART 2: Dataset setting '''\n",
    "tstart = time.time()\n",
    "dataset_config_name = \"\".join([config_keywords, config_ipcs, config_period]) + \"data\"\n",
    "for component in key_components[\"data\"]:\n",
    "    dataset_config_name += f\"[{str(configs.data[component])}]{component}\"\n",
    "dataset_path = os.path.join(project_data_dir, \"pickled_dataset\", \"[DATASET]\"+dataset_config_name+\".pickle\")\n",
    "\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "        if tech_dataset.pretrained_enc != configs.data.pretrained_enc or tech_dataset.pretrained_dec != configs.data.pretrained_dec:\n",
    "            tech_dataset.pretrained_enc = configs.data.pretrained_enc\n",
    "            tech_dataset.pretrained_dec = configs.data.pretrained_dec\n",
    "            tech_dataset.tokenizers = tech_dataset.get_tokenizers()\n",
    "        for tk in tech_dataset.tokenizers.values():\n",
    "            if \"vocab_size\" not in dir(tk):\n",
    "                tk.vocab_size = tk.get_vocab_size()\n",
    "        tech_dataset.use_keywords = configs.data.use_keywords\n",
    "        ## load saved rawdata\n",
    "        if tech_dataset.rawdata is None:\n",
    "            tech_dataset.rawdata = pd.read_csv(os.path.join(data_dir, configs.data.data_file), low_memory=False)\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    if args.debug:\n",
    "        configs.data.update({\"data_nrows\": 1000})\n",
    "        dataset_path += \".debug\"\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    if not args.debug:\n",
    "        rawdata_for_save = copy.deepcopy(tech_dataset.rawdata)\n",
    "        with open(dataset_path, \"wb\") as f:\n",
    "            tech_dataset.rawdata = None\n",
    "            pickle.dump(tech_dataset, f)\n",
    "        tech_dataset.rawdata = rawdata_for_save\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")\n",
    "\n",
    "configs.model.update({\"tokenizers\": tech_dataset.tokenizers,\n",
    "                    \"n_enc_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_dec_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_enc_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_dec_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                    \"i_padding\": tech_dataset.tokenizers[\"class_enc\"].pad_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = build_model(configs.model, tokenizers=tech_dataset.tokenizers)\n",
    "if os.path.exists(final_model_path):\n",
    "    best_states = torch.load(final_model_path)\n",
    "else:\n",
    "    raise Exception(\"Model need to be trained first\")\n",
    "converted_states = OrderedDict()\n",
    "for k, v in best_states.items():\n",
    "    if 'module' not in k:\n",
    "        k = 'module.'+k\n",
    "    else:\n",
    "        k = k.replace('features.module.', 'module.features.')\n",
    "    converted_states[k] = v\n",
    "final_model.load_state_dict(converted_states)\n",
    "\n",
    "del best_states\n",
    "del converted_states\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Model successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(root_dir, \"results\")\n",
    "\n",
    "used_train_data = pd.read_excel(os.path.join(result_path, \"[DATASET]\"+analysis_date+\".xlsx\"), sheet_name=\"TRAIN_dataset\")\n",
    "used_test_data = pd.read_excel(os.path.join(result_path, \"[DATASET]\"+analysis_date+\".xlsx\"), sheet_name=\"TEST_dataset\")\n",
    "used_train_index = tech_dataset.data.index.get_indexer(pd.Index(used_train_data[\"number\"]))\n",
    "used_test_index = tech_dataset.data.index.get_indexer(pd.Index(used_test_data[\"number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_train_dataset = Subset(tech_dataset, used_train_index)\n",
    "train_loader = DataLoader(used_train_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zs, ys, preds = [], [], []\n",
    "newzs = []\n",
    "for batch_data in tqdm(train_loader):\n",
    "    batch_data = to_device(batch_data, final_model.module.device)\n",
    "    y = batch_data[\"targets\"].cpu().detach().numpy()\n",
    "    \n",
    "    enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "    pred_outputs = final_model.module.predictor(z)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    zs.append(z.cpu().detach().numpy())\n",
    "    ys.append(y)\n",
    "    preds.append(pred_outputs.argmax(1).cpu().detach().numpy())\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "                                                \n",
    "zs = np.concatenate(zs)\n",
    "ys = np.concatenate(ys)\n",
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "col_years = [\"<1976\"] + np.arange(1976,2023).astype(str).tolist()\n",
    "latest_year = datetime.datetime.now().year - 1\n",
    "n_TC = configs.data.n_TC\n",
    "\n",
    "visualize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_config_period = \"[2012-2017]\"\n",
    "ref_data_file = \"collection_\" + \"\".join([config_keywords, config_ipcs, ref_config_period]) + \".csv\"\n",
    "ref_configs = copy.deepcopy(configs)\n",
    "ref_configs.data.update({\"target_period\": ref_config_period, \"data_file\": ref_data_file})\n",
    "ref_dataset = TechDataset(ref_configs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_rawdata = tech_dataset.rawdata.set_index(\"number\")\n",
    "total_data = pd.concat([tech_dataset.data, ref_dataset.data], axis=0)\n",
    "total_rawdata = pd.concat([tech_dataset.rawdata.set_index(\"number\"), ref_dataset.rawdata.set_index(\"number\")], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parts of the collected patent database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_index = pd.Index([\"7987362\", \"7613164\", \"7266663\", \"7266666\", \"8327354\", \"7769767\"])\n",
    "sample_index = pd.Index([\"7523443\", \"7965656\", \"8335889\", \"7324446\", \"8020096\", \"7860895\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.concat([tech_dataset.data.loc[sample_index], tech_dataset.rawdata.set_index(\"number\").loc[sample_index][[\"forward_refs\", \"granted_year\", \"application_year_forward_refs\"]]], axis=1)[[\"claims\", \"ipcs\", \"forward_refs\", \"TC5\", \"granted_year\", \"application_year_forward_refs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TC5는 application이 아니라 granted year 기준!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tech_dataset.data[\"TC5\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "used_test_data[\"TC5\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_criterion = tech_dataset.data[\"TC5\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_test_data_TC = used_test_data[(used_test_data[\"TC5\"]>0) & (used_test_data[\"TC5\"]<L1_criterion)].reset_index()\n",
    "used_test_data_TC = used_test_data[used_test_data[\"TC5\"]!=0].reset_index()\n",
    "used_test_index_TC = tech_dataset.data.index.get_indexer(pd.Index(used_test_data_TC[\"number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "used_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index_techdataset = tech_dataset.data.index.get_indexer(sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index_techdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False\n",
    "\n",
    "sample_latent_vectors = []\n",
    "for idx in sample_index_techdataset:\n",
    "    input_class = torch.tensor(tech_dataset.tokenizers[\"class_enc\"].encode(tech_dataset.X_class[idx])).unsqueeze(0)\n",
    "    input_claim = tech_dataset.tokenize(tech_dataset.tokenizers[\"claim_enc\"], tech_dataset.X_claim[idx])\n",
    "    input_claim = {k: v.unsqueeze(0) for k, v in input_claim.items()}\n",
    "    batch_input = {\"class\": torch.tensor(input_class), \"claim\": input_claim}\n",
    "    input_inf = to_device(batch_input, final_model.module.device)\n",
    "\n",
    "    output_class = torch.tensor(tech_dataset.tokenizers[\"class_dec\"].encode(tech_dataset.X_class[idx])).unsqueeze(0)\n",
    "    batch_output = {\"text_outputs\": torch.tensor(output_class)}\n",
    "    output_inf = to_device(batch_output, final_model.module.device)\n",
    "\n",
    "    near_mean_idx = np.argsort(np.sum(abs(zs - np.mean(zs, axis=0)), axis=1))[:2500]\n",
    "    near_mean_idx_ = np.union1d(near_mean_idx, np.random.choice(np.where(ys==1)[0], 50))\n",
    "    enc_outputs, z, mu, logvar = final_model.module.encode(input_inf)\n",
    "    org_z = copy.deepcopy(z.view(1,-1).cpu().detach().numpy())\n",
    "    pred_outputs = final_model.module.predict(z)\n",
    "    org_y = copy.deepcopy(pred_outputs.argmax(1).cpu().detach().numpy())\n",
    "    \n",
    "    sample_latent_vectors.append(np.round(z[0].cpu().detach().numpy()[[0,1,2,-3,-2,-1]], 4))\n",
    "\n",
    "    if visualize:\n",
    "        zs_for_tsne = np.concatenate([zs[near_mean_idx_], org_z])\n",
    "        ys_for_tsne = np.concatenate([ys[near_mean_idx_], org_y])\n",
    "        tsne = TSNE(early_exaggeration=10, learning_rate=\"auto\", n_iter=500, init=\"random\", verbose=0, metric=\"cosine\", square_distances=True)\n",
    "        z_tsne = tsne.fit_transform(zs_for_tsne)\n",
    "        plt.scatter(z_tsne[:-1,0], z_tsne[:-1,1], c=ys_for_tsne[:-1], cmap=\"bwr\")\n",
    "        plt.scatter(z_tsne[-1,0], z_tsne[-1,1], c=\"k\", marker=\"X\")\n",
    "        plt.text(z_tsne[-1,0]+0.5, z_tsne[-1,1]+0.5, \"origin\", weight=\"bold\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sample_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sample_data[\"ipcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([sample_data[\"ipcs\"], pd.Series(sample_latent_vectors, index=sample_index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown(ipcs):\n",
    "    return ([ipc[0] for ipc in ipcs], [ipc[:3] for ipc in ipcs], [ipc[:4] for ipc in ipcs], ipcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tech_identify(idx=None):\n",
    "    input_class = torch.tensor(tech_dataset.tokenizers[\"class_enc\"].encode(tech_dataset.X_class[idx])).unsqueeze(0)\n",
    "    input_claim = tech_dataset.tokenize(tech_dataset.tokenizers[\"claim_enc\"], tech_dataset.X_claim[idx])\n",
    "    input_claim = {k: v.unsqueeze(0) for k, v in input_claim.items()}\n",
    "    batch_input = {\"class\": torch.tensor(input_class), \"claim\": input_claim}\n",
    "    input_inf = to_device(batch_input, final_model.module.device)\n",
    "\n",
    "    output_class = torch.tensor(tech_dataset.tokenizers[\"class_dec\"].encode(tech_dataset.X_class[idx])).unsqueeze(0)\n",
    "    batch_output = {\"text_outputs\": torch.tensor(output_class)}\n",
    "    output_inf = to_device(batch_output, final_model.module.device)\n",
    "\n",
    "    near_mean_idx = np.argsort(np.sum(abs(zs - np.mean(zs, axis=0)), axis=1))[:2500]\n",
    "    near_mean_idx_ = np.union1d(near_mean_idx, np.random.choice(np.where(ys==1)[0], 50))\n",
    "    enc_outputs, z, mu, logvar = final_model.module.encode(input_inf)\n",
    "    org_z = copy.deepcopy(z.view(1,-1).cpu().detach().numpy())\n",
    "    pred_outputs = final_model.module.predict(z)\n",
    "    org_y = copy.deepcopy(pred_outputs.argmax(1).cpu().detach().numpy())\n",
    "    dec_inputs = None\n",
    "\n",
    "    tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "\n",
    "    org_text = tokenizer.decode_batch(input_class.cpu().detach().numpy())[0]\n",
    "    org_text = org_text[org_text.index(tokenizer.sos_token)+1:org_text.index(tokenizer.eos_token)]\n",
    "\n",
    "    n_iter = 30\n",
    "    step_size = 40\n",
    "\n",
    "    optimised = False\n",
    "    for i in range(n_iter):\n",
    "        pred_outputs = final_model.module.predict(z)\n",
    "        z.retain_grad()\n",
    "        FC_estimated = np.round(np.exp(pred_outputs[0,1].item()), 4) # estimated forward citations\n",
    "        FC_estimated_inv = np.round(np.exp(pred_outputs[0,0].item()), 4)\n",
    "\n",
    "        L1_error = (1-torch.exp(pred_outputs[0,1]))\n",
    "        L1_error.backward(retain_graph=True)\n",
    "\n",
    "        grad_for_update = (step_size * z.grad)\n",
    "        z_ = z - grad_for_update\n",
    "\n",
    "        z.grad.zero_()\n",
    "        dec_outputs = final_model.module.decode(z_, enc_outputs, dec_inputs=None)\n",
    "        dec_outputs = dec_outputs.argmax(-1)\n",
    "\n",
    "        tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "        gen_text = tokenizer.decode_batch(dec_outputs.cpu().detach().numpy())[0]\n",
    "        if tokenizer.eos_token in gen_text:\n",
    "            gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:gen_text.index(tokenizer.eos_token)]\n",
    "        else:\n",
    "            gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:]\n",
    "        if gen_text != []:\n",
    "            gen_text = [gen_text[0]] + list(np.array(gen_text[1:])[np.unique(gen_text[1:], return_index=True)[1]])                \n",
    "            gen_text = set(gen_text)\n",
    "        else: continue\n",
    "\n",
    "        print(f\"<< Iteration {i+1} >>\")\n",
    "        print(f\"Estimated prob. for L1 (L2): {FC_estimated} ({FC_estimated_inv})\")\n",
    "        print(\"Original class:\\n\",set(org_text),\"\\nGenerated class:\\n\", gen_text)                    \n",
    "\n",
    "        if FC_estimated>=0.6:\n",
    "            return\n",
    "        else:\n",
    "            z = z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tech_dataset.X_class[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_dataset.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in sample_index_techdataset:\n",
    "    print()\n",
    "    tech_identify(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_reliability(idx=None):\n",
    "    cnt_nonexist = 0\n",
    "    cnt_noFC = 0\n",
    "    cnt_diverge = 0\n",
    "    cnt_same_ipcs = 0\n",
    "    \n",
    "    input_class = torch.tensor(tech_dataset.tokenizers[\"class_enc\"].encode(tech_dataset.X_class[used_test_index_TC][idx])).unsqueeze(0)\n",
    "    input_claim = tech_dataset.tokenize(tech_dataset.tokenizers[\"claim_enc\"], tech_dataset.X_claim[used_test_index_TC][idx])\n",
    "    input_claim = {k: v.unsqueeze(0) for k, v in input_claim.items()}\n",
    "    batch_input = {\"class\": torch.tensor(input_class), \"claim\": input_claim}\n",
    "    input_inf = to_device(batch_input, final_model.module.device)\n",
    "\n",
    "    output_class = torch.tensor(tech_dataset.tokenizers[\"class_dec\"].encode(tech_dataset.X_class[used_test_index_TC][idx])).unsqueeze(0)\n",
    "    batch_output = {\"text_outputs\": torch.tensor(output_class)}\n",
    "    output_inf = to_device(batch_output, final_model.module.device)\n",
    "\n",
    "    near_mean_idx = np.argsort(np.sum(abs(zs - np.mean(zs, axis=0)), axis=1))[:2500]\n",
    "    near_mean_idx_ = np.union1d(near_mean_idx, np.random.choice(np.where(ys==1)[0], 50))\n",
    "    enc_outputs, z, mu, logvar = final_model.module.encode(input_inf)\n",
    "    org_z = copy.deepcopy(z.view(1,-1).cpu().detach().numpy())\n",
    "    pred_outputs = final_model.module.predict(z)\n",
    "    org_y = copy.deepcopy(pred_outputs.argmax(1).cpu().detach().numpy())\n",
    "    dec_inputs = None\n",
    "\n",
    "    if used_test_data_TC.iloc[idx][\"TC5\"] > 0:\n",
    "        forward_refs = used_rawdata.loc[used_test_data_TC.iloc[idx][\"number\"]][\"forward_refs\"].split(\";\")\n",
    "        ref_info = total_data.loc[[ref for ref in forward_refs if ref in total_data.index]]\n",
    "        if len(ref_info) == 0:\n",
    "#             print(\"Dataset does not have information about citing patents\")\n",
    "            cnt_nonexist += 1\n",
    "            return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs), None\n",
    "        else:\n",
    "            ref_ipcs = ref_info[\"ipcs\"].apply(lambda x: set(x))\n",
    "            ref_FCs = ref_info[\"TC\"+str(n_TC)]\n",
    "\n",
    "            tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "            \n",
    "            org_text = tokenizer.decode_batch(input_class.cpu().detach().numpy())[0]\n",
    "            org_text = org_text[org_text.index(tokenizer.sos_token)+1:org_text.index(tokenizer.eos_token)]\n",
    "            if set(org_text)==set(np.concatenate(ref_ipcs.apply(lambda x: list(x)).values)):\n",
    "                cnt_same_ipcs += 1\n",
    "#                 cnt_same_ipcs -= 1\n",
    "#                 return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs), None\n",
    "            \n",
    "            n_iter = 30\n",
    "            step_size = 40\n",
    "\n",
    "            inclusions = [None, None, None, None]\n",
    "            higher_impacts = [None, None, None, None]\n",
    "            similar_refs_out = [None, None, None, None]\n",
    "            unsimilar_refs_out = [None, None, None, None]\n",
    "            optimised = False\n",
    "            for i in range(n_iter):\n",
    "                pred_outputs = final_model.module.predict(z)\n",
    "                z.retain_grad()\n",
    "                FC_estimated = np.round(np.exp(pred_outputs[0,1].item()), 4) # estimated forward citations\n",
    "                FC_estimated_inv = np.round(np.exp(pred_outputs[0,0].item()), 4)\n",
    "                \n",
    "                L1_error = (1-torch.exp(pred_outputs[0,1]))\n",
    "                L1_error.backward(retain_graph=True)\n",
    "#                 (1-pred_outputs[0,1]).backward(retain_graph=True)\n",
    "\n",
    "                grad_for_update = (step_size * z.grad)\n",
    "                z_ = z - grad_for_update\n",
    "\n",
    "                z.grad.zero_()\n",
    "                dec_outputs = final_model.module.decode(z_, enc_outputs, dec_inputs=None)\n",
    "                dec_outputs = dec_outputs.argmax(-1)\n",
    "\n",
    "                tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "                gen_text = tokenizer.decode_batch(dec_outputs.cpu().detach().numpy())[0]\n",
    "                if tokenizer.eos_token in gen_text:\n",
    "                    gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:gen_text.index(tokenizer.eos_token)]\n",
    "                else:\n",
    "                    gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:]\n",
    "                if gen_text != []:\n",
    "                    gen_text = [gen_text[0]] + list(np.array(gen_text[1:])[np.unique(gen_text[1:], return_index=True)[1]])                \n",
    "                    gen_text = set(gen_text)\n",
    "                else: continue\n",
    "                \n",
    "#                 if not np.array_equal(org_text, gen_text) and FC_estimated>=0.5:\n",
    "                if FC_estimated>=0.6:\n",
    "#                 if not np.array_equal(org_text, gen_text):\n",
    "#                 if set(org_text)!=set(gen_text) and FC_estimated>=0.5:\n",
    "                    optimised = True\n",
    "#                     print(f\"<< Iteration {i+1} >>\")\n",
    "#                     print(f\"Estimated prob. for L1 (L2): {FC_estimated} ({FC_estimated_inv})\")\n",
    "#                     print(\"Original class:\\n\",org_text,\"\\nGenerated class:\\n\", gen_text)\n",
    "    \n",
    "                    gen_text_breakdown = breakdown(gen_text)\n",
    "                    ref_ipcs_breakdown = (ref_ipcs.apply(lambda x: breakdown(x)[0]), ref_ipcs.apply(lambda x: breakdown(x)[1]), ref_ipcs.apply(lambda x: breakdown(x)[2]), ref_ipcs)\n",
    "            \n",
    "                    for i in range(4):\n",
    "                        if inclusions[i] is not None: continue\n",
    "                        temp_gen_text = gen_text_breakdown[i]\n",
    "                        temp_ref_ipcs = ref_ipcs_breakdown[i]\n",
    "                    \n",
    "                        hit_index = temp_ref_ipcs.apply(lambda x: 1 if set(x)==set(temp_gen_text) else 0)==1\n",
    "                        similar_refs = temp_ref_ipcs[hit_index].index\n",
    "                        similar_refs_out[i] = similar_refs\n",
    "                        unsimilar_refs = temp_ref_ipcs[~hit_index].index\n",
    "                        unsimilar_refs_out[i] = unsimilar_refs\n",
    "                        if len(similar_refs) == 0:\n",
    "                            inclusions[i] = 0\n",
    "                            higher_impacts[i] = None\n",
    "#                             print(\"Generated IPCs are not in citing patents' IPCs\")\n",
    "                        elif len(unsimilar_refs) == 0:\n",
    "                            inclusions[i] = 1\n",
    "                            similar_mean_FC = np.mean(ref_FCs.loc[similar_refs])\n",
    "                            if similar_mean_FC <= 0:\n",
    "                                higher_impacts[i] = 0\n",
    "                            else:\n",
    "                                higher_impacts[i] = 1\n",
    "#                             print(f\"similar patents' FCs: {np.round(similar_mean_FC, 4)}, no unsimilar patent\")\n",
    "                        else:\n",
    "                            inclusions[i] = 1\n",
    "                            similar_mean_FC = np.mean(ref_FCs.loc[similar_refs])\n",
    "                            unsimilar_mean_FC = np.mean(ref_FCs.loc[unsimilar_refs])\n",
    "                            if similar_mean_FC >= unsimilar_mean_FC:\n",
    "                                if similar_mean_FC <= 0:\n",
    "                                    higher_impacts[i] = None\n",
    "                                else:\n",
    "                                    higher_impacts[i] = 1\n",
    "                            else:\n",
    "                                higher_impacts[i] = 0\n",
    "#                             print(f\"similar patents' FCs: {np.round(similar_mean_FC, 4)}, unsimilar patents' FCs: {np.round(unsimilar_mean_FC, 4)}\")\n",
    "#                         if higher_impact==1:\n",
    "#                             print(f\"Generated IPCs have higher impact\")\n",
    "                    if None not in inclusions:\n",
    "                        break\n",
    "                z = z_\n",
    "            if optimised:\n",
    "                return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs), {\"index\": idx, \"patent_id\": used_test_data_TC.iloc[idx][\"number\"], \n",
    "                         \"org_text\": org_text, \"gen_text\": gen_text, \"ref_ipcs\": ref_ipcs, \"ref_FCs\": ref_FCs,\n",
    "                         \"inclusions\": inclusions, \"higher_impacts\": higher_impacts, \n",
    "                         \"FC_estimated\": FC_estimated,\n",
    "                         \"similar_refs\": similar_refs_out, \"unsimilar_refs\": unsimilar_refs_out}\n",
    "            else:\n",
    "                cnt_diverge += 1\n",
    "                return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs), None\n",
    "    else:\n",
    "        pass\n",
    "#         print(\"Input patent does not have forward citation\")\n",
    "        cnt_noFC += 1\n",
    "        return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs = 0, 0, 0, 0\n",
    "dict_out = {\"index\": [], \"patent_id\": [], \"org_text\": [], \"gen_text\": [], \"ref_ipcs\": [], \"ref_FCs\": [],\n",
    "            \"inclusions\": [], \"higher_impacts\": [], \"FC_estimated\": [], \"similar_refs\": [], \"unsimilar_refs\": []}\n",
    "for idx in tqdm(range(len(used_test_index_TC))):\n",
    "# for idx in tqdm(range(500)):\n",
    "    cnts, results = validate_reliability(idx)\n",
    "    cnt_nonexist += cnts[0]\n",
    "    cnt_noFC += cnts[1]\n",
    "    cnt_diverge += cnts[2]\n",
    "    cnt_same_ipcs += cnts[3]\n",
    "    \n",
    "    if results is not None:\n",
    "        for k,v in results.items():\n",
    "#             if v is not None:\n",
    "            dict_out[k].append(v)\n",
    "    \n",
    "for k, v in dict_out.items():\n",
    "    dict_out[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"#total:\",idx+1)\n",
    "print(\"#valid data:\",len(dict_out[\"index\"]))\n",
    "print(\"#nonexist data:\",cnt_nonexist)\n",
    "print(\"#no forward citations:\",cnt_noFC)\n",
    "print(\"#diverged:\",cnt_diverge)\n",
    "print(\"#same ipcs:\",cnt_same_ipcs)\n",
    "print(\"\\n\")\n",
    "for i in range(4):\n",
    "    inclusions = np.array(dict_out[\"inclusions\"])[:,i]\n",
    "    ratio_included = np.round(len(inclusions[inclusions==1])/len(inclusions), 4)\n",
    "    higher_impacts = np.array(dict_out[\"higher_impacts\"])[:,i][np.array(dict_out[\"higher_impacts\"])[:,i] != None]\n",
    "    ratio_higher_impact = np.round(len(higher_impacts[higher_impacts==1])/len(higher_impacts), 4)\n",
    "    print(f\"for level {i+1}, Ratio generated IPCs are included in citing patents: {ratio_included}\")\n",
    "    print(f\"for level {i+1}, Ratio generated IPCs have higher impact than other citing patents: {ratio_higher_impact}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "604/4143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inclusions = np.array(dict_out[\"inclusions\"])[np.array(dict_out[\"inclusions\"])[:,-1]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_inclusions = np.array(dict_out[\"inclusions\"])[np.array(dict_out[\"inclusions\"])[:,-1]==0]\n",
    "for i in range(3):\n",
    "    temp_ratio = len(temp_inclusions[temp_inclusions[:,i]==0]) / len(temp_inclusions)\n",
    "    print(f\"for level {i+1}, Hit ratio when level 4 is not hit: {np.round(temp_ratio,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "whole_patent_classes = tech_dataset.data[\"ipcs\"].apply(lambda x: set(x))\n",
    "\n",
    "hit_similar_FCs, hit_unsimilar_FCs, hit_diff_FCs = [], [], []\n",
    "hit_similar_FCs_mean, hit_unsimilar_FCs_mean = [], []\n",
    "hit_similar_FCs_rank = []\n",
    "whole_FC_ttest = {\"statistic\": [], \"pvalue\": []}\n",
    "whole_FCs_diff = []\n",
    "hit_samples_index = dict_out[\"inclusions\"][:,-1]==1\n",
    "\n",
    "hit_patent_ids = dict_out[\"patent_id\"][hit_samples_index]\n",
    "hit_similar_refs = dict_out[\"similar_refs\"][hit_samples_index][:,-1]\n",
    "hit_unsimilar_refs = dict_out[\"unsimilar_refs\"][hit_samples_index][:,-1]\n",
    "for i in range(len(hit_patent_ids)):\n",
    "    hit_FCs = dict_out[\"ref_FCs\"][hit_samples_index][i]\n",
    "    hit_FCs = hit_FCs.loc[~hit_FCs.index.duplicated(keep=\"first\")]\n",
    "    hit_similar_FC = hit_FCs.loc[hit_similar_refs[i].drop_duplicates()]\n",
    "#     hit_similar_FC = hit_similar_FC.drop_duplicates()\n",
    "    hit_similar_FC_rank = hit_FCs.rank(pct=True).loc[hit_similar_refs[i].drop_duplicates()]\n",
    "#     hit_similar_FC_rank = hit_similar_FC_rank.drop_duplicates()\n",
    "    hit_unsimilar_FC = hit_FCs.loc[hit_unsimilar_refs[i].drop_duplicates()]\n",
    "#     hit_unsimilar_FC = hit_unsimilar_FC.drop_duplicates()\n",
    "    if len(hit_unsimilar_FC)>0:\n",
    "        hit_diff_FC = hit_similar_FC.mean() - hit_unsimilar_FC.mean()\n",
    "    else:\n",
    "        hit_diff_FC = hit_similar_FC.mean()\n",
    "    \n",
    "    org_whole_FC = tech_dataset.data.loc[whole_patent_classes[whole_patent_classes==set(dict_out[\"org_text\"][hit_samples_index][i])].index][\"TC5\"]\n",
    "    gen_whole_FC = tech_dataset.data.loc[whole_patent_classes[whole_patent_classes==set(dict_out[\"gen_text\"][hit_samples_index][i])].index][\"TC5\"]\n",
    "    if len(org_whole_FC)>0:\n",
    "        whole_FC_diff = gen_whole_FC.mean() - org_whole_FC.mean()\n",
    "    else:\n",
    "        whole_FC_diff = gen_whole_FC.mean()\n",
    "    \n",
    "    hit_similar_FCs.append(hit_similar_FC)\n",
    "    hit_similar_FCs_rank.append(hit_similar_FC_rank)\n",
    "    hit_similar_FCs_mean.append(hit_similar_FC.mean())\n",
    "    hit_unsimilar_FCs.append(hit_unsimilar_FC)\n",
    "    if len(hit_unsimilar_FC)>0:\n",
    "        hit_unsimilar_FCs_mean.append(hit_unsimilar_FC.mean())\n",
    "    else:\n",
    "        hit_unsimilar_FCs_mean.append(0)\n",
    "    hit_diff_FCs.append(hit_diff_FC)\n",
    "    \n",
    "    ttest_res = ttest_ind(gen_whole_FC, org_whole_FC, equal_var=False)\n",
    "#     if set(dict_out[\"org_text\"][hit_samples_index][i]) != set(dict_out[\"gen_text\"][hit_samples_index][i]):\n",
    "#         print(org_whole_FC, gen_whole_FC)\n",
    "#         print(ttest_res)\n",
    "    \n",
    "    whole_FC_ttest[\"statistic\"].append(ttest_res.statistic)\n",
    "    whole_FC_ttest[\"pvalue\"].append(ttest_res.pvalue)\n",
    "    if set(dict_out[\"org_text\"][hit_samples_index][i]) != set(dict_out[\"gen_text\"][hit_samples_index][i]):\n",
    "        whole_FCs_diff.append(whole_FC_diff)\n",
    "    \n",
    "hit_similar_FCs = np.concatenate(hit_similar_FCs)\n",
    "hit_similar_FCs_rank = np.concatenate(hit_similar_FCs_rank)\n",
    "hit_similar_FCs_mean = np.array(hit_similar_FCs_mean)\n",
    "hit_unsimilar_FCs = np.concatenate(hit_unsimilar_FCs)\n",
    "hit_unsimilar_FCs_mean = np.array(hit_unsimilar_FCs_mean)\n",
    "hit_diff_FCs = np.array(hit_diff_FCs)\n",
    "\n",
    "print(\"Distribution of forward citations (hit)\\n\",pd.Series(hit_similar_FCs).describe(),\"\\n\")\n",
    "print(\"Distribution of forward citations (not hit)\\n\",pd.Series(hit_unsimilar_FCs).describe(),\"\\n\")\n",
    "print(\"Distribution of mean forward citations (hit)\\n\",pd.Series(hit_similar_FCs_mean).describe(),\"\\n\")\n",
    "print(\"Distribution of mean forward citations (not hit)\\n\",pd.Series(hit_unsimilar_FCs_mean).describe(),\"\\n\")\n",
    "print(\"Distribution of difference of forward citations\\n\",pd.Series(hit_diff_FCs).describe(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_same, cnt_diff = 0, 0\n",
    "ranks_same, ranks_diff = [], []\n",
    "value_same, value_diff = [], []\n",
    "org_patents_same, org_patents_diff = [], []\n",
    "cols_val = [\"patent_id\", \"org_ipcs\", \"org_FC\", \"gen_ipcs\", \"is_same\", \n",
    "            \"forward_ref\", \"ref_ipcs\", \"ref_FC\", \"ref_FC_rank\"]\n",
    "df_val = pd.DataFrame(columns=cols_val)\n",
    "hit_similar_refs = dict_out[\"similar_refs\"][hit_samples_index][:,-1]\n",
    "\n",
    "for i in tqdm(range(len(dict_out[\"ref_ipcs\"][hit_samples_index]))):\n",
    "    pid = dict_out[\"patent_id\"][hit_samples_index][i]\n",
    "    org_FC = tech_dataset.data.loc[pid][\"TC5\"]\n",
    "    orgs = set(dict_out[\"org_text\"][dict_out[\"inclusions\"][:,-1]==1][i])\n",
    "    gens = set(dict_out[\"gen_text\"][dict_out[\"inclusions\"][:,-1]==1][i])\n",
    "    is_same = 1 if orgs==gens or orgs.union(gens)==orgs else 0\n",
    "    hit_FCs = dict_out[\"ref_FCs\"][hit_samples_index][i]\n",
    "    hit_FCs = hit_FCs.loc[~hit_FCs.index.duplicated(keep=\"first\")]\n",
    "    hit_similar_FC = hit_FCs.loc[hit_similar_refs[i][hit_similar_refs[i].duplicated()]]\n",
    "#     hit_similar_FC = hit_similar_FC.drop_duplicates()\n",
    "    hit_similar_FC_rank = hit_FCs.rank(pct=True).loc[hit_similar_refs[i][hit_similar_refs[i].duplicated()]]\n",
    "#     hit_similar_FC_rank = hit_similar_FC_rank.drop_duplicates()\n",
    "    \n",
    "    for ref in hit_similar_refs[i].drop_duplicates():\n",
    "        ref_ipcs = dict_out[\"ref_ipcs\"][hit_samples_index][i].loc[ref]\n",
    "        if isinstance(ref_ipcs, pd.Series): ref_ipcs = ref_ipcs[0]\n",
    "        hit_similar_FC = hit_FCs.loc[ref]\n",
    "        if isinstance(hit_similar_FC, pd.Series): hit_similar_FC = hit_similar_FC[0]\n",
    "        hit_similar_FC_rank = hit_FCs.rank(pct=True).loc[ref]\n",
    "        if isinstance(hit_similar_FC_rank, pd.Series): hit_similar_FC_rank = hit_similar_FC_rank[0]\n",
    "        \n",
    "        df_container = pd.DataFrame([[pid, orgs, org_FC, gens, is_same, ref, ref_ipcs, hit_similar_FC, hit_similar_FC_rank]], columns=cols_val)\n",
    "        df_val = pd.concat([df_val, df_container])\n",
    "\n",
    "df_val = df_val.set_index(\"patent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L1_criterion = tech_dataset.data[\"TC5\"].quantile(0.9)\n",
    "print(\"total hit:\", len(df_val))\n",
    "print(\"same:\",len(df_val[df_val[\"is_same\"]==1]))\n",
    "print(\"diff:\",len(df_val[df_val[\"is_same\"]==0]))\n",
    "print(\"over L1 criterion:\", len(df_val[df_val[\"is_same\"]==0][df_val[df_val[\"is_same\"]==0][\"ref_FC\"]>=L1_criterion]))\n",
    "print(\"ratio:\",len(df_val[df_val[\"is_same\"]==0][df_val[df_val[\"is_same\"]==0][\"ref_FC\"]>=L1_criterion]) / len(df_val[df_val[\"is_same\"]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 인용 IPC 중 생성 IPC와 동일한 게 있으면서, 입력 IPC와 생성 IPC가 다르고, 피인용수가 전체 데이터셋의 L1 기준인 9 이상인 샘플\n",
    "df_val[df_val[\"is_same\"]==0][df_val[df_val[\"is_same\"]==0][\"ref_FC\"]>=L1_criterion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Patent_matched 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"ref_FC\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"ref_FC_rank\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val[\"ref_FC_rank\"].astype(float).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IPC_original == IPC_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==1][\"ref_FC\"].astype(int).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==1][\"ref_FC_rank\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==1][\"ref_FC_rank\"].astype(float).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IPC_original != IPC_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==0][\"ref_FC\"].astype(int).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==0][\"ref_FC_rank\"].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[df_val[\"is_same\"]==0][\"ref_FC_rank\"].astype(float).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../results/validation/\"+analysis_date):\n",
    "    os.mkdir(\"../results/validation/\"+analysis_date)\n",
    "with open(\"../results/validation/\"+analysis_date+\"/dict_out.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dict_out, f)\n",
    "with open(\"../results/validation/\"+analysis_date+\"/df_val.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "whole_FC_ttest = {\"statistic\": [], \"pvalue\": []}\n",
    "whole_FCs_diff = []\n",
    "for i in tqdm(range(len(dict_out[\"patent_id\"]))):\n",
    "    org_whole_FC = tech_dataset.data.loc[whole_patent_classes[whole_patent_classes==set(dict_out[\"org_text\"][i])].index][\"TC5\"]\n",
    "    gen_whole_FC = tech_dataset.data.loc[whole_patent_classes[whole_patent_classes==set(dict_out[\"gen_text\"][i])].index][\"TC5\"]\n",
    "    \n",
    "#     print(org_whole_FC, gen_whole_FC)\n",
    "    \n",
    "    if len(org_whole_FC)>0 and len(gen_whole_FC)>0:\n",
    "        whole_FC_diff = gen_whole_FC.mean() - org_whole_FC.mean()\n",
    "    elif len(org_whole_FC)==0 and len(gen_whole_FC)>0:\n",
    "        whole_FC_diff = gen_whole_FC.mean()\n",
    "    elif len(org_whole_FC)>0 and len(gen_whole_FC)==0:\n",
    "        whole_FC_diff = org_whole_FC.mean()\n",
    "    else:\n",
    "        whole_FC_diff = 0.0\n",
    "    \n",
    "    ttest_res = ttest_ind(gen_whole_FC, org_whole_FC, equal_var=False)\n",
    "#     if set(dict_out[\"org_text\"][hit_samples_index][i]) != set(dict_out[\"gen_text\"][hit_samples_index][i]):\n",
    "#         print(org_whole_FC, gen_whole_FC)\n",
    "#         print(ttest_res)\n",
    "    if set(dict_out[\"org_text\"][i]) != set(dict_out[\"gen_text\"][i]):    \n",
    "        whole_FC_ttest[\"statistic\"].append(ttest_res.statistic)\n",
    "        whole_FC_ttest[\"pvalue\"].append(ttest_res.pvalue)\n",
    "        if set(dict_out[\"org_text\"][i]) != set(dict_out[\"gen_text\"][i]):\n",
    "            whole_FCs_diff.append(whole_FC_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(whole_FCs_diff).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(whole_FC_ttest[\"statistic\"])[~pd.Series(whole_FC_ttest[\"statistic\"]).isna()].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(whole_FC_ttest[\"statistic\"]).loc[pd.Series(whole_FC_ttest[\"pvalue\"]).dropna()[pd.Series(whole_FC_ttest[\"pvalue\"]).dropna()<0.05].index].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_patent_ids = dict_out[\"patent_id\"][hit_samples_index]\n",
    "# org_ipcs = pd.Series(dict_out[\"org_text\"][hit_samples_index]).apply(lambda x: set(x))\n",
    "# gen_ipcs = pd.Series(dict_out[\"gen_text\"][hit_samples_index])\n",
    "\n",
    "org_patent_ids = dict_out[\"patent_id\"]\n",
    "org_ipcs = pd.Series(dict_out[\"org_text\"]).apply(lambda x: set(x))\n",
    "gen_ipcs = pd.Series(dict_out[\"gen_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ipcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ipcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ipcs = total_rawdata.dropna(subset=[\"granted_year\", \"application_year\", \"application_year_backward_refs\", \"backward_refs\", \"n_NPL_refs\", \"main_ipc\", \"sub_ipc\"]).apply(lambda x: set([x[\"main_ipc\"].split(\"/\")[0]] + [xx.split(\"/\")[0] for xx in x[\"sub_ipc\"].split(\";\")]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_5_years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Forward citations (recent 5 years)\n",
    "#Backward citations\n",
    "#Non-patent literature references\n",
    "Technology cycle time\n",
    "Patent originality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originality 는 계산량 때문에 일단 보류..\n",
    "TCT도...\n",
    "\n",
    "-> 추후에 계산할 때는, 클래스 조합별로 미리 다 계산해놓고 org_ipcs나 gen_ipcs에 대해 가져오는걸로 해야할듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rawdata_dropna = total_rawdata.dropna(subset=[\"main_ipc\", \"sub_ipc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comparison_cols = [\"org_FC\", \"org_BC\", \"org_NPL\", \"org_TCT\", \"org_ORG\", \"gen_FC\", \"gen_BC\", \"gen_NPL\", \"gen_TCT\", \"gen_ORG\"]\n",
    "df_global_comparison = pd.DataFrame(columns=comparison_cols)\n",
    "for i in tqdm(range(len(org_ipcs))):\n",
    "    temp_pid = dict_out[\"patent_id\"][i]\n",
    "    if org_ipcs[i] != gen_ipcs[i] and org_ipcs[i] in total_ipcs.values:\n",
    "        temp_org = total_rawdata.loc[total_ipcs[total_ipcs==org_ipcs[i]].index]\n",
    "        temp_org = temp_org.loc[~temp_org.index.duplicated(keep=\"first\")]\n",
    "        org_mean_FC = temp_org[recent_5_years].values.sum(axis=1).mean()\n",
    "        org_mean_BC = temp_org[\"backward_refs\"].apply(lambda x: len(x.split(\";\"))).values.mean()\n",
    "        org_mean_NPL = temp_org[\"n_NPL_refs\"].values.mean()\n",
    "        \n",
    "        ## TODO\n",
    "        org_mean_TCT = np.nan\n",
    "        org_mean_ORG = np.nan\n",
    "        \n",
    "        temp_gen = total_rawdata.loc[total_ipcs[total_ipcs==gen_ipcs[i]].index]\n",
    "        temp_gen = temp_gen.loc[~temp_gen.index.duplicated(keep=\"first\")]\n",
    "        gen_mean_FC = temp_gen[recent_5_years].values.sum(axis=1).mean()\n",
    "        gen_mean_BC = temp_gen[\"backward_refs\"].apply(lambda x: len(x.split(\";\"))).values.mean()\n",
    "        gen_mean_NPL = temp_gen[\"n_NPL_refs\"].values.mean()\n",
    "        \n",
    "        ## TODO\n",
    "        gen_mean_TCT = np.nan\n",
    "        gen_mean_ORG = np.nan\n",
    "               \n",
    "        out = pd.DataFrame([[org_mean_FC, org_mean_BC, org_mean_NPL, org_mean_TCT, org_mean_ORG, gen_mean_FC, gen_mean_BC, gen_mean_NPL, gen_mean_TCT, gen_mean_ORG]], columns=comparison_cols, index=[temp_pid])\n",
    "        df_global_comparison = pd.concat([df_global_comparison, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_comparison.dropna(subset=[\"gen_FC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_comparison.dropna(subset=[\"gen_FC\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_org.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = temp_backward_refs.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backward_appyear = total_rawdata.loc[total_rawdata.index.intersection(pd.Index(sample))][\"application_year\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_TCT(sample):\n",
    "    backward_refs = sample[\"backward_refs\"].split(\";\")\n",
    "    backward_appyear = total_rawdata.loc[total_rawdata.index.intersection(pd.Index(backward_refs))][\"application_year\"].values\n",
    "    return np.median(sample[\"application_year\"] - backward_appyear) if len(backward_appyear) > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_TCT(temp_org.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_org.apply(cal_TCT, axis=1).dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = temp_org.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_refs = sample[\"backward_refs\"].split(\";\")\n",
    "backward_appyear = total_rawdata.loc[total_rawdata.index.intersection(pd.Index(backward_refs))][\"application_year\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(backward_appyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(sample[\"application_year\"] - backward_appyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rawdata.loc[total_rawdata.index.intersection(pd.Index(backward_refs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_appyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"backward_refs\"].split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(temp_org[\"application_year\"].iloc[0] - backward_appyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_backward_refs = temp_org['backward_refs'].apply(lambda x: x.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_backward_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = temp_backward_refs.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_ipcs_exist(sample):\n",
    "    sample_ipcs = total_rawdata_dropna.loc[total_rawdata_dropna.index.intersection(pd.Index(sample))].apply(lambda x: [x[\"main_ipc\"]]+x[\"sub_ipc\"].split(\";\"), axis=1)\n",
    "    return 1 if len(sample_ipcs) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_backward_refs.apply(return_backward_ipcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_originality(backward_ipcs):    \n",
    "    ncited_i = len(np.concatenate(sample_ipcs.values))\n",
    "    ncited_ihs = np.unique(np.concatenate(sample_ipcs.values), return_counts=True)[1]\n",
    "    out = 1 - np.sum(np.square(ncited_ihs / ncited_i))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ipcs = total_rawdata_dropna.loc[total_rawdata_dropna.index.intersection(pd.Index(sample))].apply(lambda x: [x[\"main_ipc\"]]+x[\"sub_ipc\"].split(\";\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ipcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_originality(temp_backward_refs.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncited_i = len(np.concatenate(sample_ipcs.values))\n",
    "ncited_ihs = np.unique(np.concatenate(sample_ipcs.values), return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncited_ihs / ncited_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gen[recent_5_years].values.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
