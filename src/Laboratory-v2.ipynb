{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/'\n",
    "master_dir = '/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer, Predictor\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict, to_device\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"class+claim\",\n",
    "    data_file = \"collection_[H01L,H10][2017].csv\",\n",
    "    target_ipc=\"H01L\",\n",
    "    pred_type=\"classification\",\n",
    "    n_TC = 5,\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    batch_size=16,\n",
    "    max_epochs=50,\n",
    "    use_accelerator=None,\n",
    "    do_save=False,\n",
    "    n_gpus=4,\n",
    "    light=True,\n",
    "#     config_file=os.path.join(root_dir, \"configs\", \"USED_configs\", \"[CONFIGS]2023-04-11_00:39.json\"),\n",
    "    config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "data_dir = os.path.join(master_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "    configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "elif len(configs.data.target_ipc) > 5:\n",
    "    configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir,\n",
    "                        \"pretrained_enc\": configs.model.pretrained_enc,\n",
    "                        \"pretrained_dec\": configs.model.pretrained_dec,\n",
    "                        \"data_nrows\": None})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_enc_hidden = configs.model.d_enc_hidden = None\n",
    "    d_pred_hidden = configs.model.d_pred_hidden = None\n",
    "    d_latent = 64\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_enc_hidden = configs.model.d_enc_hidden\n",
    "    d_pred_hidden = configs.model.d_pred_hidden\n",
    "    d_latent = configs.model.d_enc_hidden * configs.model.n_directions\n",
    "    d_latent = 64\n",
    "\n",
    "    configs.model.update({\"d_latent\": d_latent})\n",
    "\n",
    "    key_components = {\"data\": [\"target_ipc\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_enc_hidden\", \"d_pred_hidden\", \"d_latent\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset...\n",
      "\n",
      "\n",
      "\n",
      "Tokenizer is trained and saved\n",
      "67.3479 sec elapsed for loading patents for class [H01L]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "org_config_keys_temp = copy.copy(org_config_keys[\"data\"])\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"use_pretrained_tokenizer\"))\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"data_file\"))\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys_temp])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "        if tech_dataset.pretrained_enc != configs.data.pretrained_enc or tech_dataset.pretrained_dec != configs.data.pretrained_dec:\n",
    "                tech_dataset.pretrained_enc = configs.data.pretrained_enc\n",
    "                tech_dataset.pretrained_dec = configs.data.pretrained_dec\n",
    "                tech_dataset.tokenizers = tech_dataset.get_tokenizers()\n",
    "        for tk in tech_dataset.tokenizers.values():\n",
    "            if \"vocab_size\" not in dir(tk):\n",
    "                tk.vocab_size = tk.get_vocab_size()\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        tech_dataset.rawdata = None\n",
    "        pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.model.update({\"tokenizers\": tech_dataset.tokenizers,\n",
    "                    \"n_enc_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_dec_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_enc_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_dec_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                    \"i_padding\": tech_dataset.tokenizers[\"class_enc\"].token_to_id(\"<PAD>\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 24389, Validation: 6098, Test: 3388\n"
     ]
    }
   ],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.1, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizers=tech_dataset.tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([30722,  3153]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tech_dataset.Y_digitized, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictor parameter update 실험, z-sampling 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1][::-1].copy()).to(device)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "from utils import KLDLoss\n",
    "from parallel import DataParallel\n",
    "model_params = configs.model\n",
    "loss_recon = torch.nn.CrossEntropyLoss(ignore_index=model_params['i_padding'])\n",
    "loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.NLLLoss(weight=class_weights)\n",
    "loss_kld = KLDLoss()\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "batch_data = to_device(batch_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(277.7591, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3289, -0.8290,  2.1928, -0.8552,  0.4497, -0.4875,  0.3141, -0.3630,\n",
       "          0.4322,  2.0363],\n",
       "        [ 0.0231,  0.8366,  0.2612, -0.9064, -0.9936,  0.2772,  0.6317,  0.9932,\n",
       "         -0.5697, -0.9820],\n",
       "        [ 1.4624,  0.0575,  1.6061, -0.7062,  0.7521,  0.7862, -0.8314,  1.0175,\n",
       "          0.3154,  1.2769],\n",
       "        [-0.3571, -0.2611,  1.9931, -1.2668, -0.0377, -2.1997, -0.8126,  0.8696,\n",
       "         -0.1465, -0.5589],\n",
       "        [-0.6340,  0.5706, -1.7299,  0.0265, -0.0048, -1.1392,  1.3421,  1.0491,\n",
       "         -0.8917, -0.4334],\n",
       "        [-0.6902, -1.3615,  0.4342, -0.1711,  0.4508, -1.6071, -0.2748,  1.2614,\n",
       "          0.1740, -0.6839],\n",
       "        [ 0.0041,  0.0573, -0.5704, -1.4403,  1.4748, -0.4294, -0.9826,  1.9431,\n",
       "         -1.3444, -0.8872],\n",
       "        [ 0.0756,  0.2134,  2.2455, -0.3017,  0.6057,  0.0924,  1.3588,  0.4385,\n",
       "         -1.3261,  1.3466],\n",
       "        [ 0.8683,  0.3203, -0.9666, -0.1814, -0.0961, -1.0364, -1.0002,  0.6757,\n",
       "          1.5087,  0.8372],\n",
       "        [-0.3333,  0.3071,  1.2428, -1.2019,  0.4280, -1.2388, -1.2820,  1.0313,\n",
       "         -0.4538, -1.2969]], device='cuda:1', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.4419, device='cuda:1', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0592, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.0443, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(1.8108, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.5879, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.3179, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(0.3017, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 7.9141e-03, -8.1524e-03,  2.6540e-02,  6.9058e-02, -1.2883e-01,\n",
      "         -1.0029e-01, -8.4398e-03,  7.1938e-02, -1.2096e-01, -3.7986e-02,\n",
      "          1.4293e-01,  4.8835e-04, -1.3684e-01,  9.2880e-02, -1.9429e-02,\n",
      "         -1.2836e-01, -1.8933e-02,  3.7663e-03,  1.2849e-01, -7.3794e-02,\n",
      "         -7.8411e-02, -1.2944e-01,  3.3521e-02, -1.3669e-01, -1.3464e-02,\n",
      "         -1.3530e-01, -1.4054e-01, -4.2684e-02,  1.0326e-01, -2.7437e-02,\n",
      "         -2.1877e-02,  2.2328e-02,  1.4212e-01,  1.7567e-02, -1.1428e-01,\n",
      "         -3.0918e-02, -1.4953e-02, -1.2023e-01,  8.6323e-03, -1.3624e-01,\n",
      "          7.5921e-02, -2.6093e-02, -2.2029e-02,  5.7671e-02,  4.6748e-03,\n",
      "         -4.6485e-02,  8.6173e-02, -6.7365e-02],\n",
      "        [ 8.3927e-02, -7.5478e-02,  7.5971e-02, -5.3393e-02, -8.1054e-02,\n",
      "         -3.1728e-02, -1.4112e-01, -1.2972e-01,  1.5299e-03,  5.6047e-02,\n",
      "         -6.2440e-02,  1.3069e-01, -1.3344e-02, -1.0890e-01,  8.7305e-02,\n",
      "         -4.1881e-02, -6.3731e-02,  1.0656e-01,  3.3370e-03, -3.2975e-02,\n",
      "          3.6308e-02, -7.0078e-02, -9.1320e-02,  5.0796e-02,  8.1319e-02,\n",
      "         -1.3263e-01, -8.8583e-02,  1.2871e-02, -1.0059e-01,  5.1697e-02,\n",
      "         -1.1941e-01, -5.0472e-02,  2.9403e-02, -5.0252e-02, -1.1074e-01,\n",
      "          1.1880e-01,  1.2193e-01,  6.2001e-02, -6.2832e-02, -1.0006e-01,\n",
      "          2.2102e-02,  7.3676e-02, -9.6096e-02,  3.9671e-02, -1.4411e-01,\n",
      "          4.4047e-02, -8.1722e-02, -2.1638e-02],\n",
      "        [ 8.5473e-02, -2.4827e-03, -9.4695e-02,  9.3031e-02,  1.1042e-01,\n",
      "          5.6415e-02,  6.1127e-02,  7.8911e-02, -2.9661e-02, -8.5598e-02,\n",
      "          9.1198e-02, -4.9966e-02,  9.7357e-02, -2.8936e-02,  5.3283e-02,\n",
      "         -1.1565e-01, -1.3500e-01, -1.2777e-01, -1.0849e-01,  6.5312e-02,\n",
      "          8.5423e-02,  4.5256e-03, -1.3203e-01, -1.2040e-01, -9.7584e-02,\n",
      "          1.2327e-01, -1.2685e-01,  9.5615e-02, -6.1830e-02,  1.0665e-01,\n",
      "          1.0039e-01, -1.0015e-01, -1.3007e-01,  9.7320e-02, -1.3152e-01,\n",
      "          9.6317e-02, -9.9859e-02, -4.5473e-02,  5.0582e-02, -1.1353e-01,\n",
      "         -1.2910e-01,  2.9484e-02, -1.1995e-01, -6.7264e-03, -5.5189e-02,\n",
      "          1.2809e-01, -9.7216e-02, -5.3627e-02],\n",
      "        [-9.7057e-02, -5.4988e-02, -8.0542e-02,  2.4485e-02,  9.6763e-02,\n",
      "          3.9130e-02, -1.0015e-01,  5.3207e-02,  1.0903e-02, -4.7439e-02,\n",
      "         -1.0560e-01,  1.0692e-01, -4.5393e-02, -4.7861e-02,  1.9222e-02,\n",
      "          2.1907e-02, -1.3725e-01,  8.0168e-02,  1.1183e-01, -1.2743e-01,\n",
      "          1.2934e-01,  9.8221e-02,  1.2515e-01,  3.1547e-02,  1.3183e-01,\n",
      "          3.3001e-02, -8.3531e-02, -6.4619e-02, -1.1959e-01, -2.4853e-02,\n",
      "          1.2815e-01,  9.2615e-02,  1.3029e-01,  4.2939e-02,  7.7859e-02,\n",
      "          2.5823e-03, -1.9439e-02,  1.2235e-01,  1.1434e-01, -1.0714e-01,\n",
      "          1.3950e-01, -5.9248e-02,  6.9849e-02, -1.1244e-01,  7.2050e-02,\n",
      "          2.9703e-02, -1.0467e-01, -4.6581e-03],\n",
      "        [-8.4451e-02, -1.1588e-02,  1.2125e-01, -1.3371e-01, -1.3670e-01,\n",
      "         -1.4101e-01, -3.1827e-02, -4.1393e-02,  8.5423e-02,  5.3722e-03,\n",
      "         -1.0086e-01,  6.5276e-02,  1.2832e-02,  1.3146e-01, -6.8715e-02,\n",
      "         -1.0088e-01, -4.2347e-02,  5.5489e-02, -5.1396e-02,  1.0439e-01,\n",
      "         -1.0829e-01, -2.3177e-02,  6.1034e-02,  3.3723e-02,  1.4072e-01,\n",
      "         -1.4165e-01,  2.3173e-02, -1.3395e-01, -9.9987e-02,  1.2879e-01,\n",
      "         -9.6989e-02,  2.7807e-02,  4.0782e-02, -2.9702e-02, -1.2605e-01,\n",
      "         -3.6764e-02, -1.7874e-02, -5.6499e-02,  1.3596e-01, -7.2008e-03,\n",
      "          4.7963e-02, -1.0462e-01, -1.7530e-02, -2.8611e-02,  1.1572e-01,\n",
      "         -1.1526e-01, -1.0649e-01,  9.2785e-02],\n",
      "        [ 1.0264e-01,  1.5452e-02, -7.5021e-02, -1.2734e-01, -1.1010e-01,\n",
      "          6.5433e-02, -2.6861e-02, -5.6713e-02,  1.0922e-02, -5.9767e-03,\n",
      "         -5.4438e-02, -2.1873e-02,  8.1709e-02,  7.3583e-02, -9.6900e-02,\n",
      "          1.0220e-01, -4.3555e-02,  9.6210e-02,  1.1570e-01,  2.3866e-02,\n",
      "          1.4114e-01,  1.8515e-02, -1.2503e-01, -6.6885e-02, -4.2421e-02,\n",
      "         -4.6216e-02, -8.0502e-02,  3.6581e-02,  1.1351e-01, -9.5350e-02,\n",
      "         -1.6698e-02,  1.2849e-02, -2.1811e-02,  9.4908e-02,  2.0117e-02,\n",
      "          4.5803e-02, -5.7946e-04,  9.4793e-02,  2.8943e-02, -7.7065e-02,\n",
      "         -4.0232e-02,  1.1040e-01,  1.3697e-01,  9.6087e-04,  3.9141e-02,\n",
      "          4.2256e-02, -9.3592e-03,  3.0303e-02],\n",
      "        [-1.4251e-01,  7.8977e-02, -5.6854e-02, -5.0303e-02,  9.1607e-02,\n",
      "          6.0315e-02,  6.3116e-02, -7.4313e-02, -9.5813e-02, -8.4486e-02,\n",
      "         -1.1574e-01, -3.0103e-03, -1.2468e-01, -2.8977e-03, -9.7738e-02,\n",
      "          7.6319e-02,  2.9221e-02, -1.2229e-01,  7.4549e-02,  8.4334e-02,\n",
      "          1.2293e-01,  4.9592e-02, -7.3480e-02,  9.1758e-02,  1.0188e-01,\n",
      "         -3.4893e-02, -5.8407e-02, -9.7440e-02,  1.1230e-02,  1.4404e-01,\n",
      "          4.8549e-02, -2.7651e-02, -1.2028e-01,  7.9886e-02,  3.9201e-02,\n",
      "         -2.9505e-02,  9.5307e-02, -1.2155e-01,  4.1559e-02, -1.0009e-01,\n",
      "          7.4710e-05, -1.3452e-01,  1.3032e-02, -4.7593e-02,  9.1673e-02,\n",
      "          1.2636e-01,  1.2016e-01, -9.9639e-02],\n",
      "        [-1.1025e-01,  6.5175e-02,  1.2949e-01,  1.2375e-01, -2.1097e-02,\n",
      "         -1.0953e-01,  1.3888e-01, -6.9242e-02,  7.4020e-04, -8.4148e-02,\n",
      "          3.0733e-02, -6.7270e-02,  8.7495e-02,  9.5054e-02, -6.7560e-03,\n",
      "          8.6758e-02,  6.6432e-02,  1.3645e-01, -1.4318e-02, -1.6122e-02,\n",
      "          1.0862e-01,  1.4011e-01,  1.0209e-01, -1.3460e-01,  7.8334e-02,\n",
      "         -7.9475e-02, -6.1006e-03,  8.9412e-02,  1.3799e-01, -7.6336e-02,\n",
      "         -1.2482e-01,  8.1261e-02,  1.0203e-01,  1.2846e-01,  5.7873e-02,\n",
      "          1.2193e-01,  1.8982e-02, -1.4204e-01, -4.7230e-02, -3.0511e-02,\n",
      "          1.2635e-01,  5.8276e-02,  1.1597e-01,  1.2155e-01, -1.6430e-02,\n",
      "         -1.2956e-01, -4.2550e-02, -9.5250e-02],\n",
      "        [ 1.1124e-01, -9.3013e-02, -6.4476e-02, -7.7450e-02,  3.7234e-02,\n",
      "          9.5908e-02, -7.0962e-02, -1.0735e-02, -6.4906e-02, -2.9748e-02,\n",
      "          6.4449e-02,  1.3924e-01, -1.2115e-01, -3.7697e-02,  7.6610e-02,\n",
      "          1.2945e-01, -9.9795e-03, -7.4624e-02, -2.3162e-02, -1.4358e-01,\n",
      "          7.0783e-02,  1.3387e-01, -7.1823e-02, -2.3100e-02, -1.2235e-01,\n",
      "         -3.7539e-02, -1.5396e-02,  8.7262e-03, -1.0422e-01, -3.0316e-02,\n",
      "         -7.0593e-02, -4.3665e-02,  1.8846e-02, -1.3831e-01, -3.4452e-02,\n",
      "         -8.5803e-02, -1.0805e-01, -6.4578e-02, -1.1418e-01,  1.0073e-01,\n",
      "          1.4412e-01, -1.2648e-01,  3.3443e-02,  1.0848e-01,  5.6657e-02,\n",
      "          3.5930e-02, -6.7571e-02,  2.5279e-02],\n",
      "        [ 9.5177e-03, -7.7086e-02,  9.9428e-02,  3.4746e-02, -1.2281e-01,\n",
      "          3.6860e-02,  1.3561e-01,  6.6854e-03, -1.6414e-02,  7.7425e-02,\n",
      "          8.4127e-02,  5.6535e-02, -2.8464e-02,  1.4422e-01,  1.2096e-01,\n",
      "          2.0430e-02, -5.7981e-02,  2.0876e-02,  1.0939e-01,  1.6044e-02,\n",
      "         -6.9169e-02,  1.1051e-01,  1.2630e-01,  6.5441e-02,  8.9642e-03,\n",
      "         -6.1154e-02, -1.3357e-01,  1.1816e-01,  1.1698e-01, -2.7714e-02,\n",
      "          1.9619e-02, -9.8943e-02,  1.6676e-02, -1.4268e-01, -1.0213e-01,\n",
      "          7.1355e-02, -1.0795e-01,  6.2466e-02,  1.0686e-01,  1.1140e-02,\n",
      "         -3.7923e-02,  4.5240e-02,  2.9840e-02,  5.5711e-02,  7.4388e-02,\n",
      "          1.1311e-01, -1.4372e-01,  1.1782e-01],\n",
      "        [-6.7557e-02,  1.0858e-01,  3.6284e-02,  8.1832e-02, -1.1486e-01,\n",
      "         -6.9747e-02,  1.0777e-01, -8.1834e-02, -5.2669e-02, -1.1230e-01,\n",
      "         -5.9616e-02, -3.8421e-02, -5.0472e-02,  9.4587e-02, -1.0923e-01,\n",
      "         -1.3488e-01,  8.2561e-02,  9.6023e-02,  1.0185e-01,  3.3188e-02,\n",
      "         -5.0232e-02,  3.7418e-02, -1.0633e-01, -3.6242e-03,  2.0953e-02,\n",
      "          3.9767e-02, -5.9923e-03,  2.5856e-02, -1.3808e-01, -1.3333e-01,\n",
      "         -5.5748e-02, -4.1170e-02, -9.8206e-02, -1.3276e-01, -9.7503e-02,\n",
      "         -1.0857e-01, -1.7077e-02,  8.3645e-02,  1.0205e-01, -5.7723e-02,\n",
      "         -4.8519e-02, -9.1847e-02, -1.0412e-01,  1.3647e-01,  2.9632e-02,\n",
      "          1.2078e-01, -1.1624e-01,  1.3197e-01],\n",
      "        [-1.3246e-01,  8.0267e-02, -6.3838e-02,  1.3425e-01,  7.1490e-02,\n",
      "          1.0258e-01,  9.0691e-02,  1.2105e-01, -5.4095e-02, -8.9563e-02,\n",
      "         -9.4245e-02, -1.3036e-02,  1.2073e-02,  4.3700e-02, -1.4670e-02,\n",
      "          1.6024e-02,  6.9597e-02,  6.1059e-03,  8.4346e-02, -5.1517e-02,\n",
      "         -8.2436e-02, -3.6007e-02, -2.9602e-02,  1.2023e-01, -4.3576e-02,\n",
      "          1.1243e-01, -4.3504e-02, -1.0258e-02, -8.4399e-02, -4.3864e-02,\n",
      "         -2.0480e-03, -2.4259e-02, -7.6720e-02, -9.2239e-02, -1.0614e-01,\n",
      "         -4.7607e-02,  6.1203e-02,  1.1312e-01, -2.7570e-02, -8.1533e-03,\n",
      "          3.7911e-02, -7.8086e-02,  1.9588e-03,  6.8289e-03, -1.1632e-01,\n",
      "         -1.1130e-01,  6.5108e-03, -5.0232e-02],\n",
      "        [ 2.5357e-02, -1.0174e-01,  8.8988e-02, -4.7302e-02, -8.3680e-02,\n",
      "          2.4355e-02, -3.7060e-02, -5.7485e-02, -5.4550e-02, -9.0958e-02,\n",
      "          5.7899e-02, -8.5047e-02,  9.0305e-03, -1.4696e-02, -7.3814e-02,\n",
      "          7.7517e-02, -9.2573e-02, -1.0017e-02,  1.3339e-01, -1.2555e-01,\n",
      "         -3.4449e-02, -1.2823e-01, -1.4002e-01,  2.4991e-02,  6.6739e-02,\n",
      "         -7.8730e-02, -1.0556e-01, -2.6881e-02,  6.8488e-02, -1.2040e-01,\n",
      "         -2.2604e-02, -3.3833e-02, -1.1256e-01, -9.9878e-02,  9.6474e-02,\n",
      "         -6.9948e-02, -1.3446e-01, -9.8689e-02, -3.5523e-02, -5.3452e-02,\n",
      "         -8.4575e-02,  5.0183e-02,  7.3778e-02, -1.3025e-01, -7.5635e-02,\n",
      "         -1.4133e-02, -1.2850e-01, -1.3072e-01],\n",
      "        [-9.5257e-02,  1.3171e-01,  4.3438e-02, -8.9068e-02,  3.7093e-02,\n",
      "          5.3369e-02, -1.1410e-01,  2.0587e-02,  7.2678e-02, -1.2126e-01,\n",
      "         -1.1692e-03, -1.3353e-01, -4.4938e-04,  1.2971e-01,  1.3090e-01,\n",
      "         -4.6805e-02, -2.7331e-02, -1.2403e-01, -8.8703e-02, -2.9951e-02,\n",
      "          1.1412e-01,  5.0138e-02, -4.9892e-02, -1.1236e-01, -1.3220e-01,\n",
      "         -1.1876e-01, -9.9513e-02, -1.4214e-01,  6.4951e-02,  5.1963e-02,\n",
      "         -1.8467e-02,  5.1959e-02, -1.2906e-01,  1.9135e-02, -8.0775e-02,\n",
      "          1.2212e-02,  5.7587e-02, -5.4034e-02, -4.8397e-02,  1.3027e-01,\n",
      "         -1.0930e-01, -1.1329e-01,  2.6680e-02,  7.3780e-02,  8.9795e-02,\n",
      "         -4.5205e-02,  1.4307e-01,  7.9825e-02],\n",
      "        [-1.0061e-01, -1.3870e-01,  1.0036e-01,  4.5541e-03,  3.6811e-02,\n",
      "          2.0888e-02,  1.1809e-01, -8.3395e-02,  8.0103e-03,  3.4368e-02,\n",
      "         -4.3113e-02,  7.2984e-02, -7.4849e-02, -3.4036e-02,  4.8827e-02,\n",
      "          3.7464e-02, -7.0651e-02, -1.0998e-01,  6.6458e-02, -1.1274e-01,\n",
      "          2.8614e-02, -1.2468e-01,  6.8153e-02,  2.5595e-02,  5.5681e-02,\n",
      "          5.8065e-02,  1.3582e-01,  5.7402e-02, -1.0364e-01, -5.4049e-02,\n",
      "         -8.4531e-02,  1.1917e-01, -6.9453e-02,  5.4725e-02, -3.6901e-03,\n",
      "          1.4024e-01,  1.9397e-02, -1.2876e-02,  4.7785e-02, -1.1946e-02,\n",
      "          1.2873e-01,  1.2385e-01, -9.0266e-02,  1.0228e-01, -2.6664e-02,\n",
      "          1.2228e-01,  1.2902e-01,  7.4103e-02],\n",
      "        [ 6.9799e-02, -7.1633e-02,  3.5656e-02,  1.2171e-01,  1.3784e-01,\n",
      "          1.1889e-01, -3.6292e-02, -8.9517e-02,  1.4207e-01,  9.9583e-02,\n",
      "         -1.3666e-01, -1.4370e-02, -1.3219e-02, -5.0787e-02, -2.9069e-02,\n",
      "          1.3736e-01,  9.6763e-02,  1.5297e-02,  2.2610e-02, -1.2748e-01,\n",
      "          8.1563e-02, -3.1703e-02,  1.3077e-01,  8.3275e-02,  1.4336e-01,\n",
      "         -1.1974e-01, -1.8543e-02,  5.7757e-02, -4.5999e-02, -9.6092e-02,\n",
      "          8.2660e-02,  4.7754e-02, -1.2657e-01,  6.5581e-02,  3.8522e-02,\n",
      "         -3.1760e-02,  5.3705e-02, -5.8345e-02, -8.3644e-04,  8.5337e-02,\n",
      "         -9.6669e-02, -6.3976e-02,  1.1540e-01, -3.0182e-02, -3.3114e-03,\n",
      "          1.3365e-01,  1.2279e-01, -2.4554e-02]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0892, -0.0581,  0.0749,  0.0234, -0.0140,  0.0228, -0.0954, -0.1039,\n",
      "        -0.0156,  0.0663,  0.0332, -0.1100,  0.0803,  0.0492,  0.0258, -0.1123],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.1904e-02, -7.0044e-02, -4.3129e-02,  1.7917e-01,  1.6243e-01,\n",
      "         -1.4312e-01, -8.2843e-02,  1.4751e-01, -1.7827e-01,  2.2289e-01,\n",
      "          2.2751e-02,  1.8402e-01, -2.0844e-01, -2.0977e-01, -1.6503e-01,\n",
      "         -1.3516e-01],\n",
      "        [ 1.4439e-01, -1.4216e-01,  1.2686e-01, -1.1905e-02, -9.9333e-02,\n",
      "         -1.7065e-01,  1.0807e-01, -2.0110e-01,  1.7909e-01,  1.0765e-01,\n",
      "          2.1144e-02, -2.2659e-01,  1.7323e-01, -1.5236e-01, -1.0156e-01,\n",
      "         -1.0271e-01],\n",
      "        [ 8.4343e-02, -2.4414e-01, -1.7286e-01,  8.1440e-02, -1.3477e-02,\n",
      "         -2.0706e-01, -2.8913e-02, -1.3976e-01,  1.0963e-01,  1.9775e-01,\n",
      "          1.7767e-01,  8.0071e-03, -1.1384e-01,  3.6859e-02,  1.2737e-01,\n",
      "         -7.6600e-02],\n",
      "        [ 7.1820e-02, -2.1249e-01,  2.3373e-01,  1.2048e-01,  6.7070e-02,\n",
      "          9.5076e-02,  6.2683e-02,  2.2409e-01, -5.1221e-02,  3.4049e-03,\n",
      "         -2.1645e-01, -2.3982e-01,  6.8809e-02,  2.1707e-01,  2.3294e-01,\n",
      "         -2.0967e-01],\n",
      "        [ 1.7645e-01, -7.0293e-02,  1.1419e-01,  1.6789e-01, -1.1028e-01,\n",
      "          1.1085e-01,  3.5499e-02, -3.6532e-02, -2.3556e-01,  1.3979e-01,\n",
      "         -2.1069e-01, -1.8384e-01, -1.1131e-01,  2.0004e-01,  3.8688e-02,\n",
      "         -7.0737e-02],\n",
      "        [-5.4514e-02,  2.2133e-01, -2.0719e-01, -1.4183e-01, -1.5580e-01,\n",
      "         -2.2996e-01,  6.0350e-02, -2.1601e-01,  8.3598e-02, -1.0129e-01,\n",
      "         -9.6434e-02, -2.1720e-01,  1.3338e-01, -1.5584e-01,  2.1613e-01,\n",
      "         -5.8358e-02],\n",
      "        [ 1.1150e-02,  8.7014e-02, -8.8637e-02,  4.6010e-02,  6.6553e-02,\n",
      "         -3.6312e-02, -1.4716e-01, -9.4261e-02,  2.4339e-01, -5.4947e-02,\n",
      "          2.4963e-01,  1.7957e-01, -1.1958e-01,  2.4881e-01, -1.7711e-01,\n",
      "          2.0010e-02],\n",
      "        [ 1.3757e-01, -2.0077e-01, -1.4797e-01, -1.6023e-01, -1.2886e-01,\n",
      "          1.2562e-01,  8.5300e-02, -1.1804e-01,  1.9188e-02, -2.2266e-01,\n",
      "         -1.1059e-01,  3.5972e-02,  8.8086e-02, -1.3772e-02,  1.7488e-01,\n",
      "         -3.2731e-02],\n",
      "        [ 1.2807e-01,  1.6703e-01, -1.8984e-01,  4.5102e-02, -1.8255e-01,\n",
      "          1.3933e-02,  1.8703e-01, -1.8440e-01,  9.7932e-02,  1.6330e-01,\n",
      "          1.6753e-01, -1.2569e-01, -1.3531e-01,  2.0562e-01,  9.3781e-02,\n",
      "         -4.6107e-02],\n",
      "        [ 8.3956e-02,  2.1600e-01, -4.0804e-02,  7.4953e-02,  1.7881e-01,\n",
      "          1.3635e-01,  1.4862e-02,  1.3724e-01,  2.3529e-01,  1.9623e-02,\n",
      "         -2.3388e-02, -1.5916e-01,  7.9381e-02,  1.6864e-01, -4.9435e-02,\n",
      "         -1.0315e-01],\n",
      "        [ 2.1753e-01,  1.3266e-01, -6.1568e-02, -1.5274e-01, -1.5135e-01,\n",
      "          2.4898e-01,  3.8826e-02,  1.7368e-01, -1.6662e-02, -1.1756e-02,\n",
      "          1.2088e-01,  2.4512e-01, -1.9570e-01,  5.8113e-02,  5.1901e-02,\n",
      "          2.4069e-01],\n",
      "        [-3.9983e-02,  1.0761e-01, -1.0170e-01, -7.2733e-02,  1.0729e-01,\n",
      "         -8.1340e-02,  2.0904e-01,  2.0291e-01, -8.7768e-02, -8.0493e-02,\n",
      "          1.8302e-01,  1.9412e-01, -2.1094e-01, -1.1681e-01, -1.6224e-01,\n",
      "          7.8482e-02],\n",
      "        [ 1.4200e-01, -8.4263e-02,  1.2554e-01,  8.2181e-02, -1.4608e-01,\n",
      "          3.2485e-06,  1.6876e-01,  2.2057e-01,  1.6851e-01, -1.8015e-01,\n",
      "         -2.0444e-01,  1.7066e-01,  1.6863e-01, -1.4063e-01,  6.8669e-02,\n",
      "          9.6033e-02],\n",
      "        [ 1.4237e-01,  1.6865e-01,  5.2928e-02,  1.0804e-01, -6.5921e-02,\n",
      "         -9.7858e-02,  9.8214e-02, -2.1597e-01, -9.8606e-03, -6.1438e-02,\n",
      "          2.9044e-02,  1.4782e-01,  1.3134e-01,  1.2881e-01, -4.6190e-02,\n",
      "          2.2133e-01],\n",
      "        [-3.6049e-02,  1.3373e-01, -1.8249e-01, -1.9985e-01, -3.9068e-02,\n",
      "          2.1906e-01, -1.0278e-01, -2.0053e-01,  1.7096e-01, -1.8170e-01,\n",
      "         -1.0667e-01, -1.5259e-01, -1.5471e-01, -7.2724e-02,  1.8179e-01,\n",
      "         -2.4845e-01],\n",
      "        [-2.0178e-01, -2.9602e-02, -2.3026e-01, -4.9175e-02,  1.6983e-01,\n",
      "          1.9155e-01,  2.0172e-02,  4.0213e-02,  6.7184e-02,  1.6480e-01,\n",
      "          1.1722e-01, -8.5382e-02, -2.0741e-01, -6.2515e-02,  1.9371e-01,\n",
      "          2.4862e-01]], device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1710, -0.1168, -0.1709,  0.0403, -0.1229, -0.1002,  0.0487,  0.1305,\n",
      "         0.2047, -0.2488, -0.0581, -0.1632,  0.0096, -0.1603, -0.2170,  0.1656],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1567, -0.0589, -0.1724, -0.2424,  0.1440,  0.1865, -0.1079, -0.1703,\n",
      "         -0.0398, -0.2089, -0.1907,  0.1419, -0.1922,  0.0765, -0.1941,  0.1009],\n",
      "        [-0.0910, -0.0310,  0.1661,  0.0036,  0.0989,  0.1687, -0.2203, -0.1049,\n",
      "          0.0943,  0.2175, -0.2138, -0.0857,  0.2287,  0.1453, -0.0514,  0.1281]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0619, 0.2398], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum())\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(256.6693, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4736, -0.2272, -0.9766,  0.0770,  0.5192, -0.5376, -1.7196,  1.1690,\n",
       "          0.6373,  0.6492],\n",
       "        [ 0.7956,  0.9717,  0.9515, -0.6368,  0.3135, -0.7557,  0.5723,  0.1617,\n",
       "         -0.6741,  0.0995],\n",
       "        [ 0.7018,  0.3282,  1.0309, -0.9190,  0.6788, -0.2095, -0.3714,  1.7240,\n",
       "          0.6228,  0.6429],\n",
       "        [-1.3614,  0.5443,  0.7771,  0.0175,  0.2961, -1.5920, -1.8737,  1.0537,\n",
       "          0.2269,  0.0478],\n",
       "        [ 1.3284,  0.4488, -0.4129, -0.5439,  0.7912, -0.6398, -1.2722,  0.7707,\n",
       "         -0.0897,  0.3950],\n",
       "        [-0.1995,  0.4182,  0.7557,  0.2058, -0.5340, -0.5134, -0.2542,  0.0318,\n",
       "         -0.6629, -1.2671],\n",
       "        [ 0.1741, -0.1415,  1.5415, -0.5425,  0.8440, -1.1065,  0.3004,  0.8632,\n",
       "          0.0292, -0.5559],\n",
       "        [ 0.4454, -0.1149,  2.1670, -0.5932,  0.8308,  0.4289, -1.6735, -1.6040,\n",
       "          1.8533,  1.0629],\n",
       "        [ 0.3557, -1.4769,  2.3685, -0.1974,  1.0292, -1.7125, -3.3732,  1.7291,\n",
       "          0.3478, -0.5429],\n",
       "        [-0.3506, -0.1536,  0.7840, -0.1561, -0.2519,  0.4076, -1.6785,  1.0301,\n",
       "         -1.9287,  0.4659]], device='cuda:1', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-32.7386, device='cuda:1', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0522, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.0478, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(1.7943, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.5874, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(-0.3179, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "tensor(0.3017, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 7.4140e-03, -7.6523e-03,  2.6040e-02,  6.9558e-02, -1.2833e-01,\n",
      "         -9.9794e-02, -7.9398e-03,  7.1437e-02, -1.2046e-01, -3.7486e-02,\n",
      "          1.4243e-01,  9.8834e-04, -1.3634e-01,  9.3380e-02, -1.9929e-02,\n",
      "         -1.2786e-01, -1.8433e-02,  4.2662e-03,  1.2799e-01, -7.4294e-02,\n",
      "         -7.8911e-02, -1.2994e-01,  3.3020e-02, -1.3719e-01, -1.2964e-02,\n",
      "         -1.3480e-01, -1.4104e-01, -4.2184e-02,  1.0376e-01, -2.7937e-02,\n",
      "         -2.1377e-02,  2.2828e-02,  1.4262e-01,  1.7067e-02, -1.1378e-01,\n",
      "         -3.0418e-02, -1.4453e-02, -1.2073e-01,  8.1322e-03, -1.3574e-01,\n",
      "          7.5421e-02, -2.6592e-02, -2.1529e-02,  5.7171e-02,  4.1748e-03,\n",
      "         -4.5985e-02,  8.6673e-02, -6.6865e-02],\n",
      "        [ 8.4426e-02, -7.4978e-02,  7.5471e-02, -5.3892e-02, -8.1554e-02,\n",
      "         -3.1228e-02, -1.4062e-01, -1.3022e-01,  1.0299e-03,  5.5547e-02,\n",
      "         -6.2940e-02,  1.3119e-01, -1.3844e-02, -1.0840e-01,  8.6804e-02,\n",
      "         -4.1381e-02, -6.3230e-02,  1.0706e-01,  2.8370e-03, -3.3474e-02,\n",
      "          3.6808e-02, -7.0578e-02, -9.0819e-02,  5.0296e-02,  8.1819e-02,\n",
      "         -1.3213e-01, -8.8082e-02,  1.2371e-02, -1.0009e-01,  5.1196e-02,\n",
      "         -1.1891e-01, -4.9972e-02,  2.9903e-02, -4.9752e-02, -1.1024e-01,\n",
      "          1.1830e-01,  1.2243e-01,  6.1501e-02, -6.3332e-02, -9.9556e-02,\n",
      "          2.1602e-02,  7.3176e-02, -9.6596e-02,  3.9171e-02, -1.4461e-01,\n",
      "          4.3547e-02, -8.1221e-02, -2.1138e-02],\n",
      "        [ 8.5973e-02, -1.9826e-03, -9.5195e-02,  9.3531e-02,  1.1092e-01,\n",
      "          5.6915e-02,  6.1626e-02,  7.8410e-02, -3.0160e-02, -8.5098e-02,\n",
      "          9.0697e-02, -4.9466e-02,  9.6857e-02, -2.8436e-02,  5.2782e-02,\n",
      "         -1.1515e-01, -1.3550e-01, -1.2727e-01, -1.0898e-01,  6.4811e-02,\n",
      "          8.5922e-02,  5.0255e-03, -1.3153e-01, -1.2090e-01, -9.7083e-02,\n",
      "          1.2377e-01, -1.2635e-01,  9.6114e-02, -6.1329e-02,  1.0615e-01,\n",
      "          1.0089e-01, -9.9645e-02, -1.2957e-01,  9.7820e-02, -1.3202e-01,\n",
      "          9.6816e-02, -9.9358e-02, -4.5973e-02,  5.0081e-02, -1.1303e-01,\n",
      "         -1.2860e-01,  2.8984e-02, -1.2045e-01, -7.2263e-03, -5.5688e-02,\n",
      "          1.2858e-01, -9.6715e-02, -5.4127e-02],\n",
      "        [-9.6556e-02, -5.4488e-02, -8.0042e-02,  2.3985e-02,  9.7263e-02,\n",
      "          3.8630e-02, -9.9646e-02,  5.3706e-02,  1.0403e-02, -4.6939e-02,\n",
      "         -1.0510e-01,  1.0742e-01, -4.4893e-02, -4.7360e-02,  1.9722e-02,\n",
      "          2.1407e-02, -1.3775e-01,  7.9667e-02,  1.1133e-01, -1.2693e-01,\n",
      "          1.2984e-01,  9.8721e-02,  1.2565e-01,  3.1047e-02,  1.3233e-01,\n",
      "          3.3501e-02, -8.3031e-02, -6.4119e-02, -1.2009e-01, -2.5353e-02,\n",
      "          1.2865e-01,  9.3115e-02,  1.3079e-01,  4.3439e-02,  7.7359e-02,\n",
      "          2.0823e-03, -1.9939e-02,  1.2185e-01,  1.1484e-01, -1.0664e-01,\n",
      "          1.4000e-01, -5.9748e-02,  6.9348e-02, -1.1294e-01,  7.2549e-02,\n",
      "          3.0202e-02, -1.0516e-01, -5.1581e-03],\n",
      "        [-8.4950e-02, -1.2088e-02,  1.2075e-01, -1.3321e-01, -1.3720e-01,\n",
      "         -1.4051e-01, -3.2327e-02, -4.1892e-02,  8.4923e-02,  4.8721e-03,\n",
      "         -1.0136e-01,  6.4776e-02,  1.3332e-02,  1.3096e-01, -6.9215e-02,\n",
      "         -1.0038e-01, -4.1847e-02,  5.5989e-02, -5.0896e-02,  1.0489e-01,\n",
      "         -1.0879e-01, -2.3677e-02,  6.0534e-02,  3.4223e-02,  1.4022e-01,\n",
      "         -1.4115e-01,  2.2672e-02, -1.3445e-01, -9.9486e-02,  1.2929e-01,\n",
      "         -9.7489e-02,  2.8307e-02,  4.0281e-02, -2.9202e-02, -1.2555e-01,\n",
      "         -3.6264e-02, -1.7374e-02, -5.6999e-02,  1.3546e-01, -7.7008e-03,\n",
      "          4.7463e-02, -1.0412e-01, -1.7030e-02, -2.9111e-02,  1.1522e-01,\n",
      "         -1.1576e-01, -1.0599e-01,  9.3285e-02],\n",
      "        [ 1.0314e-01,  1.4952e-02, -7.5521e-02, -1.2684e-01, -1.1060e-01,\n",
      "          6.4933e-02, -2.6360e-02, -5.7213e-02,  1.0422e-02, -6.4767e-03,\n",
      "         -5.3938e-02, -2.1373e-02,  8.1209e-02,  7.4083e-02, -9.7400e-02,\n",
      "          1.0170e-01, -4.3055e-02,  9.6709e-02,  1.1520e-01,  2.3366e-02,\n",
      "          1.4163e-01,  1.8015e-02, -1.2553e-01, -6.7385e-02, -4.1921e-02,\n",
      "         -4.5716e-02, -8.0002e-02,  3.7081e-02,  1.1301e-01, -9.5849e-02,\n",
      "         -1.6198e-02,  1.2349e-02, -2.2310e-02,  9.5407e-02,  1.9617e-02,\n",
      "          4.6303e-02, -1.0795e-03,  9.4293e-02,  2.8443e-02, -7.6565e-02,\n",
      "         -4.0732e-02,  1.1090e-01,  1.3747e-01,  4.6087e-04,  3.8640e-02,\n",
      "          4.1756e-02, -8.8591e-03,  2.9803e-02],\n",
      "        [-1.4301e-01,  7.9476e-02, -5.7354e-02, -4.9802e-02,  9.1106e-02,\n",
      "          5.9815e-02,  6.3615e-02, -7.4812e-02, -9.5312e-02, -8.3985e-02,\n",
      "         -1.1624e-01, -2.5103e-03, -1.2518e-01, -2.3976e-03, -9.8238e-02,\n",
      "          7.5819e-02,  2.9721e-02, -1.2179e-01,  7.4048e-02,  8.3834e-02,\n",
      "          1.2343e-01,  5.0092e-02, -7.2980e-02,  9.1258e-02,  1.0238e-01,\n",
      "         -3.4393e-02, -5.8907e-02, -9.7940e-02,  1.0730e-02,  1.4354e-01,\n",
      "          4.9049e-02, -2.8151e-02, -1.1978e-01,  7.9386e-02,  3.8701e-02,\n",
      "         -2.9005e-02,  9.5807e-02, -1.2105e-01,  4.1059e-02, -9.9592e-02,\n",
      "         -4.2529e-04, -1.3402e-01,  1.3532e-02, -4.8093e-02,  9.1173e-02,\n",
      "          1.2586e-01,  1.2066e-01, -9.9139e-02],\n",
      "        [-1.0975e-01,  6.4674e-02,  1.2999e-01,  1.2425e-01, -2.1597e-02,\n",
      "         -1.1003e-01,  1.3938e-01, -6.9742e-02,  2.4024e-04, -8.4648e-02,\n",
      "          3.0233e-02, -6.6770e-02,  8.6995e-02,  9.5554e-02, -7.2560e-03,\n",
      "          8.6257e-02,  6.6932e-02,  1.3595e-01, -1.4818e-02, -1.6622e-02,\n",
      "          1.0912e-01,  1.3961e-01,  1.0159e-01, -1.3510e-01,  7.8833e-02,\n",
      "         -7.8974e-02, -5.6006e-03,  8.9912e-02,  1.3749e-01, -7.6836e-02,\n",
      "         -1.2432e-01,  8.0760e-02,  1.0153e-01,  1.2896e-01,  5.7372e-02,\n",
      "          1.2243e-01,  1.8482e-02, -1.4154e-01, -4.7730e-02, -3.1011e-02,\n",
      "          1.2585e-01,  5.7776e-02,  1.1647e-01,  1.2105e-01, -1.6930e-02,\n",
      "         -1.3005e-01, -4.2050e-02, -9.4749e-02],\n",
      "        [ 1.1174e-01, -9.2512e-02, -6.3975e-02, -7.7950e-02,  3.7734e-02,\n",
      "          9.6408e-02, -7.0462e-02, -1.0235e-02, -6.5406e-02, -2.9248e-02,\n",
      "          6.4948e-02,  1.3974e-01, -1.2065e-01, -3.7196e-02,  7.7110e-02,\n",
      "          1.2895e-01, -1.0479e-02, -7.5124e-02, -2.3662e-02, -1.4308e-01,\n",
      "          7.1283e-02,  1.3436e-01, -7.1323e-02, -2.3600e-02, -1.2185e-01,\n",
      "         -3.7039e-02, -1.4896e-02,  9.2262e-03, -1.0372e-01, -3.0816e-02,\n",
      "         -7.0093e-02, -4.3165e-02,  1.9346e-02, -1.3781e-01, -3.4952e-02,\n",
      "         -8.6303e-02, -1.0855e-01, -6.5078e-02, -1.1368e-01,  1.0123e-01,\n",
      "          1.4462e-01, -1.2698e-01,  3.2943e-02,  1.0798e-01,  5.6156e-02,\n",
      "          3.6430e-02, -6.8071e-02,  2.4779e-02],\n",
      "        [ 9.0176e-03, -7.7586e-02,  9.8928e-02,  3.4246e-02, -1.2331e-01,\n",
      "          3.7359e-02,  1.3511e-01,  7.1854e-03, -1.5914e-02,  7.6924e-02,\n",
      "          8.4626e-02,  5.6035e-02, -2.7964e-02,  1.4371e-01,  1.2146e-01,\n",
      "          2.0930e-02, -5.7481e-02,  2.1376e-02,  1.0989e-01,  1.6544e-02,\n",
      "         -6.9669e-02,  1.1001e-01,  1.2580e-01,  6.5940e-02,  8.4641e-03,\n",
      "         -6.1653e-02, -1.3407e-01,  1.1766e-01,  1.1748e-01, -2.7214e-02,\n",
      "          1.9119e-02, -9.8443e-02,  1.6176e-02, -1.4218e-01, -1.0163e-01,\n",
      "          7.1854e-02, -1.0745e-01,  6.1966e-02,  1.0736e-01,  1.0640e-02,\n",
      "         -3.8423e-02,  4.5739e-02,  3.0340e-02,  5.6211e-02,  7.3887e-02,\n",
      "          1.1261e-01, -1.4422e-01,  1.1832e-01],\n",
      "        [-6.8057e-02,  1.0807e-01,  3.5784e-02,  8.2331e-02, -1.1536e-01,\n",
      "         -7.0246e-02,  1.0727e-01, -8.2333e-02, -5.2169e-02, -1.1280e-01,\n",
      "         -5.9116e-02, -3.8921e-02, -4.9972e-02,  9.4087e-02, -1.0973e-01,\n",
      "         -1.3438e-01,  8.3061e-02,  9.6523e-02,  1.0235e-01,  3.3688e-02,\n",
      "         -5.0732e-02,  3.6918e-02, -1.0683e-01, -3.1242e-03,  2.0453e-02,\n",
      "          3.9267e-02, -6.4923e-03,  2.5356e-02, -1.3858e-01, -1.3283e-01,\n",
      "         -5.6248e-02, -4.1670e-02, -9.8706e-02, -1.3326e-01, -9.7002e-02,\n",
      "         -1.0807e-01, -1.7577e-02,  8.4145e-02,  1.0255e-01, -5.8222e-02,\n",
      "         -4.9019e-02, -9.1347e-02, -1.0362e-01,  1.3697e-01,  3.0131e-02,\n",
      "          1.2028e-01, -1.1574e-01,  1.3247e-01],\n",
      "        [-1.3296e-01,  7.9767e-02, -6.3338e-02,  1.3375e-01,  7.1989e-02,\n",
      "          1.0208e-01,  9.0191e-02,  1.2154e-01, -5.3595e-02, -9.0063e-02,\n",
      "         -9.3745e-02, -1.3536e-02,  1.1573e-02,  4.3199e-02, -1.4170e-02,\n",
      "          1.5524e-02,  6.9096e-02,  5.6059e-03,  8.4845e-02, -5.1017e-02,\n",
      "         -8.2936e-02, -3.5506e-02, -3.0101e-02,  1.2073e-01, -4.4076e-02,\n",
      "          1.1293e-01, -4.3004e-02, -9.7579e-03, -8.4898e-02, -4.3363e-02,\n",
      "         -2.5479e-03, -2.4759e-02, -7.7220e-02, -9.2739e-02, -1.0664e-01,\n",
      "         -4.8106e-02,  6.1702e-02,  1.1362e-01, -2.7070e-02, -7.6533e-03,\n",
      "          3.8411e-02, -7.7586e-02,  1.4588e-03,  7.3289e-03, -1.1582e-01,\n",
      "         -1.1180e-01,  6.0108e-03, -4.9732e-02],\n",
      "        [ 2.4857e-02, -1.0124e-01,  8.8488e-02, -4.6802e-02, -8.4180e-02,\n",
      "          2.3855e-02, -3.6560e-02, -5.7984e-02, -5.4050e-02, -9.0457e-02,\n",
      "          5.8399e-02, -8.4546e-02,  8.5305e-03, -1.4196e-02, -7.4314e-02,\n",
      "          7.8016e-02, -9.2072e-02, -9.5166e-03,  1.3289e-01, -1.2605e-01,\n",
      "         -3.3949e-02, -1.2773e-01, -1.3952e-01,  2.4491e-02,  6.7239e-02,\n",
      "         -7.8229e-02, -1.0606e-01, -2.7381e-02,  6.8987e-02, -1.2090e-01,\n",
      "         -2.2104e-02, -3.4333e-02, -1.1206e-01, -1.0038e-01,  9.5974e-02,\n",
      "         -6.9447e-02, -1.3396e-01, -9.9188e-02, -3.6023e-02, -5.2951e-02,\n",
      "         -8.5075e-02,  4.9683e-02,  7.4278e-02, -1.3075e-01, -7.6135e-02,\n",
      "         -1.4633e-02, -1.2800e-01, -1.3022e-01],\n",
      "        [-9.4756e-02,  1.3221e-01,  4.2937e-02, -8.9568e-02,  3.6593e-02,\n",
      "          5.3869e-02, -1.1360e-01,  2.0087e-02,  7.2178e-02, -1.2076e-01,\n",
      "         -1.6691e-03, -1.3303e-01,  5.0622e-05,  1.3021e-01,  1.3040e-01,\n",
      "         -4.6304e-02, -2.6831e-02, -1.2353e-01, -8.9202e-02, -3.0451e-02,\n",
      "          1.1462e-01,  4.9638e-02, -4.9391e-02, -1.1286e-01, -1.3170e-01,\n",
      "         -1.1826e-01, -1.0001e-01, -1.4164e-01,  6.5450e-02,  5.1463e-02,\n",
      "         -1.7967e-02,  5.2459e-02, -1.2856e-01,  1.9635e-02, -8.0274e-02,\n",
      "          1.2712e-02,  5.8087e-02, -5.4533e-02, -4.8897e-02,  1.3077e-01,\n",
      "         -1.0980e-01, -1.1379e-01,  2.7180e-02,  7.3280e-02,  8.9294e-02,\n",
      "         -4.5704e-02,  1.4357e-01,  8.0324e-02],\n",
      "        [-1.0011e-01, -1.3820e-01,  9.9863e-02,  5.0541e-03,  3.6310e-02,\n",
      "          2.1388e-02,  1.1859e-01, -8.3894e-02,  7.5102e-03,  3.4868e-02,\n",
      "         -4.2613e-02,  7.2483e-02, -7.4348e-02, -3.3535e-02,  4.8327e-02,\n",
      "          3.7964e-02, -7.0151e-02, -1.0948e-01,  6.5958e-02, -1.1324e-01,\n",
      "          2.9114e-02, -1.2518e-01,  6.7653e-02,  2.5095e-02,  5.6181e-02,\n",
      "          5.7565e-02,  1.3532e-01,  5.6902e-02, -1.0314e-01, -5.4549e-02,\n",
      "         -8.4031e-02,  1.1867e-01, -6.9953e-02,  5.5225e-02, -3.1901e-03,\n",
      "          1.4074e-01,  1.9897e-02, -1.3376e-02,  4.7285e-02, -1.1446e-02,\n",
      "          1.2823e-01,  1.2334e-01, -9.0766e-02,  1.0178e-01, -2.7164e-02,\n",
      "          1.2178e-01,  1.2952e-01,  7.3603e-02],\n",
      "        [ 6.9799e-02, -7.1633e-02,  3.5656e-02,  1.2171e-01,  1.3784e-01,\n",
      "          1.1889e-01, -3.6291e-02, -8.9517e-02,  1.4207e-01,  9.9583e-02,\n",
      "         -1.3666e-01, -1.4370e-02, -1.3218e-02, -5.0786e-02, -2.9068e-02,\n",
      "          1.3736e-01,  9.6762e-02,  1.5297e-02,  2.2610e-02, -1.2748e-01,\n",
      "          8.1562e-02, -3.1703e-02,  1.3077e-01,  8.3275e-02,  1.4336e-01,\n",
      "         -1.1974e-01, -1.8543e-02,  5.7757e-02, -4.5999e-02, -9.6092e-02,\n",
      "          8.2660e-02,  4.7753e-02, -1.2657e-01,  6.5581e-02,  3.8521e-02,\n",
      "         -3.1759e-02,  5.3704e-02, -5.8344e-02, -8.3643e-04,  8.5337e-02,\n",
      "         -9.6669e-02, -6.3976e-02,  1.1540e-01, -3.0182e-02, -3.3114e-03,\n",
      "          1.3365e-01,  1.2279e-01, -2.4554e-02]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0887, -0.0586,  0.0744,  0.0239, -0.0145,  0.0223, -0.0959, -0.1044,\n",
      "        -0.0151,  0.0668,  0.0327, -0.1095,  0.0798,  0.0487,  0.0253, -0.1123],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0214, -0.0695, -0.0436,  0.1797,  0.1629, -0.1426, -0.0823,  0.1480,\n",
      "         -0.1788,  0.2224,  0.0233,  0.1845, -0.2079, -0.2093, -0.1645, -0.1352],\n",
      "        [ 0.1439, -0.1427,  0.1274, -0.0114, -0.0998, -0.1706,  0.1076, -0.2011,\n",
      "          0.1796,  0.1082,  0.0206, -0.2266,  0.1727, -0.1529, -0.1021, -0.1027],\n",
      "        [ 0.0838, -0.2446, -0.1724,  0.0819, -0.0140, -0.2076, -0.0289, -0.1403,\n",
      "          0.1101,  0.1983,  0.1772,  0.0075, -0.1143,  0.0369,  0.1269, -0.0766],\n",
      "        [ 0.0713, -0.2130,  0.2332,  0.1200,  0.0666,  0.0946,  0.0622,  0.2236,\n",
      "         -0.0507,  0.0039, -0.2169, -0.2403,  0.0683,  0.2166,  0.2324, -0.2097],\n",
      "        [ 0.1769, -0.0698,  0.1147,  0.1684, -0.1098,  0.1113,  0.0360, -0.0360,\n",
      "         -0.2351,  0.1403, -0.2102, -0.1838, -0.1113,  0.2005,  0.0392, -0.0707],\n",
      "        [-0.0540,  0.2218, -0.2072, -0.1413, -0.1553, -0.2300,  0.0603, -0.2160,\n",
      "          0.0841, -0.1008, -0.0959, -0.2172,  0.1339, -0.1558,  0.2166, -0.0584],\n",
      "        [ 0.0117,  0.0875, -0.0881,  0.0465,  0.0671, -0.0358, -0.1467, -0.0938,\n",
      "          0.2439, -0.0554,  0.2501,  0.1801, -0.1191,  0.2493, -0.1766,  0.0200],\n",
      "        [ 0.1376, -0.2008, -0.1485, -0.1602, -0.1289,  0.1256,  0.0848, -0.1180,\n",
      "          0.0187, -0.2227, -0.1106,  0.0355,  0.0876, -0.0143,  0.1749, -0.0327],\n",
      "        [ 0.1276,  0.1665, -0.1903,  0.0446, -0.1831,  0.0134,  0.1865, -0.1849,\n",
      "          0.0974,  0.1628,  0.1670, -0.1262, -0.1358,  0.2051,  0.0933, -0.0461],\n",
      "        [ 0.0835,  0.2155, -0.0403,  0.0745,  0.1783,  0.1359,  0.0144,  0.1367,\n",
      "          0.2348,  0.0201, -0.0239, -0.1597,  0.0789,  0.1681, -0.0499, -0.1032],\n",
      "        [ 0.2175,  0.1332, -0.0611, -0.1527, -0.1508,  0.2490,  0.0393,  0.1737,\n",
      "         -0.0162, -0.0113,  0.1214,  0.2456, -0.1952,  0.0586,  0.0519,  0.2407],\n",
      "        [-0.0400,  0.1076, -0.1017, -0.0727,  0.1073, -0.0813,  0.2090,  0.2029,\n",
      "         -0.0878, -0.0805,  0.1830,  0.1941, -0.2109, -0.1168, -0.1622,  0.0785],\n",
      "        [ 0.1415, -0.0848,  0.1260,  0.0827, -0.1456, -0.0005,  0.1683,  0.2201,\n",
      "          0.1690, -0.1797, -0.2049,  0.1702,  0.1681, -0.1411,  0.0682,  0.0960],\n",
      "        [ 0.1424,  0.1681,  0.0524,  0.1075, -0.0664, -0.0979,  0.0982, -0.2160,\n",
      "         -0.0104, -0.0619,  0.0285,  0.1473,  0.1313,  0.1283, -0.0467,  0.2213],\n",
      "        [-0.0365,  0.1332, -0.1825, -0.2003, -0.0396,  0.2191, -0.1028, -0.2005,\n",
      "          0.1705, -0.1822, -0.1072, -0.1526, -0.1552, -0.0727,  0.1813, -0.2484],\n",
      "        [-0.2023, -0.0301, -0.2298, -0.0497,  0.1693,  0.1910,  0.0197,  0.0397,\n",
      "          0.0667,  0.1653,  0.1167, -0.0859, -0.2079, -0.0630,  0.1932,  0.2486]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1715, -0.1163, -0.1704,  0.0398, -0.1224, -0.0997,  0.0492,  0.1300,\n",
      "         0.2042, -0.2493, -0.0576, -0.1632,  0.0101, -0.1608, -0.2175,  0.1651],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1572, -0.0594, -0.1719, -0.2419,  0.1445,  0.1870, -0.1074, -0.1698,\n",
      "         -0.0393, -0.2084, -0.1902,  0.1419, -0.1917,  0.0770, -0.1936,  0.1014],\n",
      "        [-0.0915, -0.0305,  0.1656,  0.0031,  0.0984,  0.1682, -0.2208, -0.1054,\n",
      "          0.0938,  0.2170, -0.2143, -0.0857,  0.2282,  0.1448, -0.0519,  0.1276]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0624, 0.2393], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum())\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "final_model.module.freeze(module_name=\"predictor\")\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(207.7741, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5709e-01, -4.9432e-01, -8.0583e-01, -4.5443e-01, -1.2907e-01,\n",
       "          1.6342e-01,  2.6257e-01,  4.0090e-01,  1.0620e+00, -2.1962e-01],\n",
       "        [ 8.7164e-01,  1.3203e-01,  9.4832e-01,  8.6002e-02, -2.2500e-01,\n",
       "         -5.3908e-01, -1.5957e+00, -4.6577e-01, -8.0176e-01,  1.8494e+00],\n",
       "        [-1.0795e-01, -2.0285e+00,  1.2273e+00, -1.4995e-01,  4.4946e-01,\n",
       "         -7.1788e-01, -1.5552e-01,  7.4372e-01, -5.1485e-01,  3.7813e-01],\n",
       "        [ 4.8809e-01,  5.6596e-01,  1.0377e+00, -3.9848e-01, -5.3214e-01,\n",
       "         -6.4806e-01,  6.9967e-01,  1.3287e+00,  8.6062e-01,  4.3469e-01],\n",
       "        [ 7.0350e-01,  1.3099e+00,  3.5010e-01, -1.1539e+00,  2.0622e-01,\n",
       "          1.1206e+00,  1.0781e+00, -2.3437e-01, -8.5554e-01,  2.1002e-01],\n",
       "        [-1.1574e-01,  4.0096e-01,  2.3872e+00, -5.4562e-01, -4.1038e-01,\n",
       "          5.1674e-01,  2.4054e-01,  2.3169e+00,  7.0590e-01,  1.4846e+00],\n",
       "        [-2.7840e-01,  1.7006e-02,  4.1294e-01, -1.0329e+00,  2.2243e-01,\n",
       "          1.1384e-01, -4.3268e-01,  7.4192e-01,  1.2177e+00,  2.8935e+00],\n",
       "        [ 7.7926e-01, -3.3372e-01, -3.2451e-01, -1.1364e+00,  1.1880e+00,\n",
       "         -3.5168e-01, -1.7898e+00,  9.6548e-02,  2.6531e-01, -1.1448e+00],\n",
       "        [-3.3145e-01,  8.5022e-01,  1.8018e-01, -6.7215e-01,  1.2815e+00,\n",
       "          1.1853e+00,  1.9497e-01,  1.0350e-01,  1.0842e+00, -6.2637e-01],\n",
       "        [-9.1422e-01, -4.1187e-01, -1.3560e-04,  4.4970e-02, -1.0960e+00,\n",
       "         -1.2562e+00, -1.0163e-01,  1.4935e+00, -5.3634e-01,  2.3636e-01]],\n",
       "       device='cuda:1', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(65.1528, device='cuda:1', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0452, device='cuda:1') False\n",
      "tensor(-0.0513, device='cuda:1') False\n",
      "tensor(1.7778, device='cuda:1') False\n",
      "tensor(-0.5869, device='cuda:1') False\n",
      "tensor(-0.3179, device='cuda:1') False\n",
      "tensor(0.3017, device='cuda:1') False\n",
      "Parameter containing:\n",
      "tensor([[ 6.9140e-03, -7.1523e-03,  2.5539e-02,  7.0057e-02, -1.2782e-01,\n",
      "         -9.9294e-02, -7.4398e-03,  7.0937e-02, -1.1996e-01, -3.6986e-02,\n",
      "          1.4193e-01,  1.4883e-03, -1.3584e-01,  9.3879e-02, -2.0429e-02,\n",
      "         -1.2736e-01, -1.7933e-02,  4.7662e-03,  1.2749e-01, -7.4794e-02,\n",
      "         -7.9410e-02, -1.3044e-01,  3.2520e-02, -1.3769e-01, -1.2464e-02,\n",
      "         -1.3430e-01, -1.4154e-01, -4.1684e-02,  1.0426e-01, -2.8437e-02,\n",
      "         -2.0877e-02,  2.3328e-02,  1.4312e-01,  1.6566e-02, -1.1328e-01,\n",
      "         -2.9918e-02, -1.3953e-02, -1.2123e-01,  7.6322e-03, -1.3524e-01,\n",
      "          7.4920e-02, -2.7092e-02, -2.1028e-02,  5.6670e-02,  3.6748e-03,\n",
      "         -4.5485e-02,  8.7172e-02, -6.6364e-02],\n",
      "        [ 8.4926e-02, -7.4478e-02,  7.4970e-02, -5.4392e-02, -8.2054e-02,\n",
      "         -3.0728e-02, -1.4012e-01, -1.3072e-01,  5.2986e-04,  5.5047e-02,\n",
      "         -6.3439e-02,  1.3169e-01, -1.4344e-02, -1.0790e-01,  8.6304e-02,\n",
      "         -4.0880e-02, -6.2730e-02,  1.0756e-01,  2.3369e-03, -3.3974e-02,\n",
      "          3.7308e-02, -7.1077e-02, -9.0319e-02,  4.9795e-02,  8.2319e-02,\n",
      "         -1.3163e-01, -8.7582e-02,  1.1871e-02, -9.9591e-02,  5.0696e-02,\n",
      "         -1.1841e-01, -4.9471e-02,  3.0402e-02, -4.9252e-02, -1.0974e-01,\n",
      "          1.1780e-01,  1.2293e-01,  6.1000e-02, -6.3831e-02, -9.9055e-02,\n",
      "          2.1102e-02,  7.2675e-02, -9.7095e-02,  3.8671e-02, -1.4511e-01,\n",
      "          4.3046e-02, -8.0721e-02, -2.0638e-02],\n",
      "        [ 8.6472e-02, -1.4826e-03, -9.5694e-02,  9.4031e-02,  1.1142e-01,\n",
      "          5.7415e-02,  6.2126e-02,  7.7910e-02, -3.0660e-02, -8.4597e-02,\n",
      "          9.0197e-02, -4.8965e-02,  9.6356e-02, -2.7935e-02,  5.2282e-02,\n",
      "         -1.1465e-01, -1.3599e-01, -1.2677e-01, -1.0948e-01,  6.4311e-02,\n",
      "          8.6422e-02,  5.5255e-03, -1.3103e-01, -1.2140e-01, -9.6583e-02,\n",
      "          1.2427e-01, -1.2585e-01,  9.6614e-02, -6.0829e-02,  1.0565e-01,\n",
      "          1.0139e-01, -9.9144e-02, -1.2907e-01,  9.8319e-02, -1.3252e-01,\n",
      "          9.7316e-02, -9.8858e-02, -4.6473e-02,  4.9581e-02, -1.1253e-01,\n",
      "         -1.2810e-01,  2.8484e-02, -1.2095e-01, -7.7263e-03, -5.6188e-02,\n",
      "          1.2908e-01, -9.6215e-02, -5.4627e-02],\n",
      "        [-9.6056e-02, -5.3988e-02, -7.9542e-02,  2.3485e-02,  9.7762e-02,\n",
      "          3.8130e-02, -9.9146e-02,  5.4206e-02,  9.9028e-03, -4.6438e-02,\n",
      "         -1.0460e-01,  1.0792e-01, -4.4393e-02, -4.6860e-02,  2.0222e-02,\n",
      "          2.0907e-02, -1.3824e-01,  7.9167e-02,  1.1083e-01, -1.2643e-01,\n",
      "          1.3033e-01,  9.9220e-02,  1.2615e-01,  3.0547e-02,  1.3283e-01,\n",
      "          3.4000e-02, -8.2530e-02, -6.3618e-02, -1.2059e-01, -2.5852e-02,\n",
      "          1.2914e-01,  9.3614e-02,  1.3129e-01,  4.3939e-02,  7.6858e-02,\n",
      "          1.5823e-03, -2.0439e-02,  1.2135e-01,  1.1534e-01, -1.0614e-01,\n",
      "          1.4050e-01, -6.0248e-02,  6.8848e-02, -1.1343e-01,  7.3049e-02,\n",
      "          3.0702e-02, -1.0566e-01, -5.6581e-03],\n",
      "        [-8.5450e-02, -1.2588e-02,  1.2025e-01, -1.3271e-01, -1.3770e-01,\n",
      "         -1.4001e-01, -3.2827e-02, -4.2392e-02,  8.4422e-02,  4.3721e-03,\n",
      "         -1.0186e-01,  6.4275e-02,  1.3832e-02,  1.3046e-01, -6.9714e-02,\n",
      "         -9.9881e-02, -4.1347e-02,  5.6488e-02, -5.0396e-02,  1.0539e-01,\n",
      "         -1.0929e-01, -2.4177e-02,  6.0034e-02,  3.4723e-02,  1.3972e-01,\n",
      "         -1.4065e-01,  2.2172e-02, -1.3495e-01, -9.8986e-02,  1.2979e-01,\n",
      "         -9.7989e-02,  2.8807e-02,  3.9781e-02, -2.8702e-02, -1.2505e-01,\n",
      "         -3.5764e-02, -1.6874e-02, -5.7499e-02,  1.3496e-01, -8.2007e-03,\n",
      "          4.6962e-02, -1.0362e-01, -1.6530e-02, -2.9611e-02,  1.1472e-01,\n",
      "         -1.1626e-01, -1.0549e-01,  9.3784e-02],\n",
      "        [ 1.0364e-01,  1.4452e-02, -7.6021e-02, -1.2634e-01, -1.1110e-01,\n",
      "          6.4432e-02, -2.5860e-02, -5.7713e-02,  9.9215e-03, -6.9766e-03,\n",
      "         -5.3438e-02, -2.0873e-02,  8.0708e-02,  7.4582e-02, -9.7899e-02,\n",
      "          1.0120e-01, -4.2555e-02,  9.7209e-02,  1.1470e-01,  2.2866e-02,\n",
      "          1.4213e-01,  1.7515e-02, -1.2603e-01, -6.7884e-02, -4.1421e-02,\n",
      "         -4.5215e-02, -7.9502e-02,  3.7581e-02,  1.1251e-01, -9.6349e-02,\n",
      "         -1.5698e-02,  1.1849e-02, -2.2810e-02,  9.5907e-02,  1.9116e-02,\n",
      "          4.6802e-02, -1.5794e-03,  9.3792e-02,  2.7942e-02, -7.6064e-02,\n",
      "         -4.1232e-02,  1.1140e-01,  1.3797e-01, -3.9131e-05,  3.8140e-02,\n",
      "          4.1256e-02, -8.3591e-03,  2.9303e-02],\n",
      "        [-1.4351e-01,  7.9976e-02, -5.7853e-02, -4.9302e-02,  9.0606e-02,\n",
      "          5.9315e-02,  6.4115e-02, -7.5312e-02, -9.4812e-02, -8.3485e-02,\n",
      "         -1.1674e-01, -2.0103e-03, -1.2568e-01, -1.8976e-03, -9.8737e-02,\n",
      "          7.5318e-02,  3.0221e-02, -1.2129e-01,  7.3548e-02,  8.3333e-02,\n",
      "          1.2393e-01,  5.0592e-02, -7.2479e-02,  9.0757e-02,  1.0288e-01,\n",
      "         -3.3893e-02, -5.9407e-02, -9.8439e-02,  1.0230e-02,  1.4304e-01,\n",
      "          4.9548e-02, -2.8651e-02, -1.1928e-01,  7.8886e-02,  3.8201e-02,\n",
      "         -2.8505e-02,  9.6306e-02, -1.2055e-01,  4.0559e-02, -9.9092e-02,\n",
      "         -9.2528e-04, -1.3351e-01,  1.4031e-02, -4.8593e-02,  9.0672e-02,\n",
      "          1.2536e-01,  1.2116e-01, -9.8639e-02],\n",
      "        [-1.0925e-01,  6.4174e-02,  1.3049e-01,  1.2475e-01, -2.2097e-02,\n",
      "         -1.1053e-01,  1.3988e-01, -7.0241e-02, -2.5973e-04, -8.5147e-02,\n",
      "          2.9733e-02, -6.6269e-02,  8.6495e-02,  9.6053e-02, -7.7559e-03,\n",
      "          8.5757e-02,  6.7432e-02,  1.3545e-01, -1.5318e-02, -1.7122e-02,\n",
      "          1.0962e-01,  1.3911e-01,  1.0109e-01, -1.3560e-01,  7.9333e-02,\n",
      "         -7.8474e-02, -5.1006e-03,  9.0412e-02,  1.3699e-01, -7.7336e-02,\n",
      "         -1.2382e-01,  8.0260e-02,  1.0103e-01,  1.2946e-01,  5.6872e-02,\n",
      "          1.2293e-01,  1.7982e-02, -1.4104e-01, -4.8230e-02, -3.1511e-02,\n",
      "          1.2535e-01,  5.7276e-02,  1.1697e-01,  1.2055e-01, -1.7430e-02,\n",
      "         -1.3055e-01, -4.1550e-02, -9.4249e-02],\n",
      "        [ 1.1224e-01, -9.2012e-02, -6.3475e-02, -7.8449e-02,  3.8234e-02,\n",
      "          9.6907e-02, -6.9962e-02, -9.7350e-03, -6.5906e-02, -2.8748e-02,\n",
      "          6.5448e-02,  1.4024e-01, -1.2015e-01, -3.6696e-02,  7.7609e-02,\n",
      "          1.2845e-01, -1.0979e-02, -7.5623e-02, -2.4162e-02, -1.4258e-01,\n",
      "          7.1782e-02,  1.3486e-01, -7.0823e-02, -2.4100e-02, -1.2135e-01,\n",
      "         -3.6539e-02, -1.4396e-02,  9.7261e-03, -1.0322e-01, -3.1316e-02,\n",
      "         -6.9592e-02, -4.2665e-02,  1.9845e-02, -1.3731e-01, -3.5451e-02,\n",
      "         -8.6802e-02, -1.0905e-01, -6.5577e-02, -1.1318e-01,  1.0173e-01,\n",
      "          1.4512e-01, -1.2748e-01,  3.2443e-02,  1.0748e-01,  5.5656e-02,\n",
      "          3.6930e-02, -6.8570e-02,  2.4279e-02],\n",
      "        [ 8.5176e-03, -7.8086e-02,  9.8427e-02,  3.3746e-02, -1.2381e-01,\n",
      "          3.7859e-02,  1.3461e-01,  7.6854e-03, -1.5414e-02,  7.6424e-02,\n",
      "          8.5126e-02,  5.5534e-02, -2.7464e-02,  1.4321e-01,  1.2196e-01,\n",
      "          2.1430e-02, -5.6980e-02,  2.1876e-02,  1.1039e-01,  1.7044e-02,\n",
      "         -7.0168e-02,  1.0951e-01,  1.2530e-01,  6.6440e-02,  7.9641e-03,\n",
      "         -6.2153e-02, -1.3457e-01,  1.1716e-01,  1.1798e-01, -2.6714e-02,\n",
      "          1.8619e-02, -9.7942e-02,  1.5676e-02, -1.4167e-01, -1.0113e-01,\n",
      "          7.2354e-02, -1.0695e-01,  6.1465e-02,  1.0786e-01,  1.0140e-02,\n",
      "         -3.8923e-02,  4.6239e-02,  3.0840e-02,  5.6711e-02,  7.3387e-02,\n",
      "          1.1211e-01, -1.4471e-01,  1.1882e-01],\n",
      "        [-6.8557e-02,  1.0757e-01,  3.5283e-02,  8.2831e-02, -1.1586e-01,\n",
      "         -7.0746e-02,  1.0677e-01, -8.2833e-02, -5.1669e-02, -1.1330e-01,\n",
      "         -5.8615e-02, -3.9421e-02, -4.9472e-02,  9.3586e-02, -1.1023e-01,\n",
      "         -1.3388e-01,  8.3560e-02,  9.7022e-02,  1.0285e-01,  3.4188e-02,\n",
      "         -5.1231e-02,  3.6417e-02, -1.0733e-01, -2.6242e-03,  1.9953e-02,\n",
      "          3.8767e-02, -6.9922e-03,  2.4856e-02, -1.3907e-01, -1.3233e-01,\n",
      "         -5.6747e-02, -4.2170e-02, -9.9205e-02, -1.3376e-01, -9.6502e-02,\n",
      "         -1.0757e-01, -1.8077e-02,  8.4644e-02,  1.0305e-01, -5.8722e-02,\n",
      "         -4.9519e-02, -9.0846e-02, -1.0311e-01,  1.3747e-01,  3.0631e-02,\n",
      "          1.1978e-01, -1.1524e-01,  1.3297e-01],\n",
      "        [-1.3345e-01,  7.9266e-02, -6.2838e-02,  1.3325e-01,  7.2489e-02,\n",
      "          1.0158e-01,  8.9691e-02,  1.2204e-01, -5.3095e-02, -9.0563e-02,\n",
      "         -9.3244e-02, -1.4036e-02,  1.1073e-02,  4.2699e-02, -1.3670e-02,\n",
      "          1.5024e-02,  6.8596e-02,  5.1058e-03,  8.5345e-02, -5.0516e-02,\n",
      "         -8.3435e-02, -3.5006e-02, -3.0601e-02,  1.2123e-01, -4.4576e-02,\n",
      "          1.1343e-01, -4.2503e-02, -9.2579e-03, -8.5398e-02, -4.2863e-02,\n",
      "         -3.0479e-03, -2.5259e-02, -7.7720e-02, -9.3238e-02, -1.0714e-01,\n",
      "         -4.8606e-02,  6.2202e-02,  1.1412e-01, -2.6570e-02, -7.1532e-03,\n",
      "          3.8911e-02, -7.7086e-02,  9.5883e-04,  7.8288e-03, -1.1531e-01,\n",
      "         -1.1230e-01,  5.5108e-03, -4.9231e-02],\n",
      "        [ 2.4357e-02, -1.0073e-01,  8.7988e-02, -4.6302e-02, -8.4679e-02,\n",
      "          2.3355e-02, -3.6059e-02, -5.8484e-02, -5.3550e-02, -8.9957e-02,\n",
      "          5.8898e-02, -8.4046e-02,  8.0304e-03, -1.3696e-02, -7.4813e-02,\n",
      "          7.8516e-02, -9.1572e-02, -9.0165e-03,  1.3239e-01, -1.2655e-01,\n",
      "         -3.3449e-02, -1.2723e-01, -1.3902e-01,  2.3991e-02,  6.7738e-02,\n",
      "         -7.7729e-02, -1.0656e-01, -2.7881e-02,  6.9487e-02, -1.2140e-01,\n",
      "         -2.1604e-02, -3.4833e-02, -1.1156e-01, -1.0088e-01,  9.5473e-02,\n",
      "         -6.8947e-02, -1.3346e-01, -9.9688e-02, -3.6523e-02, -5.2451e-02,\n",
      "         -8.5574e-02,  4.9183e-02,  7.4778e-02, -1.3125e-01, -7.6635e-02,\n",
      "         -1.5133e-02, -1.2750e-01, -1.2972e-01],\n",
      "        [-9.4256e-02,  1.3271e-01,  4.2437e-02, -9.0067e-02,  3.6093e-02,\n",
      "          5.4368e-02, -1.1309e-01,  1.9587e-02,  7.1677e-02, -1.2026e-01,\n",
      "         -2.1691e-03, -1.3252e-01,  5.5062e-04,  1.3071e-01,  1.2990e-01,\n",
      "         -4.5804e-02, -2.6331e-02, -1.2303e-01, -8.9702e-02, -3.0951e-02,\n",
      "          1.1512e-01,  4.9137e-02, -4.8891e-02, -1.1336e-01, -1.3120e-01,\n",
      "         -1.1776e-01, -1.0051e-01, -1.4114e-01,  6.5950e-02,  5.0962e-02,\n",
      "         -1.7467e-02,  5.2959e-02, -1.2806e-01,  2.0135e-02, -7.9774e-02,\n",
      "          1.3212e-02,  5.8587e-02, -5.5033e-02, -4.9397e-02,  1.3127e-01,\n",
      "         -1.1030e-01, -1.1429e-01,  2.7680e-02,  7.2779e-02,  8.8794e-02,\n",
      "         -4.6204e-02,  1.4407e-01,  8.0824e-02],\n",
      "        [-9.9606e-02, -1.3770e-01,  9.9363e-02,  5.5540e-03,  3.5810e-02,\n",
      "          2.1888e-02,  1.1909e-01, -8.4394e-02,  7.0102e-03,  3.5368e-02,\n",
      "         -4.2113e-02,  7.1983e-02, -7.3848e-02, -3.3035e-02,  4.7827e-02,\n",
      "          3.8464e-02, -6.9651e-02, -1.0898e-01,  6.5457e-02, -1.1374e-01,\n",
      "          2.9614e-02, -1.2568e-01,  6.7153e-02,  2.4595e-02,  5.6681e-02,\n",
      "          5.7065e-02,  1.3482e-01,  5.6402e-02, -1.0264e-01, -5.5049e-02,\n",
      "         -8.3531e-02,  1.1817e-01, -7.0452e-02,  5.5724e-02, -2.6901e-03,\n",
      "          1.4124e-01,  2.0397e-02, -1.3876e-02,  4.6785e-02, -1.0946e-02,\n",
      "          1.2773e-01,  1.2284e-01, -9.1265e-02,  1.0128e-01, -2.7664e-02,\n",
      "          1.2128e-01,  1.3002e-01,  7.3102e-02],\n",
      "        [ 6.9798e-02, -7.1632e-02,  3.5656e-02,  1.2171e-01,  1.3784e-01,\n",
      "          1.1889e-01, -3.6291e-02, -8.9516e-02,  1.4207e-01,  9.9582e-02,\n",
      "         -1.3666e-01, -1.4370e-02, -1.3218e-02, -5.0786e-02, -2.9068e-02,\n",
      "          1.3736e-01,  9.6762e-02,  1.5297e-02,  2.2610e-02, -1.2748e-01,\n",
      "          8.1562e-02, -3.1703e-02,  1.3077e-01,  8.3274e-02,  1.4336e-01,\n",
      "         -1.1974e-01, -1.8543e-02,  5.7757e-02, -4.5998e-02, -9.6091e-02,\n",
      "          8.2660e-02,  4.7753e-02, -1.2656e-01,  6.5580e-02,  3.8521e-02,\n",
      "         -3.1759e-02,  5.3704e-02, -5.8344e-02, -8.3643e-04,  8.5337e-02,\n",
      "         -9.6668e-02, -6.3976e-02,  1.1540e-01, -3.0182e-02, -3.3114e-03,\n",
      "          1.3365e-01,  1.2279e-01, -2.4554e-02]], device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([ 0.0882, -0.0591,  0.0739,  0.0244, -0.0150,  0.0218, -0.0964, -0.1049,\n",
      "        -0.0146,  0.0673,  0.0322, -0.1090,  0.0793,  0.0482,  0.0248, -0.1123],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([[-0.0209, -0.0690, -0.0441,  0.1802,  0.1634, -0.1421, -0.0818,  0.1485,\n",
      "         -0.1793,  0.2219,  0.0238,  0.1850, -0.2074, -0.2088, -0.1640, -0.1352],\n",
      "        [ 0.1434, -0.1432,  0.1279, -0.0109, -0.1003, -0.1706,  0.1071, -0.2011,\n",
      "          0.1801,  0.1087,  0.0201, -0.2266,  0.1722, -0.1534, -0.1026, -0.1027],\n",
      "        [ 0.0833, -0.2451, -0.1719,  0.0824, -0.0145, -0.2081, -0.0289, -0.1408,\n",
      "          0.1106,  0.1988,  0.1767,  0.0070, -0.1148,  0.0369,  0.1264, -0.0766],\n",
      "        [ 0.0708, -0.2135,  0.2327,  0.1195,  0.0661,  0.0941,  0.0617,  0.2231,\n",
      "         -0.0502,  0.0044, -0.2174, -0.2408,  0.0678,  0.2161,  0.2319, -0.2097],\n",
      "        [ 0.1774, -0.0693,  0.1152,  0.1689, -0.1093,  0.1118,  0.0365, -0.0355,\n",
      "         -0.2346,  0.1408, -0.2097, -0.1838, -0.1113,  0.2010,  0.0397, -0.0707],\n",
      "        [-0.0535,  0.2223, -0.2072, -0.1408, -0.1548, -0.2300,  0.0603, -0.2160,\n",
      "          0.0846, -0.1003, -0.0954, -0.2172,  0.1344, -0.1558,  0.2171, -0.0584],\n",
      "        [ 0.0122,  0.0880, -0.0876,  0.0470,  0.0676, -0.0353, -0.1462, -0.0933,\n",
      "          0.2444, -0.0559,  0.2506,  0.1806, -0.1186,  0.2498, -0.1761,  0.0200],\n",
      "        [ 0.1376, -0.2008, -0.1490, -0.1602, -0.1289,  0.1256,  0.0843, -0.1180,\n",
      "          0.0182, -0.2227, -0.1106,  0.0350,  0.0871, -0.0148,  0.1749, -0.0327],\n",
      "        [ 0.1271,  0.1660, -0.1908,  0.0441, -0.1836,  0.0129,  0.1860, -0.1854,\n",
      "          0.0969,  0.1623,  0.1665, -0.1267, -0.1363,  0.2046,  0.0928, -0.0461],\n",
      "        [ 0.0830,  0.2150, -0.0398,  0.0740,  0.1778,  0.1354,  0.0139,  0.1362,\n",
      "          0.2343,  0.0206, -0.0244, -0.1602,  0.0784,  0.1676, -0.0504, -0.1032],\n",
      "        [ 0.2175,  0.1337, -0.0606, -0.1527, -0.1503,  0.2490,  0.0398,  0.1737,\n",
      "         -0.0157, -0.0108,  0.1219,  0.2461, -0.1947,  0.0591,  0.0519,  0.2407],\n",
      "        [-0.0400,  0.1076, -0.1017, -0.0727,  0.1073, -0.0813,  0.2090,  0.2029,\n",
      "         -0.0878, -0.0805,  0.1830,  0.1941, -0.2109, -0.1168, -0.1622,  0.0785],\n",
      "        [ 0.1410, -0.0853,  0.1265,  0.0832, -0.1451, -0.0010,  0.1678,  0.2196,\n",
      "          0.1695, -0.1792, -0.2054,  0.1697,  0.1676, -0.1416,  0.0677,  0.0960],\n",
      "        [ 0.1424,  0.1676,  0.0519,  0.1070, -0.0669, -0.0979,  0.0982, -0.2160,\n",
      "         -0.0109, -0.0624,  0.0280,  0.1468,  0.1313,  0.1278, -0.0472,  0.2213],\n",
      "        [-0.0370,  0.1327, -0.1825, -0.2008, -0.0401,  0.2191, -0.1028, -0.2005,\n",
      "          0.1700, -0.1827, -0.1077, -0.1526, -0.1557, -0.0727,  0.1808, -0.2484],\n",
      "        [-0.2028, -0.0306, -0.2293, -0.0502,  0.1688,  0.1905,  0.0192,  0.0392,\n",
      "          0.0662,  0.1658,  0.1162, -0.0864, -0.2084, -0.0635,  0.1927,  0.2486]],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([ 0.1720, -0.1158, -0.1699,  0.0393, -0.1219, -0.0992,  0.0497,  0.1295,\n",
      "         0.2037, -0.2498, -0.0571, -0.1632,  0.0106, -0.1613, -0.2180,  0.1646],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([[ 0.1577, -0.0599, -0.1714, -0.2414,  0.1450,  0.1875, -0.1069, -0.1693,\n",
      "         -0.0388, -0.2079, -0.1897,  0.1419, -0.1912,  0.0775, -0.1931,  0.1019],\n",
      "        [-0.0920, -0.0300,  0.1651,  0.0026,  0.0979,  0.1677, -0.2213, -0.1059,\n",
      "          0.0933,  0.2165, -0.2148, -0.0857,  0.2277,  0.1443, -0.0524,  0.1271]],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([0.0629, 0.2388], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0452, device='cuda:1') False\n",
      "tensor(-0.0513, device='cuda:1') False\n",
      "tensor(1.7778, device='cuda:1') False\n",
      "tensor(-0.5869, device='cuda:1') False\n",
      "tensor(-0.3179, device='cuda:1') False\n",
      "tensor(0.3017, device='cuda:1') False\n",
      "Parameter containing:\n",
      "tensor([[ 6.9140e-03, -7.1523e-03,  2.5539e-02,  7.0057e-02, -1.2782e-01,\n",
      "         -9.9294e-02, -7.4398e-03,  7.0937e-02, -1.1996e-01, -3.6986e-02,\n",
      "          1.4193e-01,  1.4883e-03, -1.3584e-01,  9.3879e-02, -2.0429e-02,\n",
      "         -1.2736e-01, -1.7933e-02,  4.7662e-03,  1.2749e-01, -7.4794e-02,\n",
      "         -7.9410e-02, -1.3044e-01,  3.2520e-02, -1.3769e-01, -1.2464e-02,\n",
      "         -1.3430e-01, -1.4154e-01, -4.1684e-02,  1.0426e-01, -2.8437e-02,\n",
      "         -2.0877e-02,  2.3328e-02,  1.4312e-01,  1.6566e-02, -1.1328e-01,\n",
      "         -2.9918e-02, -1.3953e-02, -1.2123e-01,  7.6322e-03, -1.3524e-01,\n",
      "          7.4920e-02, -2.7092e-02, -2.1028e-02,  5.6670e-02,  3.6748e-03,\n",
      "         -4.5485e-02,  8.7172e-02, -6.6364e-02],\n",
      "        [ 8.4926e-02, -7.4478e-02,  7.4970e-02, -5.4392e-02, -8.2054e-02,\n",
      "         -3.0728e-02, -1.4012e-01, -1.3072e-01,  5.2986e-04,  5.5047e-02,\n",
      "         -6.3439e-02,  1.3169e-01, -1.4344e-02, -1.0790e-01,  8.6304e-02,\n",
      "         -4.0880e-02, -6.2730e-02,  1.0756e-01,  2.3369e-03, -3.3974e-02,\n",
      "          3.7308e-02, -7.1077e-02, -9.0319e-02,  4.9795e-02,  8.2319e-02,\n",
      "         -1.3163e-01, -8.7582e-02,  1.1871e-02, -9.9591e-02,  5.0696e-02,\n",
      "         -1.1841e-01, -4.9471e-02,  3.0402e-02, -4.9252e-02, -1.0974e-01,\n",
      "          1.1780e-01,  1.2293e-01,  6.1000e-02, -6.3831e-02, -9.9055e-02,\n",
      "          2.1102e-02,  7.2675e-02, -9.7095e-02,  3.8671e-02, -1.4511e-01,\n",
      "          4.3046e-02, -8.0721e-02, -2.0638e-02],\n",
      "        [ 8.6472e-02, -1.4826e-03, -9.5694e-02,  9.4031e-02,  1.1142e-01,\n",
      "          5.7415e-02,  6.2126e-02,  7.7910e-02, -3.0660e-02, -8.4597e-02,\n",
      "          9.0197e-02, -4.8965e-02,  9.6356e-02, -2.7935e-02,  5.2282e-02,\n",
      "         -1.1465e-01, -1.3599e-01, -1.2677e-01, -1.0948e-01,  6.4311e-02,\n",
      "          8.6422e-02,  5.5255e-03, -1.3103e-01, -1.2140e-01, -9.6583e-02,\n",
      "          1.2427e-01, -1.2585e-01,  9.6614e-02, -6.0829e-02,  1.0565e-01,\n",
      "          1.0139e-01, -9.9144e-02, -1.2907e-01,  9.8319e-02, -1.3252e-01,\n",
      "          9.7316e-02, -9.8858e-02, -4.6473e-02,  4.9581e-02, -1.1253e-01,\n",
      "         -1.2810e-01,  2.8484e-02, -1.2095e-01, -7.7263e-03, -5.6188e-02,\n",
      "          1.2908e-01, -9.6215e-02, -5.4627e-02],\n",
      "        [-9.6056e-02, -5.3988e-02, -7.9542e-02,  2.3485e-02,  9.7762e-02,\n",
      "          3.8130e-02, -9.9146e-02,  5.4206e-02,  9.9028e-03, -4.6438e-02,\n",
      "         -1.0460e-01,  1.0792e-01, -4.4393e-02, -4.6860e-02,  2.0222e-02,\n",
      "          2.0907e-02, -1.3824e-01,  7.9167e-02,  1.1083e-01, -1.2643e-01,\n",
      "          1.3033e-01,  9.9220e-02,  1.2615e-01,  3.0547e-02,  1.3283e-01,\n",
      "          3.4000e-02, -8.2530e-02, -6.3618e-02, -1.2059e-01, -2.5852e-02,\n",
      "          1.2914e-01,  9.3614e-02,  1.3129e-01,  4.3939e-02,  7.6858e-02,\n",
      "          1.5823e-03, -2.0439e-02,  1.2135e-01,  1.1534e-01, -1.0614e-01,\n",
      "          1.4050e-01, -6.0248e-02,  6.8848e-02, -1.1343e-01,  7.3049e-02,\n",
      "          3.0702e-02, -1.0566e-01, -5.6581e-03],\n",
      "        [-8.5450e-02, -1.2588e-02,  1.2025e-01, -1.3271e-01, -1.3770e-01,\n",
      "         -1.4001e-01, -3.2827e-02, -4.2392e-02,  8.4422e-02,  4.3721e-03,\n",
      "         -1.0186e-01,  6.4275e-02,  1.3832e-02,  1.3046e-01, -6.9714e-02,\n",
      "         -9.9881e-02, -4.1347e-02,  5.6488e-02, -5.0396e-02,  1.0539e-01,\n",
      "         -1.0929e-01, -2.4177e-02,  6.0034e-02,  3.4723e-02,  1.3972e-01,\n",
      "         -1.4065e-01,  2.2172e-02, -1.3495e-01, -9.8986e-02,  1.2979e-01,\n",
      "         -9.7989e-02,  2.8807e-02,  3.9781e-02, -2.8702e-02, -1.2505e-01,\n",
      "         -3.5764e-02, -1.6874e-02, -5.7499e-02,  1.3496e-01, -8.2007e-03,\n",
      "          4.6962e-02, -1.0362e-01, -1.6530e-02, -2.9611e-02,  1.1472e-01,\n",
      "         -1.1626e-01, -1.0549e-01,  9.3784e-02],\n",
      "        [ 1.0364e-01,  1.4452e-02, -7.6021e-02, -1.2634e-01, -1.1110e-01,\n",
      "          6.4432e-02, -2.5860e-02, -5.7713e-02,  9.9215e-03, -6.9766e-03,\n",
      "         -5.3438e-02, -2.0873e-02,  8.0708e-02,  7.4582e-02, -9.7899e-02,\n",
      "          1.0120e-01, -4.2555e-02,  9.7209e-02,  1.1470e-01,  2.2866e-02,\n",
      "          1.4213e-01,  1.7515e-02, -1.2603e-01, -6.7884e-02, -4.1421e-02,\n",
      "         -4.5215e-02, -7.9502e-02,  3.7581e-02,  1.1251e-01, -9.6349e-02,\n",
      "         -1.5698e-02,  1.1849e-02, -2.2810e-02,  9.5907e-02,  1.9116e-02,\n",
      "          4.6802e-02, -1.5794e-03,  9.3792e-02,  2.7942e-02, -7.6064e-02,\n",
      "         -4.1232e-02,  1.1140e-01,  1.3797e-01, -3.9131e-05,  3.8140e-02,\n",
      "          4.1256e-02, -8.3591e-03,  2.9303e-02],\n",
      "        [-1.4351e-01,  7.9976e-02, -5.7853e-02, -4.9302e-02,  9.0606e-02,\n",
      "          5.9315e-02,  6.4115e-02, -7.5312e-02, -9.4812e-02, -8.3485e-02,\n",
      "         -1.1674e-01, -2.0103e-03, -1.2568e-01, -1.8976e-03, -9.8737e-02,\n",
      "          7.5318e-02,  3.0221e-02, -1.2129e-01,  7.3548e-02,  8.3333e-02,\n",
      "          1.2393e-01,  5.0592e-02, -7.2479e-02,  9.0757e-02,  1.0288e-01,\n",
      "         -3.3893e-02, -5.9407e-02, -9.8439e-02,  1.0230e-02,  1.4304e-01,\n",
      "          4.9548e-02, -2.8651e-02, -1.1928e-01,  7.8886e-02,  3.8201e-02,\n",
      "         -2.8505e-02,  9.6306e-02, -1.2055e-01,  4.0559e-02, -9.9092e-02,\n",
      "         -9.2528e-04, -1.3351e-01,  1.4031e-02, -4.8593e-02,  9.0672e-02,\n",
      "          1.2536e-01,  1.2116e-01, -9.8639e-02],\n",
      "        [-1.0925e-01,  6.4174e-02,  1.3049e-01,  1.2475e-01, -2.2097e-02,\n",
      "         -1.1053e-01,  1.3988e-01, -7.0241e-02, -2.5973e-04, -8.5147e-02,\n",
      "          2.9733e-02, -6.6269e-02,  8.6495e-02,  9.6053e-02, -7.7559e-03,\n",
      "          8.5757e-02,  6.7432e-02,  1.3545e-01, -1.5318e-02, -1.7122e-02,\n",
      "          1.0962e-01,  1.3911e-01,  1.0109e-01, -1.3560e-01,  7.9333e-02,\n",
      "         -7.8474e-02, -5.1006e-03,  9.0412e-02,  1.3699e-01, -7.7336e-02,\n",
      "         -1.2382e-01,  8.0260e-02,  1.0103e-01,  1.2946e-01,  5.6872e-02,\n",
      "          1.2293e-01,  1.7982e-02, -1.4104e-01, -4.8230e-02, -3.1511e-02,\n",
      "          1.2535e-01,  5.7276e-02,  1.1697e-01,  1.2055e-01, -1.7430e-02,\n",
      "         -1.3055e-01, -4.1550e-02, -9.4249e-02],\n",
      "        [ 1.1224e-01, -9.2012e-02, -6.3475e-02, -7.8449e-02,  3.8234e-02,\n",
      "          9.6907e-02, -6.9962e-02, -9.7350e-03, -6.5906e-02, -2.8748e-02,\n",
      "          6.5448e-02,  1.4024e-01, -1.2015e-01, -3.6696e-02,  7.7609e-02,\n",
      "          1.2845e-01, -1.0979e-02, -7.5623e-02, -2.4162e-02, -1.4258e-01,\n",
      "          7.1782e-02,  1.3486e-01, -7.0823e-02, -2.4100e-02, -1.2135e-01,\n",
      "         -3.6539e-02, -1.4396e-02,  9.7261e-03, -1.0322e-01, -3.1316e-02,\n",
      "         -6.9592e-02, -4.2665e-02,  1.9845e-02, -1.3731e-01, -3.5451e-02,\n",
      "         -8.6802e-02, -1.0905e-01, -6.5577e-02, -1.1318e-01,  1.0173e-01,\n",
      "          1.4512e-01, -1.2748e-01,  3.2443e-02,  1.0748e-01,  5.5656e-02,\n",
      "          3.6930e-02, -6.8570e-02,  2.4279e-02],\n",
      "        [ 8.5176e-03, -7.8086e-02,  9.8427e-02,  3.3746e-02, -1.2381e-01,\n",
      "          3.7859e-02,  1.3461e-01,  7.6854e-03, -1.5414e-02,  7.6424e-02,\n",
      "          8.5126e-02,  5.5534e-02, -2.7464e-02,  1.4321e-01,  1.2196e-01,\n",
      "          2.1430e-02, -5.6980e-02,  2.1876e-02,  1.1039e-01,  1.7044e-02,\n",
      "         -7.0168e-02,  1.0951e-01,  1.2530e-01,  6.6440e-02,  7.9641e-03,\n",
      "         -6.2153e-02, -1.3457e-01,  1.1716e-01,  1.1798e-01, -2.6714e-02,\n",
      "          1.8619e-02, -9.7942e-02,  1.5676e-02, -1.4167e-01, -1.0113e-01,\n",
      "          7.2354e-02, -1.0695e-01,  6.1465e-02,  1.0786e-01,  1.0140e-02,\n",
      "         -3.8923e-02,  4.6239e-02,  3.0840e-02,  5.6711e-02,  7.3387e-02,\n",
      "          1.1211e-01, -1.4471e-01,  1.1882e-01],\n",
      "        [-6.8557e-02,  1.0757e-01,  3.5283e-02,  8.2831e-02, -1.1586e-01,\n",
      "         -7.0746e-02,  1.0677e-01, -8.2833e-02, -5.1669e-02, -1.1330e-01,\n",
      "         -5.8615e-02, -3.9421e-02, -4.9472e-02,  9.3586e-02, -1.1023e-01,\n",
      "         -1.3388e-01,  8.3560e-02,  9.7022e-02,  1.0285e-01,  3.4188e-02,\n",
      "         -5.1231e-02,  3.6417e-02, -1.0733e-01, -2.6242e-03,  1.9953e-02,\n",
      "          3.8767e-02, -6.9922e-03,  2.4856e-02, -1.3907e-01, -1.3233e-01,\n",
      "         -5.6747e-02, -4.2170e-02, -9.9205e-02, -1.3376e-01, -9.6502e-02,\n",
      "         -1.0757e-01, -1.8077e-02,  8.4644e-02,  1.0305e-01, -5.8722e-02,\n",
      "         -4.9519e-02, -9.0846e-02, -1.0311e-01,  1.3747e-01,  3.0631e-02,\n",
      "          1.1978e-01, -1.1524e-01,  1.3297e-01],\n",
      "        [-1.3345e-01,  7.9266e-02, -6.2838e-02,  1.3325e-01,  7.2489e-02,\n",
      "          1.0158e-01,  8.9691e-02,  1.2204e-01, -5.3095e-02, -9.0563e-02,\n",
      "         -9.3244e-02, -1.4036e-02,  1.1073e-02,  4.2699e-02, -1.3670e-02,\n",
      "          1.5024e-02,  6.8596e-02,  5.1058e-03,  8.5345e-02, -5.0516e-02,\n",
      "         -8.3435e-02, -3.5006e-02, -3.0601e-02,  1.2123e-01, -4.4576e-02,\n",
      "          1.1343e-01, -4.2503e-02, -9.2579e-03, -8.5398e-02, -4.2863e-02,\n",
      "         -3.0479e-03, -2.5259e-02, -7.7720e-02, -9.3238e-02, -1.0714e-01,\n",
      "         -4.8606e-02,  6.2202e-02,  1.1412e-01, -2.6570e-02, -7.1532e-03,\n",
      "          3.8911e-02, -7.7086e-02,  9.5883e-04,  7.8288e-03, -1.1531e-01,\n",
      "         -1.1230e-01,  5.5108e-03, -4.9231e-02],\n",
      "        [ 2.4357e-02, -1.0073e-01,  8.7988e-02, -4.6302e-02, -8.4679e-02,\n",
      "          2.3355e-02, -3.6059e-02, -5.8484e-02, -5.3550e-02, -8.9957e-02,\n",
      "          5.8898e-02, -8.4046e-02,  8.0304e-03, -1.3696e-02, -7.4813e-02,\n",
      "          7.8516e-02, -9.1572e-02, -9.0165e-03,  1.3239e-01, -1.2655e-01,\n",
      "         -3.3449e-02, -1.2723e-01, -1.3902e-01,  2.3991e-02,  6.7738e-02,\n",
      "         -7.7729e-02, -1.0656e-01, -2.7881e-02,  6.9487e-02, -1.2140e-01,\n",
      "         -2.1604e-02, -3.4833e-02, -1.1156e-01, -1.0088e-01,  9.5473e-02,\n",
      "         -6.8947e-02, -1.3346e-01, -9.9688e-02, -3.6523e-02, -5.2451e-02,\n",
      "         -8.5574e-02,  4.9183e-02,  7.4778e-02, -1.3125e-01, -7.6635e-02,\n",
      "         -1.5133e-02, -1.2750e-01, -1.2972e-01],\n",
      "        [-9.4256e-02,  1.3271e-01,  4.2437e-02, -9.0067e-02,  3.6093e-02,\n",
      "          5.4368e-02, -1.1309e-01,  1.9587e-02,  7.1677e-02, -1.2026e-01,\n",
      "         -2.1691e-03, -1.3252e-01,  5.5062e-04,  1.3071e-01,  1.2990e-01,\n",
      "         -4.5804e-02, -2.6331e-02, -1.2303e-01, -8.9702e-02, -3.0951e-02,\n",
      "          1.1512e-01,  4.9137e-02, -4.8891e-02, -1.1336e-01, -1.3120e-01,\n",
      "         -1.1776e-01, -1.0051e-01, -1.4114e-01,  6.5950e-02,  5.0962e-02,\n",
      "         -1.7467e-02,  5.2959e-02, -1.2806e-01,  2.0135e-02, -7.9774e-02,\n",
      "          1.3212e-02,  5.8587e-02, -5.5033e-02, -4.9397e-02,  1.3127e-01,\n",
      "         -1.1030e-01, -1.1429e-01,  2.7680e-02,  7.2779e-02,  8.8794e-02,\n",
      "         -4.6204e-02,  1.4407e-01,  8.0824e-02],\n",
      "        [-9.9606e-02, -1.3770e-01,  9.9363e-02,  5.5540e-03,  3.5810e-02,\n",
      "          2.1888e-02,  1.1909e-01, -8.4394e-02,  7.0102e-03,  3.5368e-02,\n",
      "         -4.2113e-02,  7.1983e-02, -7.3848e-02, -3.3035e-02,  4.7827e-02,\n",
      "          3.8464e-02, -6.9651e-02, -1.0898e-01,  6.5457e-02, -1.1374e-01,\n",
      "          2.9614e-02, -1.2568e-01,  6.7153e-02,  2.4595e-02,  5.6681e-02,\n",
      "          5.7065e-02,  1.3482e-01,  5.6402e-02, -1.0264e-01, -5.5049e-02,\n",
      "         -8.3531e-02,  1.1817e-01, -7.0452e-02,  5.5724e-02, -2.6901e-03,\n",
      "          1.4124e-01,  2.0397e-02, -1.3876e-02,  4.6785e-02, -1.0946e-02,\n",
      "          1.2773e-01,  1.2284e-01, -9.1265e-02,  1.0128e-01, -2.7664e-02,\n",
      "          1.2128e-01,  1.3002e-01,  7.3102e-02],\n",
      "        [ 6.9798e-02, -7.1632e-02,  3.5656e-02,  1.2171e-01,  1.3784e-01,\n",
      "          1.1889e-01, -3.6291e-02, -8.9516e-02,  1.4207e-01,  9.9582e-02,\n",
      "         -1.3666e-01, -1.4370e-02, -1.3218e-02, -5.0786e-02, -2.9068e-02,\n",
      "          1.3736e-01,  9.6762e-02,  1.5297e-02,  2.2610e-02, -1.2748e-01,\n",
      "          8.1562e-02, -3.1703e-02,  1.3077e-01,  8.3274e-02,  1.4336e-01,\n",
      "         -1.1974e-01, -1.8543e-02,  5.7757e-02, -4.5998e-02, -9.6091e-02,\n",
      "          8.2660e-02,  4.7753e-02, -1.2656e-01,  6.5580e-02,  3.8521e-02,\n",
      "         -3.1759e-02,  5.3704e-02, -5.8344e-02, -8.3643e-04,  8.5337e-02,\n",
      "         -9.6668e-02, -6.3976e-02,  1.1540e-01, -3.0182e-02, -3.3114e-03,\n",
      "          1.3365e-01,  1.2279e-01, -2.4554e-02]], device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([ 0.0882, -0.0591,  0.0739,  0.0244, -0.0150,  0.0218, -0.0964, -0.1049,\n",
      "        -0.0146,  0.0673,  0.0322, -0.1090,  0.0793,  0.0482,  0.0248, -0.1123],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([[-0.0209, -0.0690, -0.0441,  0.1802,  0.1634, -0.1421, -0.0818,  0.1485,\n",
      "         -0.1793,  0.2219,  0.0238,  0.1850, -0.2074, -0.2088, -0.1640, -0.1352],\n",
      "        [ 0.1434, -0.1432,  0.1279, -0.0109, -0.1003, -0.1706,  0.1071, -0.2011,\n",
      "          0.1801,  0.1087,  0.0201, -0.2266,  0.1722, -0.1534, -0.1026, -0.1027],\n",
      "        [ 0.0833, -0.2451, -0.1719,  0.0824, -0.0145, -0.2081, -0.0289, -0.1408,\n",
      "          0.1106,  0.1988,  0.1767,  0.0070, -0.1148,  0.0369,  0.1264, -0.0766],\n",
      "        [ 0.0708, -0.2135,  0.2327,  0.1195,  0.0661,  0.0941,  0.0617,  0.2231,\n",
      "         -0.0502,  0.0044, -0.2174, -0.2408,  0.0678,  0.2161,  0.2319, -0.2097],\n",
      "        [ 0.1774, -0.0693,  0.1152,  0.1689, -0.1093,  0.1118,  0.0365, -0.0355,\n",
      "         -0.2346,  0.1408, -0.2097, -0.1838, -0.1113,  0.2010,  0.0397, -0.0707],\n",
      "        [-0.0535,  0.2223, -0.2072, -0.1408, -0.1548, -0.2300,  0.0603, -0.2160,\n",
      "          0.0846, -0.1003, -0.0954, -0.2172,  0.1344, -0.1558,  0.2171, -0.0584],\n",
      "        [ 0.0122,  0.0880, -0.0876,  0.0470,  0.0676, -0.0353, -0.1462, -0.0933,\n",
      "          0.2444, -0.0559,  0.2506,  0.1806, -0.1186,  0.2498, -0.1761,  0.0200],\n",
      "        [ 0.1376, -0.2008, -0.1490, -0.1602, -0.1289,  0.1256,  0.0843, -0.1180,\n",
      "          0.0182, -0.2227, -0.1106,  0.0350,  0.0871, -0.0148,  0.1749, -0.0327],\n",
      "        [ 0.1271,  0.1660, -0.1908,  0.0441, -0.1836,  0.0129,  0.1860, -0.1854,\n",
      "          0.0969,  0.1623,  0.1665, -0.1267, -0.1363,  0.2046,  0.0928, -0.0461],\n",
      "        [ 0.0830,  0.2150, -0.0398,  0.0740,  0.1778,  0.1354,  0.0139,  0.1362,\n",
      "          0.2343,  0.0206, -0.0244, -0.1602,  0.0784,  0.1676, -0.0504, -0.1032],\n",
      "        [ 0.2175,  0.1337, -0.0606, -0.1527, -0.1503,  0.2490,  0.0398,  0.1737,\n",
      "         -0.0157, -0.0108,  0.1219,  0.2461, -0.1947,  0.0591,  0.0519,  0.2407],\n",
      "        [-0.0400,  0.1076, -0.1017, -0.0727,  0.1073, -0.0813,  0.2090,  0.2029,\n",
      "         -0.0878, -0.0805,  0.1830,  0.1941, -0.2109, -0.1168, -0.1622,  0.0785],\n",
      "        [ 0.1410, -0.0853,  0.1265,  0.0832, -0.1451, -0.0010,  0.1678,  0.2196,\n",
      "          0.1695, -0.1792, -0.2054,  0.1697,  0.1676, -0.1416,  0.0677,  0.0960],\n",
      "        [ 0.1424,  0.1676,  0.0519,  0.1070, -0.0669, -0.0979,  0.0982, -0.2160,\n",
      "         -0.0109, -0.0624,  0.0280,  0.1468,  0.1313,  0.1278, -0.0472,  0.2213],\n",
      "        [-0.0370,  0.1327, -0.1825, -0.2008, -0.0401,  0.2191, -0.1028, -0.2005,\n",
      "          0.1700, -0.1827, -0.1077, -0.1526, -0.1557, -0.0727,  0.1808, -0.2484],\n",
      "        [-0.2028, -0.0306, -0.2293, -0.0502,  0.1688,  0.1905,  0.0192,  0.0392,\n",
      "          0.0662,  0.1658,  0.1162, -0.0864, -0.2084, -0.0635,  0.1927,  0.2486]],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([ 0.1720, -0.1158, -0.1699,  0.0393, -0.1219, -0.0992,  0.0497,  0.1295,\n",
      "         0.2037, -0.2498, -0.0571, -0.1632,  0.0106, -0.1613, -0.2180,  0.1646],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([[ 0.1577, -0.0599, -0.1714, -0.2414,  0.1450,  0.1875, -0.1069, -0.1693,\n",
      "         -0.0388, -0.2079, -0.1897,  0.1419, -0.1912,  0.0775, -0.1931,  0.1019],\n",
      "        [-0.0920, -0.0300,  0.1651,  0.0026,  0.0979,  0.1677, -0.2213, -0.1059,\n",
      "          0.0933,  0.2165, -0.2148, -0.0857,  0.2277,  0.1443, -0.0524,  0.1271]],\n",
      "       device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([0.0629, 0.2388], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "final_model.module.freeze(module_name=\"predictor\", defreeze=True)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(163.2842, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9188,  1.0647,  0.3373, -1.0589, -0.4356,  1.0034, -0.1101,  0.3827,\n",
       "          0.9371, -1.9254],\n",
       "        [ 0.0978,  0.7434,  0.6444, -0.2944,  0.3274,  0.8281, -0.6298, -0.8488,\n",
       "         -1.1199,  0.7339],\n",
       "        [ 0.1135, -0.1256,  1.8128,  0.0260, -0.9463, -1.1076, -0.8307,  0.4789,\n",
       "          1.0825,  0.2068],\n",
       "        [-1.1163,  0.1125,  1.3946, -0.4888,  0.0986, -0.4214, -0.6237,  0.1326,\n",
       "         -1.5205, -0.6777],\n",
       "        [-0.9647, -0.5700, -0.3964,  0.4473,  0.7972, -1.0017,  0.0936,  0.8673,\n",
       "         -0.1744,  0.2031],\n",
       "        [-0.2352,  0.5598,  0.3131, -0.2481,  1.2925,  0.4672, -1.5914,  0.9305,\n",
       "          1.9326,  0.0876],\n",
       "        [-0.9283, -1.5283,  1.0758, -0.7223,  1.3624,  0.7709,  0.9271,  1.9560,\n",
       "          1.0451, -1.0441],\n",
       "        [-2.0542,  0.6931,  1.5115,  0.0730,  1.6530,  1.1155, -1.9170,  0.8677,\n",
       "         -2.0559,  1.5885],\n",
       "        [-0.7855, -1.5159,  0.9893, -0.8754,  0.3694, -0.4529, -0.2145, -0.4598,\n",
       "         -0.6518,  0.2534],\n",
       "        [ 1.7088,  0.1335, -0.4558, -2.0668,  0.0511, -0.3929, -0.4618,  1.3527,\n",
       "         -1.5567, -0.3284]], device='cuda:1', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-20.0368, device='cuda:1', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0292, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "tensor(-0.0533, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "tensor(1.7583, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "tensor(-0.5889, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "tensor(-0.3179, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "tensor(0.3017, device='cuda:1', grad_fn=<SumBackward0>) True\n",
      "Parameter containing:\n",
      "tensor([[ 0.0064, -0.0067,  0.0250,  0.0706, -0.1283, -0.0988, -0.0069,  0.0704,\n",
      "         -0.1195, -0.0375,  0.1414,  0.0020, -0.1353,  0.0944, -0.0209, -0.1269,\n",
      "         -0.0174,  0.0053,  0.1270, -0.0753, -0.0789, -0.1309,  0.0320, -0.1382,\n",
      "         -0.0120, -0.1338, -0.1420, -0.0412,  0.1048, -0.0289, -0.0204,  0.0228,\n",
      "          0.1426,  0.0171, -0.1128, -0.0294, -0.0135, -0.1217,  0.0071, -0.1347,\n",
      "          0.0744, -0.0276, -0.0205,  0.0562,  0.0032, -0.0450,  0.0877, -0.0659],\n",
      "        [ 0.0844, -0.0740,  0.0745, -0.0539, -0.0826, -0.0302, -0.1396, -0.1312,\n",
      "          0.0010,  0.0545, -0.0629,  0.1322, -0.0148, -0.1074,  0.0858, -0.0404,\n",
      "         -0.0622,  0.1081,  0.0018, -0.0345,  0.0378, -0.0716, -0.0898,  0.0493,\n",
      "          0.0828, -0.1311, -0.0881,  0.0114, -0.0991,  0.0502, -0.1179, -0.0500,\n",
      "          0.0299, -0.0488, -0.1092,  0.1183,  0.1224,  0.0605, -0.0643, -0.0986,\n",
      "          0.0206,  0.0732, -0.0966,  0.0382, -0.1456,  0.0425, -0.0812, -0.0201],\n",
      "        [ 0.0860, -0.0010, -0.0952,  0.0945,  0.1119,  0.0569,  0.0626,  0.0774,\n",
      "         -0.0312, -0.0841,  0.0897, -0.0485,  0.0959, -0.0274,  0.0528, -0.1142,\n",
      "         -0.1365, -0.1263, -0.1100,  0.0638,  0.0869,  0.0050, -0.1315, -0.1209,\n",
      "         -0.0971,  0.1238, -0.1264,  0.0971, -0.0603,  0.1051,  0.1019, -0.0986,\n",
      "         -0.1286,  0.0988, -0.1330,  0.0968, -0.0984, -0.0460,  0.0491, -0.1120,\n",
      "         -0.1286,  0.0280, -0.1214, -0.0082, -0.0567,  0.1296, -0.0957, -0.0541],\n",
      "        [-0.0956, -0.0535, -0.0790,  0.0230,  0.0983,  0.0376, -0.0986,  0.0547,\n",
      "          0.0104, -0.0459, -0.1051,  0.1074, -0.0439, -0.0464,  0.0207,  0.0204,\n",
      "         -0.1387,  0.0797,  0.1103, -0.1259,  0.1298,  0.0997,  0.1266,  0.0300,\n",
      "          0.1333,  0.0345, -0.0820, -0.0631, -0.1201, -0.0264,  0.1286,  0.0941,\n",
      "          0.1318,  0.0444,  0.0764,  0.0011, -0.0199,  0.1209,  0.1158, -0.1056,\n",
      "          0.1410, -0.0607,  0.0683, -0.1129,  0.0725,  0.0312, -0.1062, -0.0052],\n",
      "        [-0.0859, -0.0131,  0.1208, -0.1332, -0.1382, -0.1395, -0.0333, -0.0419,\n",
      "          0.0849,  0.0039, -0.1024,  0.0638,  0.0143,  0.1300, -0.0702, -0.1004,\n",
      "         -0.0408,  0.0560, -0.0499,  0.1059, -0.1098, -0.0237,  0.0595,  0.0352,\n",
      "          0.1392, -0.1401,  0.0227, -0.1355, -0.0985,  0.1303, -0.0985,  0.0283,\n",
      "          0.0403, -0.0292, -0.1245, -0.0363, -0.0164, -0.0580,  0.1355, -0.0087,\n",
      "          0.0475, -0.1031, -0.0160, -0.0291,  0.1152, -0.1158, -0.1050,  0.0943],\n",
      "        [ 0.1041,  0.0140, -0.0765, -0.1258, -0.1106,  0.0649, -0.0254, -0.0582,\n",
      "          0.0094, -0.0075, -0.0529, -0.0214,  0.0802,  0.0751, -0.0984,  0.1007,\n",
      "         -0.0421,  0.0977,  0.1142,  0.0224,  0.1426,  0.0170, -0.1255, -0.0684,\n",
      "         -0.0409, -0.0447, -0.0800,  0.0371,  0.1130, -0.0968, -0.0152,  0.0113,\n",
      "         -0.0233,  0.0964,  0.0186,  0.0473, -0.0011,  0.0933,  0.0274, -0.0756,\n",
      "         -0.0417,  0.1119,  0.1385, -0.0005,  0.0376,  0.0408, -0.0079,  0.0298],\n",
      "        [-0.1440,  0.0795, -0.0584, -0.0488,  0.0911,  0.0588,  0.0636, -0.0758,\n",
      "         -0.0953, -0.0830, -0.1162, -0.0015, -0.1252, -0.0014, -0.0982,  0.0758,\n",
      "          0.0297, -0.1208,  0.0730,  0.0838,  0.1244,  0.0511, -0.0730,  0.0913,\n",
      "          0.1024, -0.0344, -0.0599, -0.0979,  0.0107,  0.1425,  0.0500, -0.0292,\n",
      "         -0.1198,  0.0794,  0.0377, -0.0280,  0.0968, -0.1200,  0.0401, -0.0986,\n",
      "         -0.0014, -0.1340,  0.0135, -0.0491,  0.0902,  0.1259,  0.1217, -0.0981],\n",
      "        [-0.1088,  0.0647,  0.1300,  0.1253, -0.0226, -0.1100,  0.1404, -0.0707,\n",
      "          0.0002, -0.0856,  0.0302, -0.0658,  0.0860,  0.0966, -0.0083,  0.0863,\n",
      "          0.0679,  0.1360, -0.0158, -0.0176,  0.1101,  0.1386,  0.1016, -0.1361,\n",
      "          0.0798, -0.0790, -0.0056,  0.0899,  0.1375, -0.0778, -0.1233,  0.0798,\n",
      "          0.1005,  0.1290,  0.0564,  0.1224,  0.0175, -0.1405, -0.0487, -0.0320,\n",
      "          0.1248,  0.0578,  0.1175,  0.1201, -0.0179, -0.1311, -0.0420, -0.0937],\n",
      "        [ 0.1127, -0.0915, -0.0630, -0.0779,  0.0387,  0.0974, -0.0695, -0.0102,\n",
      "         -0.0654, -0.0282,  0.0649,  0.1407, -0.1196, -0.0362,  0.0781,  0.1280,\n",
      "         -0.0115, -0.0751, -0.0247, -0.1421,  0.0723,  0.1354, -0.0703, -0.0246,\n",
      "         -0.1208, -0.0360, -0.0139,  0.0102, -0.1027, -0.0318, -0.0691, -0.0422,\n",
      "          0.0203, -0.1368, -0.0360, -0.0863, -0.1085, -0.0661, -0.1137,  0.1022,\n",
      "          0.1446, -0.1280,  0.0329,  0.1070,  0.0552,  0.0374, -0.0691,  0.0248],\n",
      "        [ 0.0080, -0.0786,  0.0989,  0.0332, -0.1233,  0.0384,  0.1341,  0.0082,\n",
      "         -0.0149,  0.0769,  0.0846,  0.0550, -0.0270,  0.1427,  0.1225,  0.0209,\n",
      "         -0.0575,  0.0224,  0.1109,  0.0175, -0.0707,  0.1100,  0.1258,  0.0669,\n",
      "          0.0085, -0.0617, -0.1351,  0.1177,  0.1175, -0.0262,  0.0181, -0.0974,\n",
      "          0.0152, -0.1422, -0.1006,  0.0719, -0.1064,  0.0610,  0.1084,  0.0096,\n",
      "         -0.0384,  0.0457,  0.0313,  0.0572,  0.0739,  0.1126, -0.1452,  0.1193],\n",
      "        [-0.0691,  0.1071,  0.0358,  0.0823, -0.1164, -0.0712,  0.1063, -0.0823,\n",
      "         -0.0522, -0.1138, -0.0581, -0.0399, -0.0500,  0.0931, -0.1107, -0.1344,\n",
      "          0.0841,  0.0965,  0.1033,  0.0347, -0.0517,  0.0369, -0.1078, -0.0021,\n",
      "          0.0195,  0.0383, -0.0065,  0.0244, -0.1396, -0.1318, -0.0572, -0.0427,\n",
      "         -0.0997, -0.1343, -0.0970, -0.1071, -0.0186,  0.0851,  0.1035, -0.0592,\n",
      "         -0.0490, -0.0903, -0.1026,  0.1380,  0.0311,  0.1193, -0.1147,  0.1325],\n",
      "        [-0.1340,  0.0788, -0.0623,  0.1327,  0.0720,  0.1011,  0.0892,  0.1225,\n",
      "         -0.0526, -0.0911, -0.0937, -0.0145,  0.0116,  0.0422, -0.0132,  0.0145,\n",
      "          0.0681,  0.0046,  0.0858, -0.0500, -0.0839, -0.0345, -0.0311,  0.1217,\n",
      "         -0.0451,  0.1139, -0.0420, -0.0088, -0.0859, -0.0424, -0.0035, -0.0258,\n",
      "         -0.0782, -0.0937, -0.1076, -0.0491,  0.0627,  0.1146, -0.0261, -0.0077,\n",
      "          0.0394, -0.0776,  0.0005,  0.0083, -0.1148, -0.1118,  0.0050, -0.0487],\n",
      "        [ 0.0239, -0.1002,  0.0875, -0.0458, -0.0852,  0.0239, -0.0356, -0.0590,\n",
      "         -0.0530, -0.0895,  0.0594, -0.0835,  0.0075, -0.0132, -0.0753,  0.0790,\n",
      "         -0.0911, -0.0085,  0.1319, -0.1271, -0.0329, -0.1277, -0.1385,  0.0235,\n",
      "          0.0682, -0.0772, -0.1071, -0.0284,  0.0700, -0.1219, -0.0211, -0.0353,\n",
      "         -0.1121, -0.1004,  0.0950, -0.0684, -0.1330, -0.1002, -0.0370, -0.0520,\n",
      "         -0.0861,  0.0487,  0.0753, -0.1317, -0.0771, -0.0156, -0.1270, -0.1292],\n",
      "        [-0.0938,  0.1332,  0.0429, -0.0906,  0.0366,  0.0539, -0.1136,  0.0191,\n",
      "          0.0722, -0.1208, -0.0027, -0.1320,  0.0011,  0.1312,  0.1304, -0.0463,\n",
      "         -0.0268, -0.1225, -0.0902, -0.0315,  0.1146,  0.0496, -0.0484, -0.1139,\n",
      "         -0.1307, -0.1173, -0.1000, -0.1406,  0.0654,  0.0505, -0.0180,  0.0535,\n",
      "         -0.1286,  0.0196, -0.0793,  0.0137,  0.0591, -0.0555, -0.0499,  0.1308,\n",
      "         -0.1098, -0.1148,  0.0282,  0.0733,  0.0893, -0.0457,  0.1436,  0.0813],\n",
      "        [-0.0991, -0.1372,  0.0989,  0.0061,  0.0363,  0.0224,  0.1196, -0.0849,\n",
      "          0.0075,  0.0349, -0.0426,  0.0715, -0.0733, -0.0325,  0.0483,  0.0380,\n",
      "         -0.0692, -0.1085,  0.0650, -0.1142,  0.0301, -0.1262,  0.0677,  0.0241,\n",
      "          0.0572,  0.0576,  0.1343,  0.0559, -0.1021, -0.0555, -0.0830,  0.1177,\n",
      "         -0.0710,  0.0552, -0.0032,  0.1417,  0.0209, -0.0144,  0.0463, -0.0114,\n",
      "          0.1272,  0.1223, -0.0908,  0.1008, -0.0282,  0.1208,  0.1295,  0.0736],\n",
      "        [ 0.0693, -0.0721,  0.0362,  0.1212,  0.1373,  0.1184, -0.0368, -0.0900,\n",
      "          0.1426,  0.0991, -0.1362, -0.0139, -0.0127, -0.0503, -0.0286,  0.1379,\n",
      "          0.0963,  0.0148,  0.0231, -0.1280,  0.0821, -0.0322,  0.1313,  0.0838,\n",
      "          0.1439, -0.1192, -0.0190,  0.0583, -0.0465, -0.0966,  0.0822,  0.0483,\n",
      "         -0.1271,  0.0651,  0.0390, -0.0313,  0.0542, -0.0578, -0.0013,  0.0848,\n",
      "         -0.0962, -0.0635,  0.1159, -0.0297, -0.0038,  0.1342,  0.1223, -0.0241]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0877, -0.0596,  0.0734,  0.0239, -0.0145,  0.0213, -0.0969, -0.1054,\n",
      "        -0.0151,  0.0678,  0.0327, -0.1085,  0.0788,  0.0487,  0.0243, -0.1118],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0204, -0.0685, -0.0436,  0.1807,  0.1639, -0.1416, -0.0813,  0.1490,\n",
      "         -0.1788,  0.2214,  0.0243,  0.1855, -0.2069, -0.2083, -0.1645, -0.1347],\n",
      "        [ 0.1429, -0.1437,  0.1274, -0.0114, -0.1008, -0.1711,  0.1066, -0.2011,\n",
      "          0.1796,  0.1092,  0.0196, -0.2271,  0.1717, -0.1539, -0.1031, -0.1032],\n",
      "        [ 0.0828, -0.2446, -0.1714,  0.0829, -0.0140, -0.2086, -0.0289, -0.1413,\n",
      "          0.1111,  0.1993,  0.1762,  0.0065, -0.1153,  0.0374,  0.1269, -0.0766],\n",
      "        [ 0.0703, -0.2130,  0.2322,  0.1190,  0.0656,  0.0936,  0.0622,  0.2226,\n",
      "         -0.0507,  0.0049, -0.2179, -0.2413,  0.0673,  0.2166,  0.2314, -0.2102],\n",
      "        [ 0.1779, -0.0698,  0.1147,  0.1694, -0.1088,  0.1123,  0.0360, -0.0350,\n",
      "         -0.2341,  0.1413, -0.2092, -0.1833, -0.1113,  0.2005,  0.0402, -0.0707],\n",
      "        [-0.0530,  0.2228, -0.2072, -0.1403, -0.1543, -0.2295,  0.0608, -0.2155,\n",
      "          0.0851, -0.0998, -0.0949, -0.2167,  0.1349, -0.1558,  0.2176, -0.0579],\n",
      "        [ 0.0127,  0.0885, -0.0881,  0.0475,  0.0681, -0.0348, -0.1467, -0.0928,\n",
      "          0.2449, -0.0564,  0.2511,  0.1811, -0.1181,  0.2503, -0.1756,  0.0205],\n",
      "        [ 0.1371, -0.2013, -0.1495, -0.1607, -0.1294,  0.1251,  0.0838, -0.1185,\n",
      "          0.0177, -0.2227, -0.1111,  0.0345,  0.0866, -0.0153,  0.1744, -0.0332],\n",
      "        [ 0.1266,  0.1655, -0.1913,  0.0436, -0.1841,  0.0124,  0.1855, -0.1859,\n",
      "          0.0964,  0.1628,  0.1660, -0.1272, -0.1368,  0.2041,  0.0923, -0.0466],\n",
      "        [ 0.0825,  0.2145, -0.0403,  0.0735,  0.1773,  0.1349,  0.0134,  0.1357,\n",
      "          0.2338,  0.0211, -0.0249, -0.1607,  0.0779,  0.1671, -0.0509, -0.1037],\n",
      "        [ 0.2180,  0.1342, -0.0611, -0.1522, -0.1498,  0.2495,  0.0393,  0.1742,\n",
      "         -0.0152, -0.0103,  0.1224,  0.2466, -0.1942,  0.0586,  0.0524,  0.2412],\n",
      "        [-0.0395,  0.1081, -0.1012, -0.0722,  0.1078, -0.0808,  0.2095,  0.2034,\n",
      "         -0.0873, -0.0800,  0.1835,  0.1946, -0.2104, -0.1163, -0.1617,  0.0785],\n",
      "        [ 0.1405, -0.0858,  0.1270,  0.0827, -0.1456, -0.0015,  0.1673,  0.2191,\n",
      "          0.1690, -0.1786, -0.2059,  0.1692,  0.1671, -0.1411,  0.0672,  0.0955],\n",
      "        [ 0.1419,  0.1671,  0.0524,  0.1065, -0.0674, -0.0984,  0.0987, -0.2160,\n",
      "         -0.0114, -0.0629,  0.0275,  0.1463,  0.1308,  0.1283, -0.0477,  0.2208],\n",
      "        [-0.0375,  0.1322, -0.1825, -0.2013, -0.0406,  0.2191, -0.1033, -0.2010,\n",
      "          0.1695, -0.1832, -0.1082, -0.1526, -0.1562, -0.0727,  0.1803, -0.2484],\n",
      "        [-0.2033, -0.0311, -0.2298, -0.0507,  0.1683,  0.1900,  0.0187,  0.0387,\n",
      "          0.0657,  0.1663,  0.1157, -0.0869, -0.2089, -0.0640,  0.1922,  0.2481]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1725, -0.1163, -0.1694,  0.0388, -0.1224, -0.0987,  0.0502,  0.1290,\n",
      "         0.2032, -0.2503, -0.0566, -0.1627,  0.0101, -0.1618, -0.2185,  0.1641],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1582, -0.0604, -0.1709, -0.2409,  0.1455,  0.1880, -0.1064, -0.1688,\n",
      "         -0.0383, -0.2074, -0.1892,  0.1424, -0.1907,  0.0780, -0.1926,  0.1024],\n",
      "        [-0.0925, -0.0295,  0.1646,  0.0021,  0.0974,  0.1672, -0.2218, -0.1064,\n",
      "          0.0928,  0.2160, -0.2153, -0.0862,  0.2272,  0.1438, -0.0529,  0.1266]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0634, 0.2383], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    print(\"Validate model on train dataset\")\n",
    "    # trues_recon_train, preds_recon_train, trues_y_train, preds_y_train = validate_model(final_model, whole_loader, configs.model, configs.train)\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, mp=mp, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "print(\"Validate model on test dataset\")\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, mp=mp, batch_size=64, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=configs.data.pred_type)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    confmat_y_res = pd.concat([confmat_y_train, confmat_y_test], axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
