{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/'\n",
    "master_dir = '/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer, Predictor\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict, to_device\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv(os.path.join(data_dir, \"collection_\" + \"\".join([config_keywords, config_ipcs, config_period]) + \".csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>assignee</th>\n",
       "      <th>main cpc</th>\n",
       "      <th>sub cpc</th>\n",
       "      <th>main ipc</th>\n",
       "      <th>sub ipc</th>\n",
       "      <th>&lt;1976</th>\n",
       "      <th>1976</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>claims</th>\n",
       "      <th>claims_org</th>\n",
       "      <th>forward_refs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8925188</th>\n",
       "      <td>8925188</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Fujitsu Limited</td>\n",
       "      <td>H05K3/305</td>\n",
       "      <td>Y10T29/53183;H05K2203/1115;Y10T29/53191;Y10T29...</td>\n",
       "      <td>B23P19/00</td>\n",
       "      <td>H05K3/30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A mounting apparatus comprising: a stage de...</td>\n",
       "      <td>1. A mounting apparatus comprising: a stage de...</td>\n",
       "      <td>10932401;9210836;9761556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925190</th>\n",
       "      <td>8925190</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Panasonic Intellectual Property Management Co....</td>\n",
       "      <td>H05K13/083;H05K13/0812;H05K13/0452</td>\n",
       "      <td>Y10T29/53174;Y10T29/49904;H01L2224/81;Y10T29/5...</td>\n",
       "      <td>H05K3/30</td>\n",
       "      <td>H05K13/04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. An electronic component mounting device whi...</td>\n",
       "      <td>1. An electronic component mounting device whi...</td>\n",
       "      <td>10271437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925260</th>\n",
       "      <td>8925260</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>P4P Holdings LLC</td>\n",
       "      <td>H02S20/32;H02S20/10;F24S25/50;E04C3/30;H02S20/20</td>\n",
       "      <td>Y02E10/47;Y02E10/50</td>\n",
       "      <td>E04H12/20</td>\n",
       "      <td>H01L31/042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A method of supporting a solar panel array ...</td>\n",
       "      <td>1. A method of supporting a solar panel array ...</td>\n",
       "      <td>10337586;9184694;9954478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925262</th>\n",
       "      <td>8925262</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Building Materials Investment Corporation</td>\n",
       "      <td>E04D1/30;H02S40/34;E04D13/174;H02S20/23;E04D13...</td>\n",
       "      <td>Y02E10/50;Y02B10/10;E04D2001/305</td>\n",
       "      <td>E04D5/00</td>\n",
       "      <td>F24F7/02;E04D3/00;H01L31/048;E04D13/10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A ridge vent system comprising: an elongate...</td>\n",
       "      <td>1. A ridge vent system comprising: an elongate...</td>\n",
       "      <td>10281189;10739055;10845115;9695594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925263</th>\n",
       "      <td>8925263</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H02S20/23;F16B5/0607;F16B2/065;F24S25/632;H02S...</td>\n",
       "      <td>F16B2005/0678;Y02B10/20;F24S2025/6008;F16B2/12...</td>\n",
       "      <td>E04D13/18</td>\n",
       "      <td>E04H14/00;H01L31/042;F24J2/52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A photovoltaic module mounting assembly, co...</td>\n",
       "      <td>1. A photovoltaic module mounting assembly, co...</td>\n",
       "      <td>10014818;10041254;10097132;10128790;10205418;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE46435</th>\n",
       "      <td>RE46435</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>SANDISK TECHNOLOGIES LLC</td>\n",
       "      <td>G11C5/025;G11C8/08;H01L27/1021;H01L27/2409;H01...</td>\n",
       "      <td>G11C16/0483;H01L27/112;H01L45/085;H01L45/04;H0...</td>\n",
       "      <td>G11C5/02</td>\n",
       "      <td>G11C8/08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A nonvolatile memory device, comprising.Iad...</td>\n",
       "      <td>1. A nonvolatile memory device, comprising.Iad...</td>\n",
       "      <td>10061633;10283493;10381322;10453798;10510738;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE46441</th>\n",
       "      <td>RE46441</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NOVARTIS AG</td>\n",
       "      <td>B01F33/811;A61K9/1075;B01F25/44;B01F23/41;A61K...</td>\n",
       "      <td>A61K2039/55566</td>\n",
       "      <td>A61K31/01</td>\n",
       "      <td>A61K9/107;B01F5/06;B01F13/10;B01F3/08;A61K39/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A method for the manufacture of a squalene-...</td>\n",
       "      <td>1. A method for the manufacture of a squalene-...</td>\n",
       "      <td>10159637;10463615;10813872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE46456</th>\n",
       "      <td>RE46456</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>RICOH COMPANY, LTD.</td>\n",
       "      <td>G06F1/325;G06F1/3203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G06F13/24</td>\n",
       "      <td>G06F1/32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. An image processing device comprising: a fi...</td>\n",
       "      <td>1. An image processing device comprising: a fi...</td>\n",
       "      <td>10631051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE46465</th>\n",
       "      <td>RE46465</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>KAWASAKI JUKOGYO KABUSHIKI KAISHA</td>\n",
       "      <td>H01L21/67766</td>\n",
       "      <td>Y10S414/139;Y10S414/135;Y10S414/137</td>\n",
       "      <td>H01L21/677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>.[.1. A wafer transfer apparatus for transferr...</td>\n",
       "      <td>.[.1. A wafer transfer apparatus for transferr...</td>\n",
       "      <td>RE47145;RE47909;RE48031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE46609</th>\n",
       "      <td>RE46609</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>SATURN LICENSING LLC.</td>\n",
       "      <td>G02F1/133605</td>\n",
       "      <td>G02F1/133322;G02F1/133612;G02F2201/46;G02F1/13...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G09F13/04;G02F1/1335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. A backlight device that illuminates a trans...</td>\n",
       "      <td>1. A backlight device that illuminates a trans...</td>\n",
       "      <td>10725338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48841 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          number  year  month  \\\n",
       "8925188  8925188  2015      1   \n",
       "8925190  8925190  2015      1   \n",
       "8925260  8925260  2015      1   \n",
       "8925262  8925262  2015      1   \n",
       "8925263  8925263  2015      1   \n",
       "...          ...   ...    ...   \n",
       "RE46435  RE46435  2017      6   \n",
       "RE46441  RE46441  2017      6   \n",
       "RE46456  RE46456  2017      6   \n",
       "RE46465  RE46465  2017      7   \n",
       "RE46609  RE46609  2017     11   \n",
       "\n",
       "                                                  assignee  \\\n",
       "8925188                                    Fujitsu Limited   \n",
       "8925190  Panasonic Intellectual Property Management Co....   \n",
       "8925260                                   P4P Holdings LLC   \n",
       "8925262          Building Materials Investment Corporation   \n",
       "8925263                                                NaN   \n",
       "...                                                    ...   \n",
       "RE46435                           SANDISK TECHNOLOGIES LLC   \n",
       "RE46441                                        NOVARTIS AG   \n",
       "RE46456                                RICOH COMPANY, LTD.   \n",
       "RE46465                  KAWASAKI JUKOGYO KABUSHIKI KAISHA   \n",
       "RE46609                              SATURN LICENSING LLC.   \n",
       "\n",
       "                                                  main cpc  \\\n",
       "8925188                                          H05K3/305   \n",
       "8925190                 H05K13/083;H05K13/0812;H05K13/0452   \n",
       "8925260   H02S20/32;H02S20/10;F24S25/50;E04C3/30;H02S20/20   \n",
       "8925262  E04D1/30;H02S40/34;E04D13/174;H02S20/23;E04D13...   \n",
       "8925263  H02S20/23;F16B5/0607;F16B2/065;F24S25/632;H02S...   \n",
       "...                                                    ...   \n",
       "RE46435  G11C5/025;G11C8/08;H01L27/1021;H01L27/2409;H01...   \n",
       "RE46441  B01F33/811;A61K9/1075;B01F25/44;B01F23/41;A61K...   \n",
       "RE46456                               G06F1/325;G06F1/3203   \n",
       "RE46465                                       H01L21/67766   \n",
       "RE46609                                       G02F1/133605   \n",
       "\n",
       "                                                   sub cpc    main ipc  \\\n",
       "8925188  Y10T29/53183;H05K2203/1115;Y10T29/53191;Y10T29...   B23P19/00   \n",
       "8925190  Y10T29/53174;Y10T29/49904;H01L2224/81;Y10T29/5...    H05K3/30   \n",
       "8925260                                Y02E10/47;Y02E10/50   E04H12/20   \n",
       "8925262                   Y02E10/50;Y02B10/10;E04D2001/305    E04D5/00   \n",
       "8925263  F16B2005/0678;Y02B10/20;F24S2025/6008;F16B2/12...   E04D13/18   \n",
       "...                                                    ...         ...   \n",
       "RE46435  G11C16/0483;H01L27/112;H01L45/085;H01L45/04;H0...    G11C5/02   \n",
       "RE46441                                     A61K2039/55566   A61K31/01   \n",
       "RE46456                                                NaN   G06F13/24   \n",
       "RE46465                Y10S414/139;Y10S414/135;Y10S414/137  H01L21/677   \n",
       "RE46609  G02F1/133322;G02F1/133612;G02F2201/46;G02F1/13...         NaN   \n",
       "\n",
       "                                                   sub ipc  <1976  1976  ...  \\\n",
       "8925188                                           H05K3/30      0     0  ...   \n",
       "8925190                                          H05K13/04      0     0  ...   \n",
       "8925260                                         H01L31/042      0     0  ...   \n",
       "8925262             F24F7/02;E04D3/00;H01L31/048;E04D13/10      0     0  ...   \n",
       "8925263                      E04H14/00;H01L31/042;F24J2/52      0     0  ...   \n",
       "...                                                    ...    ...   ...  ...   \n",
       "RE46435                                           G11C8/08      0     0  ...   \n",
       "RE46441  A61K9/107;B01F5/06;B01F13/10;B01F3/08;A61K39/3...      0     0  ...   \n",
       "RE46456                                           G06F1/32      0     0  ...   \n",
       "RE46465                                                NaN      0     0  ...   \n",
       "RE46609                               G09F13/04;G02F1/1335      0     0  ...   \n",
       "\n",
       "         2016  2017  2018  2019  2020  2021  2022  \\\n",
       "8925188     1     1     1     4    30     1     1   \n",
       "8925190     1     1     1     1    30     1     1   \n",
       "8925260     1     1     1     1    30     1     1   \n",
       "8925262     1     1     1     1     2     1     1   \n",
       "8925263     5     2     9     9     7     6     1   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   \n",
       "RE46435     1     1     1     4     2     1     1   \n",
       "RE46441     1     1     1     1     1     1     1   \n",
       "RE46456     1     1     1     1     1     1     1   \n",
       "RE46465     1     1     1     1     2     1     1   \n",
       "RE46609     1     1     1     1     1     1     1   \n",
       "\n",
       "                                                    claims  \\\n",
       "8925188  1. A mounting apparatus comprising: a stage de...   \n",
       "8925190  1. An electronic component mounting device whi...   \n",
       "8925260  1. A method of supporting a solar panel array ...   \n",
       "8925262  1. A ridge vent system comprising: an elongate...   \n",
       "8925263  1. A photovoltaic module mounting assembly, co...   \n",
       "...                                                    ...   \n",
       "RE46435  1. A nonvolatile memory device, comprising.Iad...   \n",
       "RE46441  1. A method for the manufacture of a squalene-...   \n",
       "RE46456  1. An image processing device comprising: a fi...   \n",
       "RE46465  .[.1. A wafer transfer apparatus for transferr...   \n",
       "RE46609  1. A backlight device that illuminates a trans...   \n",
       "\n",
       "                                                claims_org  \\\n",
       "8925188  1. A mounting apparatus comprising: a stage de...   \n",
       "8925190  1. An electronic component mounting device whi...   \n",
       "8925260  1. A method of supporting a solar panel array ...   \n",
       "8925262  1. A ridge vent system comprising: an elongate...   \n",
       "8925263  1. A photovoltaic module mounting assembly, co...   \n",
       "...                                                    ...   \n",
       "RE46435  1. A nonvolatile memory device, comprising.Iad...   \n",
       "RE46441  1. A method for the manufacture of a squalene-...   \n",
       "RE46456  1. An image processing device comprising: a fi...   \n",
       "RE46465  .[.1. A wafer transfer apparatus for transferr...   \n",
       "RE46609  1. A backlight device that illuminates a trans...   \n",
       "\n",
       "                                              forward_refs  \n",
       "8925188                           10932401;9210836;9761556  \n",
       "8925190                                           10271437  \n",
       "8925260                           10337586;9184694;9954478  \n",
       "8925262                 10281189;10739055;10845115;9695594  \n",
       "8925263  10014818;10041254;10097132;10128790;10205418;1...  \n",
       "...                                                    ...  \n",
       "RE46435  10061633;10283493;10381322;10453798;10510738;1...  \n",
       "RE46441                         10159637;10463615;10813872  \n",
       "RE46456                                           10631051  \n",
       "RE46465                            RE47145;RE47909;RE48031  \n",
       "RE46609                                           10725338  \n",
       "\n",
       "[48841 rows x 59 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.rename(columns={\"year\": \"granted_year\", \"main ipc\": \"main_ipc\", \"sub ipc\": \"sub_ipc\"}).to_csv(os.path.join(data_dir, \"collection_\" + \"\".join([config_keywords, config_ipcs, config_period]) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"class+claim\",\n",
    "#     data_file = \"collection_[H01L,H10][2017].csv\",\n",
    "    target_ipc=[\"H01L\", \"H10\"],\n",
    "    pred_type=\"classification\",\n",
    "    n_TC = 5,\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    ipc_level=4,\n",
    "    batch_size=16,\n",
    "    max_epochs=50,\n",
    "    use_accelerator=None,\n",
    "    do_save=True,\n",
    "    n_gpus=4,\n",
    "    light=True,\n",
    "#     config_file=os.path.join(root_dir, \"configs\", \"USED_configs\", \"[CONFIGS]2023-04-11_00:39.json\"),\n",
    "    config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "data_dir = os.path.join(master_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "# regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "# if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "#     configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "# elif len(configs.data.target_ipc) > 5:\n",
    "#     configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir,\n",
    "                        \"pretrained_enc\": configs.model.pretrained_enc,\n",
    "                        \"pretrained_dec\": configs.model.pretrained_dec,\n",
    "                        \"data_nrows\": None})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_enc_hidden = configs.model.d_enc_hidden = None\n",
    "    d_pred_hidden = configs.model.d_pred_hidden = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_enc_hidden = configs.model.d_enc_hidden\n",
    "    d_pred_hidden = configs.model.d_pred_hidden\n",
    "    d_latent = configs.model.d_latent\n",
    "\n",
    "    key_components = {\"data\": [\"target_ipc\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_enc_hidden\", \"d_pred_hidden\", \"d_latent\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = DotDict().load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일명 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_period = [2015, 2017] # format: [year_after, year_before] or [-1, year_before] or [year_after, -1]; \"-1\" indicates the oldest or latest year\n",
    "target_ipcs = [\"H01L\", \"H10\"]\n",
    "# target_keywords = [\"semiconductor\", \"silicon\", \"chip\"]\n",
    "target_keywords = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/data/pickled_dataset/[DATASET][semiconductor,silicon,chip][H01L,H10][2015-2017]data[3]ipc_level[30]max_seq_len_class[200]max_seq_len_claim[1500]vocab_size.pickle'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DotDict({'data_type': 'class', 'pred_type': 'classification', 'target_period': [2015, 2017], 'target_ipc': ['H01L', 'H10'], 'target_keywords': ['semiconductor', 'silicon', 'chip'], 'pred_target': 'citation', 'ipc_level': 3, 'claim_level': 1, 'class_level': 3, 'n_TC': 5, 'use_keywords': False, 'max_seq_len_class': 30, 'max_seq_len_claim': 200, 'vocab_size': 1500, 'use_pretrained_tokenizer': False})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[semiconductor,silicon,chip][H01L,H10][2015-2017]\n"
     ]
    }
   ],
   "source": [
    "config_period = \"[\"+\"-\".join([str(year) for year in configs.data.target_period])+\"]\"\n",
    "config_ipcs = str(configs.data.target_ipc).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "config_keywords = str(configs.data.target_keywords).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "dataset_config_name = \"\".join([config_keywords, config_ipcs, config_period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_name = \"\".join([config_keywords, config_ipcs, config_period]) + \"data\"\n",
    "config_period = \"[\"+\"-\".join([str(year) for year in configs.data.target_period])+\"]\"\n",
    "config_ipcs = str(configs.data.target_ipc).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "config_keywords = str(configs.data.target_keywords).replace(\"\\'\",\"\").replace(\" \",\"\")\n",
    "for component in dataset_key_components:\n",
    "    dataset_config_name += f\"[{str(configs.data[component])}]{component}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[semiconductor,silicon,chip][H01L,H10][2015-2017]data[3]ipc_level[30]max_seq_len_class[200]max_seq_len_claim[1500]vocab_size'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[DATASET]\"+dataset_config_name+\".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/data/pickled_dataset/[DATASET][semiconductor,silicon,chip][H01L,H10][2015-2017]data[3]ipc_level[30]max_seq_len_class[200]max_seq_len_claim[1500]vocab_size.pickle'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/models/[Final_model][H01Ltarget_ipc][1500vocab_size][4n_layers][16d_enc_hidden][8d_pred_hidden][64d_latent][128d_embedding][16d_ff][4n_head][32d_head][0.0005learning_rate][16batch_size][50max_epochs].ckpt'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/data/pickled_dataset/[tech_dataset]data_type=class+claim-pred_type=classification-target_ipc=H01L-target_type=citation-ipc_level=4-claim_level=1-class_level=3-n_TC=5-use_keywords=False-max_seq_len_class=30-max_seq_len_claim=200-vocab_size=1500.pickle'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_key_components = [\"ipc_level\", \"max_seq_len_class\", \"max_seq_len_claim\", \"vocab_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_type',\n",
       " 'data_file',\n",
       " 'pred_type',\n",
       " 'target_ipc',\n",
       " 'target_type',\n",
       " 'ipc_level',\n",
       " 'claim_level',\n",
       " 'class_level',\n",
       " 'n_TC',\n",
       " 'use_keywords',\n",
       " 'max_seq_len_class',\n",
       " 'max_seq_len_claim',\n",
       " 'vocab_size',\n",
       " 'use_pretrained_tokenizer']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_config_keys[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_type',\n",
       " 'pred_type',\n",
       " 'target_ipc',\n",
       " 'target_type',\n",
       " 'ipc_level',\n",
       " 'claim_level',\n",
       " 'class_level',\n",
       " 'n_TC',\n",
       " 'use_keywords',\n",
       " 'max_seq_len_class',\n",
       " 'max_seq_len_claim',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_config_keys_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'collection_[semiconductor,silicon,chip][H01L,H10][2015-2017].csv'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = \"collection_\" + \"\".join([config_keywords, config_ipcs, config_period]) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_key_components = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset...\n",
      "\n",
      "\n",
      "\n",
      "Tokenizer is trained and saved\n",
      "62.5476 sec elapsed for loading patents for class [H01L]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "org_config_keys_temp = copy.copy(org_config_keys[\"data\"])\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"use_pretrained_tokenizer\"))\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"data_file\"))\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys_temp])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "        if tech_dataset.pretrained_enc != configs.data.pretrained_enc or tech_dataset.pretrained_dec != configs.data.pretrained_dec:\n",
    "                tech_dataset.pretrained_enc = configs.data.pretrained_enc\n",
    "                tech_dataset.pretrained_dec = configs.data.pretrained_dec\n",
    "                tech_dataset.tokenizers = tech_dataset.get_tokenizers()\n",
    "        for tk in tech_dataset.tokenizers.values():\n",
    "            if \"vocab_size\" not in dir(tk):\n",
    "                tk.vocab_size = tk.get_vocab_size()\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "#     with open(dataset_path, \"wb\") as f:\n",
    "#         tech_dataset.rawdata = None\n",
    "#         pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>main_ipc</th>\n",
       "      <th>sub_ipc</th>\n",
       "      <th>ipcs</th>\n",
       "      <th>claims</th>\n",
       "      <th>TC5</th>\n",
       "      <th>TC5_digitized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9853235</th>\n",
       "      <td>9853235</td>\n",
       "      <td>H01L51/52</td>\n",
       "      <td>[H01L27/32, H05B33/04]</td>\n",
       "      <td>[H01L51/52, H01L27/32, H05B33/04]</td>\n",
       "      <td>1. A display device comprising: a light emitti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9854199</th>\n",
       "      <td>9854199</td>\n",
       "      <td>H04N05/76</td>\n",
       "      <td>[G11B27/00, G11B27/024, G11B27/032, G11B27/034...</td>\n",
       "      <td>[H04N05/76, G11B27/00, G11B27/024, G11B27/032,...</td>\n",
       "      <td>1. A method for a digital video recorder, comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9851599</th>\n",
       "      <td>9851599</td>\n",
       "      <td>G02F01/1335</td>\n",
       "      <td>[G02B05/20, G02F01/1343, G09G03/34, G09G03/36,...</td>\n",
       "      <td>[G02F01/1335, G02B05/20, G02F01/1343, G09G03/3...</td>\n",
       "      <td>1. A color display device for displaying an n-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9851864</th>\n",
       "      <td>9851864</td>\n",
       "      <td>G06F17/21</td>\n",
       "      <td>[G06F03/041, G06F03/0481, G06F03/0485, G06F03/...</td>\n",
       "      <td>[G06F17/21, G06F03/041, G06F03/0481, G06F03/04...</td>\n",
       "      <td>1. A method comprising: identifying content to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9852488</th>\n",
       "      <td>9852488</td>\n",
       "      <td>A63F09/24</td>\n",
       "      <td>[A63F13/00, G06F17/00, G06F19/00, G06Q50/34, G...</td>\n",
       "      <td>[A63F09/24, A63F13/00, G06F17/00, G06F19/00, G...</td>\n",
       "      <td>1. A computer implemented method of managing b...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537605</th>\n",
       "      <td>9537605</td>\n",
       "      <td>H04K03/00</td>\n",
       "      <td>[H04B01/04]</td>\n",
       "      <td>[H04K03/00, H04B01/04]</td>\n",
       "      <td>1. An ultra-wideband, high-power, solid-state ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538636</th>\n",
       "      <td>9538636</td>\n",
       "      <td>H05K01/02</td>\n",
       "      <td>[H05K01/03, H05K01/14, H05K01/18, H05K03/00, H...</td>\n",
       "      <td>[H05K01/02, H05K01/03, H05K01/14, H05K01/18, H...</td>\n",
       "      <td>1. An apparatus comprising: a substrate compri...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9536977</th>\n",
       "      <td>9536977</td>\n",
       "      <td>H01L29/66</td>\n",
       "      <td>[H01L21/332, H01L21/336, H01L21/8238, H01L29/739]</td>\n",
       "      <td>[H01L29/66, H01L21/332, H01L21/336, H01L21/823...</td>\n",
       "      <td>1. A semiconductor device comprising: a precur...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534772</th>\n",
       "      <td>9534772</td>\n",
       "      <td>H01L33/62</td>\n",
       "      <td>[F21K99/00, F21V03/04, F21V05/04, F21V07/00, F...</td>\n",
       "      <td>[H01L33/62, F21K99/00, F21V03/04, F21V05/04, F...</td>\n",
       "      <td>1. A lighting apparatus comprising: a pluralit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9532585</th>\n",
       "      <td>9532585</td>\n",
       "      <td>A61K35/60</td>\n",
       "      <td>[A23D09/007, A61K09/48, A61K36/534, A61K36/752]</td>\n",
       "      <td>[A61K35/60, A23D09/007, A61K09/48, A61K36/534,...</td>\n",
       "      <td>1. A capsule for delivering an odoriferous oil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33875 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          number     main_ipc  \\\n",
       "number                          \n",
       "9853235  9853235    H01L51/52   \n",
       "9854199  9854199    H04N05/76   \n",
       "9851599  9851599  G02F01/1335   \n",
       "9851864  9851864    G06F17/21   \n",
       "9852488  9852488    A63F09/24   \n",
       "...          ...          ...   \n",
       "9537605  9537605    H04K03/00   \n",
       "9538636  9538636    H05K01/02   \n",
       "9536977  9536977    H01L29/66   \n",
       "9534772  9534772    H01L33/62   \n",
       "9532585  9532585    A61K35/60   \n",
       "\n",
       "                                                   sub_ipc  \\\n",
       "number                                                       \n",
       "9853235                             [H01L27/32, H05B33/04]   \n",
       "9854199  [G11B27/00, G11B27/024, G11B27/032, G11B27/034...   \n",
       "9851599  [G02B05/20, G02F01/1343, G09G03/34, G09G03/36,...   \n",
       "9851864  [G06F03/041, G06F03/0481, G06F03/0485, G06F03/...   \n",
       "9852488  [A63F13/00, G06F17/00, G06F19/00, G06Q50/34, G...   \n",
       "...                                                    ...   \n",
       "9537605                                        [H04B01/04]   \n",
       "9538636  [H05K01/03, H05K01/14, H05K01/18, H05K03/00, H...   \n",
       "9536977  [H01L21/332, H01L21/336, H01L21/8238, H01L29/739]   \n",
       "9534772  [F21K99/00, F21V03/04, F21V05/04, F21V07/00, F...   \n",
       "9532585    [A23D09/007, A61K09/48, A61K36/534, A61K36/752]   \n",
       "\n",
       "                                                      ipcs  \\\n",
       "number                                                       \n",
       "9853235                  [H01L51/52, H01L27/32, H05B33/04]   \n",
       "9854199  [H04N05/76, G11B27/00, G11B27/024, G11B27/032,...   \n",
       "9851599  [G02F01/1335, G02B05/20, G02F01/1343, G09G03/3...   \n",
       "9851864  [G06F17/21, G06F03/041, G06F03/0481, G06F03/04...   \n",
       "9852488  [A63F09/24, A63F13/00, G06F17/00, G06F19/00, G...   \n",
       "...                                                    ...   \n",
       "9537605                             [H04K03/00, H04B01/04]   \n",
       "9538636  [H05K01/02, H05K01/03, H05K01/14, H05K01/18, H...   \n",
       "9536977  [H01L29/66, H01L21/332, H01L21/336, H01L21/823...   \n",
       "9534772  [H01L33/62, F21K99/00, F21V03/04, F21V05/04, F...   \n",
       "9532585  [A61K35/60, A23D09/007, A61K09/48, A61K36/534,...   \n",
       "\n",
       "                                                    claims  TC5  \\\n",
       "number                                                            \n",
       "9853235  1. A display device comprising: a light emitti...    0   \n",
       "9854199  1. A method for a digital video recorder, comp...    0   \n",
       "9851599  1. A color display device for displaying an n-...    0   \n",
       "9851864  1. A method comprising: identifying content to...    0   \n",
       "9852488  1. A computer implemented method of managing b...    8   \n",
       "...                                                    ...  ...   \n",
       "9537605  1. An ultra-wideband, high-power, solid-state ...    1   \n",
       "9538636  1. An apparatus comprising: a substrate compri...    2   \n",
       "9536977  1. A semiconductor device comprising: a precur...    5   \n",
       "9534772  1. A lighting apparatus comprising: a pluralit...    6   \n",
       "9532585  1. A capsule for delivering an odoriferous oil...    0   \n",
       "\n",
       "         TC5_digitized  class  \n",
       "number                         \n",
       "9853235              0    106  \n",
       "9854199              0    109  \n",
       "9851599              0     95  \n",
       "9851864              0     99  \n",
       "9852488              1     13  \n",
       "...                ...    ...  \n",
       "9537605              0    109  \n",
       "9538636              0    110  \n",
       "9536977              1    106  \n",
       "9534772              1    106  \n",
       "9532585              0     11  \n",
       "\n",
       "[33875 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.model.update({\"tokenizers\": tech_dataset.tokenizers,\n",
    "                    \"n_enc_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_dec_seq_claim\": tech_dataset.max_seq_len_claim,\n",
    "                    \"n_enc_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_dec_seq_class\": tech_dataset.max_seq_len_class,\n",
    "                    \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                    \"i_padding\": tech_dataset.tokenizers[\"class_enc\"].token_to_id(\"<PAD>\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.1, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizers=tech_dataset.tokenizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping for multi criteria 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=True, delta=0, path='../models/checkpoint.ckpt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                # Load latest saved model\n",
    "                model = self.load_model(model)\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "        return model\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\\n')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def load_model(self, model):\n",
    "        saved_model = copy.copy(model)\n",
    "        saved_model.load_state_dict(torch.load(self.path))\n",
    "        return saved_model\n",
    "\n",
    "class EarlyStopping_multi(EarlyStopping):\n",
    "    def __init__(self, patience=10, verbose=True, delta=0, path='../models/checkpoint.ckpt', criteria=None):\n",
    "        super().__init__(patience=10)\n",
    "        self.best_scores = None\n",
    "        self.delta = 0.005\n",
    "        self.deltas = None\n",
    "        if criteria is not None:\n",
    "            self.criteria = criteria\n",
    "        else:\n",
    "            self.criteria = [\"total\", \"recon\", \"y\"]\n",
    "        self.val_losses_min = {criterion: np.Inf for criterion in self.criteria}\n",
    "\n",
    "    def __call__(self, model, val_losses={}):\n",
    "        scores = {k: -val_losses[k] for k in self.criteria}\n",
    "        if self.best_scores is not None:\n",
    "            print([(self.best_scores[k], self.deltas[k], self.best_scores[k]+self.deltas[k], scores[k]) for k in self.criteria])\n",
    "\n",
    "        if self.best_scores is None:\n",
    "            self.best_scores = scores\n",
    "            self.deltas = {k: self.best_scores[k]*self.delta for k in self.criteria}\n",
    "            self.save_checkpoint(val_losses, model)\n",
    "        elif any([scores[k] < self.best_scores[k] + self.deltas[k] for k in self.criteria]):\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                # Load latest saved model\n",
    "                model = self.load_model(model)\n",
    "        else:\n",
    "            self.best_scores = scores\n",
    "            self.deltas = {k: self.best_scores[k]*self.delta for k in self.criteria}\n",
    "            self.save_checkpoint(val_losses, model)\n",
    "            self.counter = 0\n",
    "\n",
    "        return model\n",
    "\n",
    "    def save_checkpoint(self, val_losses, model):\n",
    "        if self.verbose:\n",
    "            for criterion in self.criteria:\n",
    "                print(f'Validation loss[{criterion}] decreased ({self.val_losses_min[criterion]:.6f} --> {val_losses[criterion]:.6f})')\n",
    "            print(\"\\n\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_losses_min = val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=11, verbose=True, path=\"../models/es_test.ckpt\")\n",
    "es_multi = EarlyStopping_multi(patience=10, criteria=[\"total\", \"kld\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_ = {\"total\": 10, \"recon\": 8, \"y\": 2, \"kld\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_ = {\"total\": 10, \"recon\": 7, \"y\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss[total] decreased (inf --> 10.000000)\n",
      "Validation loss[kld] decreased (inf --> 100.000000)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = es_multi(model, val_losses=losses_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': -10, 'kld': -100}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_multi.best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': -0.05, 'kld': -0.5}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_multi.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 10, 'recon': 8, 'y': 2, 'kld': 100}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_multi.val_losses_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024240216"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.024216 * 1.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024282"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.024282"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import CLS2CLS, VCLS2CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VCLS2CLS(configs.model, tokenizers=tech_dataset.tokenizers).to(configs.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = to_device(next(iter(train_loader)), device=configs.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = model.encode(batch_data[\"text_inputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs = model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dec_outputs = model.decode(z, enc_outputs[\"class\"], batch_data[\"text_outputs\"], teach_force_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dec_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational 빼고 Attention 추가해서 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import CLS2CLS, VCLS2CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLS2CLS(configs.model, tokenizers=tech_dataset.tokenizers).to(configs.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = to_device(next(iter(train_loader)), device=configs.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = model.encode(batch_data[\"text_inputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs={}\n",
    "enc_outputs[\"claim\"], *_ = model.encoders[\"claim\"](**batch_data[\"text_inputs\"][\"claim\"])\n",
    "enc_outputs[\"class\"], hidden = model.encoders[\"class\"](batch_data[\"text_inputs\"][\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs[\"class\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden.permute(1,0,2).contiguous().view(16, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.d_hidden * model.n_directions * model.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.d_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pool(enc_outputs[\"claim\"]).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs[\"class\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs = model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dec_outputs = model.decode(z, enc_outputs[\"class\"], batch_data[\"text_outputs\"], teach_force_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_anneal_function(step, func_type=\"logistic\", k=0.0025, x0=2500):\n",
    "    if func_type == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-x0))))\n",
    "    elif func_type == 'linear':\n",
    "        return min(1, step/x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_anneal_function(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(tech_dataset.X_class.apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_loader = DataLoader(whole_dataset, batch_size=len(whole_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholebatch = next(iter(whole_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictor parameter update 실험, z-sampling 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1][::-1].copy()).to(device)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "from utils import KLDLoss\n",
    "from parallel import DataParallel\n",
    "model_params = configs.model\n",
    "loss_recon = torch.nn.CrossEntropyLoss(ignore_index=model_params['i_padding'])\n",
    "loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.NLLLoss(weight=class_weights)\n",
    "loss_kld = KLDLoss()\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "batch_data = to_device(batch_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum())\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum())\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.module.freeze(module_name=\"predictor\")\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model.module.freeze(module_name=\"predictor\", defreeze=True)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, final_model.module.parameters()), lr=configs.train['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])\n",
    "preds_recon = outputs[\"dec_outputs\"].permute(0,2,1)\n",
    "trues_recon = batch_data[\"text_outputs\"]\n",
    "preds_y = outputs[\"pred_outputs\"]\n",
    "trues_y = batch_data[\"targets\"]\n",
    "preds_mu = outputs[\"mu\"]\n",
    "preds_logvar = outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_recon(preds_recon, trues_recon) + loss_kld(preds_mu, preds_logvar) + loss_y(preds_y, trues_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, z, mu, logvar = final_model.module.encode(batch_data[\"text_inputs\"])\n",
    "pred_outputs = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p.sum(), p.requires_grad)\n",
    "for p in final_model.module.predictor.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    print(\"Validate model on train dataset\")\n",
    "    # trues_recon_train, preds_recon_train, trues_y_train, preds_y_train = validate_model(final_model, whole_loader, configs.model, configs.train)\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, mp=mp, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "print(\"Validate model on test dataset\")\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, mp=mp, batch_size=64, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=configs.data.pred_type)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    confmat_y_res = pd.concat([confmat_y_train, confmat_y_test], axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
