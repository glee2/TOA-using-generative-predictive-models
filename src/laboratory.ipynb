{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from model import Encoder_SEQ, Decoder_SEQ, SEQ2SEQ, Attention, AttnDecoder_SEQ\n",
    "from train_utils import run_epoch, EarlyStopping, perf_eval\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_SOS = '<SOS>'\n",
    "TOKEN_EOS = '<EOS>'\n",
    "TOKEN_PAD = '<PAD>'\n",
    "tokens = [TOKEN_SOS, TOKEN_EOS, TOKEN_PAD]\n",
    "regex = re.compile(\"[0-9a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home2/glee/Tech_Gen/data/\"\n",
    "rawdata = pd.read_csv(os.path.join(data_root, \"collection_final.csv\"))\n",
    "rawdata_dropna = rawdata.dropna(axis=0, subset=['main ipc', 'sub ipc'])[['number','main ipc', 'sub ipc']]\n",
    "cols_year = ['<1976']+list(np.arange(1976,2018).astype(str))\n",
    "n_TC = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipc, num = np.unique(rawdata_dropna['main ipc'].apply(lambda x: x.split(' ')[0]), return_counts=True)\n",
    "ipc_vocab_size = pd.concat([pd.Series(ipc[np.argsort(num)[::-1]]), pd.Series(num[np.argsort(num)[::-1]])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A61K</td>\n",
       "      <td>44658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C07K</td>\n",
       "      <td>7686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01N</td>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C12N</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A61L</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A61F</td>\n",
       "      <td>1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A23L</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G01N</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A23K</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C07D</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C07C</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A61Q</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C07H</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C12Q</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C12P</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A61B</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C11D</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A23G</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A01K</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C08G</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0   A61K  44658\n",
       "1   C07K   7686\n",
       "2   A01N   6265\n",
       "3   C12N   2174\n",
       "4   A61L   2008\n",
       "5   A61F   1841\n",
       "6   A23L   1075\n",
       "7   G01N    820\n",
       "8   A23K    767\n",
       "9   C07D    692\n",
       "10  C07C    670\n",
       "11  A61Q    585\n",
       "12  C07H    573\n",
       "13  C12Q    531\n",
       "14  C12P    472\n",
       "15  A61B    468\n",
       "16  C11D    445\n",
       "17  A23G    406\n",
       "18  A01K    324\n",
       "19  C08G    292"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipc_vocab_size.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ipc = \"A61K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ipcs = [x for x in pd.unique(rawdata_dropna['main ipc']) if target_ipc in x]\n",
    "rawdata_ipc = rawdata_dropna.loc[rawdata_dropna['main ipc'].isin(main_ipcs)]\n",
    "data = rawdata_ipc[['number']].copy(deep=True)\n",
    "data['main_ipc'] = rawdata_ipc['main ipc'].apply(lambda x: regex.findall(x)[0])\n",
    "data['sub_ipc'] = rawdata_ipc['sub ipc'].apply(lambda x: [regex.findall(xx)[0] for xx in x.split(';')])\n",
    "\n",
    "rawdata_tc = rawdata.loc[rawdata_ipc.index][['year']+cols_year]\n",
    "data['TC'+str(n_TC)] = rawdata_tc.apply(lambda x: x[np.arange(x['year']+1 if x['year']<2017 else 2017, x['year']+n_TC+1 if x['year']+n_TC<2018 else 2018).astype(str)].sum(), axis=1)\n",
    "\n",
    "data = data.set_index('number')\n",
    "# main_ipcs = [regex.findall(x)[0] for x in main_ipcs]\n",
    "main_ipcs = [target_ipc]\n",
    "sub_ipcs = list(np.unique(np.concatenate(list(data['sub_ipc'].values))))\n",
    "all_ipcs = list(np.union1d(main_ipcs, sub_ipcs))\n",
    "seq_len = data['sub_ipc'].apply(lambda x: len(x)).max() + 3\n",
    "\n",
    "vocab_w2i = {all_ipcs[i]: i for i in range(len(all_ipcs))}\n",
    "vocab_w2i.update({tokens[i]: len(all_ipcs)+i for i in range(len(tokens))})\n",
    "vocab_i2w = {i: all_ipcs[i] for i in range(len(all_ipcs))}\n",
    "vocab_i2w.update({len(all_ipcs)+i: tokens[i] for i in range(len(tokens))})\n",
    "vocab_size = len(vocab_w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(index=data.index)\n",
    "X_df['main'] = data['main_ipc'].apply(lambda x: vocab_w2i[x])\n",
    "X_df['sub'] = data['sub_ipc'].apply(lambda x: [vocab_w2i[xx] for xx in x])\n",
    "main_sub_combined = X_df.apply(lambda x: [x['main']]+x['sub'], axis=1)\n",
    "X_df['seq'] = main_sub_combined.apply(lambda x: np.concatenate([[vocab_w2i['<SOS>']]+x+[vocab_w2i['<EOS>']], np.zeros(seq_len-(len(x)+2))+vocab_w2i['<PAD>']]).astype(int))\n",
    "\n",
    "# xaxis = np.concatenate([np.tile([i], X_df['sub'].apply(lambda x: len(x)).values[i]) for i in range(len(X_df))])\n",
    "# X = np.zeros((len(self.data), len(self.all_ipcs))) # (#samples, #ipcs)\n",
    "# X[tuple(np.arange(len(X_df))), tuple(X_df['main'].values)] += 10\n",
    "# X[tuple(xaxis), tuple(np.concatenate(X_df['sub'].values))] += 1\n",
    "\n",
    "# X = np.zeros((len(data), seq_len, len(all_ipcs)+len(tokens)))\n",
    "# X[tuple(np.sort(np.tile(np.arange(len(X_df)), seq_len))), tuple(np.tile(np.arange(seq_len), len(X_df))), tuple(np.concatenate(X_df['seq'].values))] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORM one-by-one\n",
      "27.436416625976562 sec Elapsed\n",
      "TRANSFORM as a whole\n",
      "26.884346961975098 sec Elapsed\n"
     ]
    }
   ],
   "source": [
    "print(\"TRANSFORM one-by-one\")\n",
    "tstart = time.time()\n",
    "tech_dataset = TechDataset(device=device, data_dir=data_root, do_transform=True, params={'target_ipc': target_ipc})\n",
    "data_loader = DataLoader(tech_dataset, batch_size=batch_size)\n",
    "tend = time.time()\n",
    "print(f\"{tend-tstart} sec Elapsed\")\n",
    "\n",
    "print(\"TRANSFORM as a whole\")\n",
    "tstart = time.time()\n",
    "tech_dataset = TechDataset(device=device, data_dir=data_root, do_transform=False, params={'target_ipc': target_ipc})\n",
    "data_loader = DataLoader(tech_dataset, batch_size=batch_size)\n",
    "tend = time.time()\n",
    "print(f\"{tend-tstart} sec Elapsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0036962032318115234 sec Elapsed\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "xx, yy = next(iter(data_loader))\n",
    "tend = time.time()\n",
    "print(f\"{tend-tstart} sec Elapsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder_SEQ(embedding_dim=128, vocab_size=vocab_size, hidden_dim=32, n_layers=1, device=device, padding_idx=tech_dataset.vocab_w2i['<PAD>'])\n",
    "enc = enc.to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351],\n",
       "         [-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351],\n",
       "         [-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351],\n",
       "         ...,\n",
       "         [-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351],\n",
       "         [-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351],\n",
       "         [-0.0181, -0.0901,  0.1597,  ...,  0.1031, -0.0934, -0.1351]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = Decoder_SEQ(embedding_dim=128, vocab_size=vocab_size, hidden_dim=32, n_layers=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input = torch.from_numpy(np.tile(vocab_w2i[TOKEN_SOS], 32)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.initHidden(len(next_input)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "o,h = dec(next_input, hidden=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6032])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = SEQ2SEQ(device=device, dataset=tech_dataset, enc=enc, dec=dec, max_len=tech_dataset.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, zz = seq2seq(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([168, 32, 6032])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A01C1/06', 'A23K1/14', 'A61B5/055', 'A61K31/06', 'A61K31/133',\n",
       "       'A61K31/53', 'A61K31/713', 'A61K35/64', 'A61K36/63', 'A61K39/085',\n",
       "       'A61K47/40', 'A61K8/44', 'A61M5/20', 'A61P15/00', 'B01J19/10',\n",
       "       'B01J39/14', 'B05D7/00', 'B32B5/24', 'C01B15/037', 'C01B21/24',\n",
       "       'C03C3/15', 'C07B39/00', 'C07B59/00', 'C07C229/24', 'C07C239/00',\n",
       "       'C07C25/00', 'C07C275/10', 'C07C275/40', 'C07C43/315', 'C07C59/72',\n",
       "       'C07C69/28', 'C07D207/27', 'C07D241/24', 'C07D253/00',\n",
       "       'C07D261/20', 'C07D277/34', 'C07D295/32', 'C07D305/08',\n",
       "       'C07D487/18', 'C07F9/44', 'C07K1/113', 'C07K14/555', 'C08F2/50',\n",
       "       'C08F224/00', 'C08G65/332', 'C08G77/20', 'C08G77/38', 'C08G77/458',\n",
       "       'C08J3/03', 'C09C1/62', 'C09J133/02', 'C09K15/24', 'C12N1/20',\n",
       "       'C12N5/0775', 'C12P17/12', 'C13K5/00', 'C40B30/04', 'G01N21/80',\n",
       "       'G01N33/573'], dtype='<U10')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([tech_dataset.vocab_i2w[i] for i in outputs[:,0,:].argmax(1).detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7048, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(outputs.transpose(0,1).transpose(1,2), xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 168])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = xx.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_losses = []\n",
    "\n",
    "outputs, z = seq2seq(xx) # outputs shape: (seq_len, batch_size, vocab_size)\n",
    "preds = outputs.transpose(0,1).transpose(1,2) # preds shape: (batch_size, vocab_size, seq_len), regard seq_len as additional dimension\n",
    "trues = xx.clone()\n",
    "loss = loss_fn(preds, trues)\n",
    "batch_losses.append(loss.item())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# if batch % 10 == 0 or batch == len(dataloader)-1:\n",
    "#     loss, current = loss.item(), batch*len(X)\n",
    "#     if batch == len(dataloader)-1:\n",
    "#         current = size\n",
    "#     print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.tile([0], 32)).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.tile(np.arange(30), (32,1))).squeeze(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n",
      "loss: 7.744429 [ 4800/44658]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19295/2158694661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {ep+1}\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Tech_Gen/src/train_utils.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(dataloader, model, loss_fn, mode, optimizer)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=True, path=\"../models/ES_checkpoint.ckpt\")\n",
    "for ep in range(max_epochs):\n",
    "    print(f\"Epoch {ep+1}\\n\"+str(\"-\"*30))\n",
    "    train_loss = run_epoch(data_loader, seq2seq, loss_fn, mode='train', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=1, test_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_idx = sampler.get_idx_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 25008, Validation: 6252, Test: 13398\n"
     ]
    }
   ],
   "source": [
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data\n",
    "importlib.reload(data)\n",
    "from data import TechDataset, CVSampler\n",
    "\n",
    "import model\n",
    "importlib.reload(model)\n",
    "from model import Encoder_SEQ, Decoder_SEQ, SEQ2SEQ, Attention, AttnDecoder_SEQ\n",
    "\n",
    "import train_utils\n",
    "importlib.reload(train_utils)\n",
    "from train_utils import run_epoch, EarlyStopping, perf_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new sample from latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'sequence'\n",
    "n_folds = 1\n",
    "learning_rate = 5e-3\n",
    "batch_size = 1\n",
    "max_epochs = 2\n",
    "n_gpus = 1\n",
    "embedding_dim = 128\n",
    "hidden_dim = 32\n",
    "n_layers = 3\n",
    "bidirec = None\n",
    "\n",
    "data_dir = \"/home2/glee/Tech_Gen/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ipc = 'G01N'\n",
    "train_params = {'target_ipc': target_ipc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset...\n",
      "0.8273 sec elapsed for loading patents for class [G01N]\n"
     ]
    }
   ],
   "source": [
    "print(\"Load dataset...\")\n",
    "tstart = time.time()\n",
    "tech_dataset = TechDataset(device=device, data_dir=data_dir, do_transform=False, params=train_params)\n",
    "data_loader = DataLoader(tech_dataset, batch_size=batch_size)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{train_params['target_ipc']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = next(iter(data_loader))\n",
    "x = xs[0].unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirec = True\n",
    "# hidden_dim_enc = 2 if bidirec else 1\n",
    "hidden_dim_dec = hidden_dim\n",
    "n_directions = 2 if bidirec else 1\n",
    "hidden_dim_enc = hidden_dim * n_directions if bidirec else hidden_dim\n",
    "\n",
    "enc = Encoder_SEQ(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=tech_dataset.vocab_size, n_layers=n_layers, bidirec=bidirec, device=device).to(device)\n",
    "att = Attention(hidden_dim_enc, hidden_dim).to(device)\n",
    "dec = AttnDecoder_SEQ(embedding_dim=embedding_dim, vocab_size=tech_dataset.vocab_size, hidden_dim=hidden_dim, hidden_dim_enc=hidden_dim_enc, attention=att, n_layers=n_layers, device=device, max_len=tech_dataset.seq_len).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEQ2SEQ(device=device, dataset=tech_dataset, enc=enc, dec=dec, max_len=tech_dataset.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000e+00,  3.1341e-01, -4.2600e-01,  ...,  4.2356e-02,\n",
       "            3.6929e-01,  6.3694e-01],\n",
       "          [ 0.0000e+00,  5.2404e-01,  1.2323e+00,  ...,  1.5604e-01,\n",
       "           -2.9833e-01, -2.6807e-01],\n",
       "          [ 0.0000e+00, -4.7191e-01, -2.9242e-01,  ..., -1.4210e-01,\n",
       "           -2.7083e-01,  3.7827e-02],\n",
       "          ...,\n",
       "          [ 1.0000e+00,  1.0887e+00, -8.0131e-01,  ..., -2.4319e-01,\n",
       "           -5.7250e-02, -7.0056e-02],\n",
       "          [ 0.0000e+00, -9.6376e-02, -4.5436e-01,  ...,  2.0529e-01,\n",
       "            3.7771e-01,  4.6745e-01],\n",
       "          [ 0.0000e+00, -5.0294e-01,  3.5158e-01,  ...,  5.5043e-01,\n",
       "            1.0792e-01, -2.8503e-04]]], device='cuda:0', grad_fn=<CopySlices>),\n",
       " tensor([[[ 0.9369,  0.1477, -0.9490,  0.7942,  0.6514, -0.9209,  0.0945,\n",
       "           -0.7410, -0.1404,  0.1339, -0.3090, -0.8749, -0.9897,  0.7289,\n",
       "            0.0482,  0.1574,  0.8850,  0.2707,  0.8615,  0.1815,  0.9266,\n",
       "           -0.3052,  0.7899,  0.8589,  0.9722, -0.2754, -0.3244,  0.0674,\n",
       "           -0.1678,  0.9602, -0.7070, -0.9662,  0.7330,  0.1074,  0.7944,\n",
       "           -0.7708, -0.3187,  0.2670, -0.8434, -0.4237, -0.7081, -0.2210,\n",
       "           -0.4182,  0.5508, -0.7718,  0.0922,  0.4523,  0.4320,  0.0277,\n",
       "           -0.6251,  0.1154, -0.3362,  0.4856,  0.2334,  0.3328,  0.3782,\n",
       "            0.0389,  0.1730, -0.2079,  0.4727, -0.2325,  0.3922,  0.2065,\n",
       "            0.4973]],\n",
       " \n",
       "         [[ 0.4797,  0.1247, -0.2603, -0.5312, -0.4224, -0.2166,  0.1866,\n",
       "            0.1743,  0.3628,  0.0876,  0.0635, -0.3998,  0.3598,  0.1437,\n",
       "           -0.3663,  0.1301,  0.8681,  0.2230, -0.2308,  0.8250,  0.2673,\n",
       "           -0.4941, -0.4132, -0.4864,  0.2691, -0.1957, -0.2164,  0.2076,\n",
       "            0.5472,  0.4755, -0.3664,  0.7582,  0.1789, -0.3594, -0.3700,\n",
       "            0.0336, -0.3227, -0.0328,  0.0648,  0.0768,  0.1398,  0.0238,\n",
       "           -0.3620, -0.1539,  0.2076,  0.5958,  0.3282,  0.2172, -0.1704,\n",
       "           -0.0509, -0.0132,  0.1758,  0.1461, -0.7238, -0.4279,  0.0430,\n",
       "           -0.3557, -0.0557,  0.4019,  0.1917, -0.0315,  0.0275,  0.0574,\n",
       "           -0.1655]],\n",
       " \n",
       "         [[-0.1880, -0.0180,  0.1434, -0.4630, -0.6188,  0.4536, -0.2461,\n",
       "           -0.2843, -0.0678,  0.0398,  0.1899, -0.4130,  0.0196, -0.0740,\n",
       "            0.5066, -0.0919,  0.1376, -0.0147,  0.2880, -0.1613, -0.0247,\n",
       "            0.2884, -0.2652, -0.3731, -0.4428,  0.0205, -0.1262, -0.1087,\n",
       "           -0.0387, -0.2846,  0.0413,  0.1674,  0.2146,  0.3620, -0.2519,\n",
       "            0.1531,  0.2627, -0.0762, -0.2131,  0.0209,  0.2240,  0.0156,\n",
       "            0.1721, -0.2452, -0.0129,  0.5321,  0.3338, -0.3947, -0.0181,\n",
       "           -0.0549, -0.3740,  0.0385, -0.0840, -0.1116, -0.1735,  0.1939,\n",
       "            0.1322,  0.1505, -0.0409, -0.0681, -0.2047, -0.1366,  0.3262,\n",
       "           -0.0877]]], device='cuda:0', grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o, h = enc(x)\n",
    "display(o.shape)\n",
    "display(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input = torch.from_numpy(np.tile([tech_dataset.vocab_w2i['<SOS>']], batch_size)).to(device)\n",
    "inputs = next_input.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = dec.dropout(dec.embedding(inputs))\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 14])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dec.attention(h, o)\n",
    "a = a.unsqueeze(1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = torch.bmm(a, o)\n",
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 192])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_input = torch.cat((embedded, weighted), dim=2)\n",
    "gru_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o, h = dec.gru(gru_input, h)\n",
    "display(o.shape)\n",
    "display(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=256, out_features=124, bias=True)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 124])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = dec.fc_out(torch.cat((embedded.squeeze(1), weighted.squeeze(1), o.squeeze(1)), dim=1))\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2593, -0.1279, -0.0694, -0.7554,  0.0180,  0.6668,  0.0036, -0.5078,\n",
       "           1.1024, -0.2065,  0.5753,  0.9603, -0.1081, -1.2144, -0.8858,  0.0778,\n",
       "          -0.5076, -0.2697,  0.4934, -0.4087, -0.3356,  0.3361,  0.6147, -0.0450,\n",
       "           0.0830,  1.1113, -0.3555, -0.1468,  0.0836,  1.3751, -1.2525,  0.0981,\n",
       "          -0.9191,  0.2434,  0.1560, -0.0868,  0.3900, -0.8439,  0.2458,  0.6249,\n",
       "           0.0519, -0.4166, -0.2436, -1.2634, -0.1646, -0.3555,  0.0968,  0.2803,\n",
       "          -0.2863,  1.3421,  0.4019,  0.4331,  0.4422, -0.2289,  0.6627, -0.3243,\n",
       "          -0.1927,  0.7590, -0.5286,  0.3681,  0.4035, -0.3187, -0.0964,  0.0607,\n",
       "           0.4015, -0.0627, -1.0599,  1.2583, -0.5918, -0.8080,  0.2754, -0.0161,\n",
       "          -0.0553,  0.5829, -0.5438, -0.5946, -0.4520,  0.5416,  0.5283, -0.3772,\n",
       "           0.5215,  1.0873,  0.0737, -0.0935,  0.2990, -0.4810, -0.6650, -0.0434,\n",
       "           0.5959, -0.5721, -0.0806,  0.2492,  0.9251,  0.1382, -0.3697, -0.7398,\n",
       "          -0.3065, -0.1106, -0.5809, -0.5178, -0.2017,  0.5527,  0.6691, -0.2898,\n",
       "           0.6660,  0.1457,  0.2952,  0.7329,  0.1614,  0.4602, -0.6123,  0.5540,\n",
       "          -0.1504, -0.7051,  0.5329,  0.1321,  0.4364, -0.3030,  0.3354,  0.0711,\n",
       "           0.3837, -0.0549, -0.7279,  0.4726,  0.8607,  0.0584, -0.0326,  0.2928]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[[ 0.0397,  0.0396,  0.0834,  0.2793,  0.2129,  0.8080,  0.4832,\n",
       "           -0.0172, -0.4439,  0.2816,  0.2685, -0.5190,  0.1440, -0.1331,\n",
       "           -0.5159,  0.7343,  0.1576, -0.2922, -0.0248,  0.3535, -0.7354,\n",
       "            0.8701,  0.0708, -0.4250, -0.0409,  0.0396,  0.7784, -0.3580,\n",
       "            0.1021,  0.6477, -0.2068, -0.5998, -0.1394,  0.2113, -0.1927,\n",
       "           -0.1448, -0.0465,  0.4197,  0.1110,  0.7605, -0.2075, -0.7503,\n",
       "           -0.2473, -0.1075, -0.5179, -0.0788, -0.0690, -0.2991, -0.3324,\n",
       "            0.2921,  0.2787,  0.5680, -0.1326,  0.2153, -0.6630,  0.4863,\n",
       "            0.0387,  0.6756, -0.3173, -0.2607,  0.2920,  0.5761, -0.6627,\n",
       "            0.1761]],\n",
       " \n",
       "         [[-0.1779,  0.5598,  0.2358, -0.0861, -0.0968,  0.0645,  0.1353,\n",
       "            0.2536, -0.0791,  0.2080, -0.2623,  0.2757,  0.0365, -0.1436,\n",
       "           -0.0927, -0.1343,  0.0062, -0.1913, -0.2851, -0.4406, -0.2173,\n",
       "            0.0907,  0.0906,  0.1366,  0.1912, -0.3806, -0.1339,  0.1309,\n",
       "           -0.2605, -0.1476, -0.1991,  0.0160,  0.0925, -0.0803,  0.0165,\n",
       "           -0.0488,  0.1563,  0.3351, -0.0295, -0.1186, -0.0889, -0.1515,\n",
       "           -0.1474, -0.1304,  0.0087,  0.0139, -0.0030,  0.0401, -0.0591,\n",
       "           -0.0083,  0.0527, -0.0888,  0.0639,  0.2246, -0.0750,  0.1236,\n",
       "           -0.1091, -0.2443,  0.1804, -0.0310, -0.0019, -0.0958,  0.0409,\n",
       "            0.1871]],\n",
       " \n",
       "         [[-0.0659,  0.2794, -0.1999, -0.0297, -0.0461,  0.1496,  0.1368,\n",
       "            0.0756,  0.2384, -0.0579, -0.2376,  0.0785,  0.1843,  0.0288,\n",
       "            0.1712,  0.0442,  0.0548, -0.1140, -0.1402, -0.2769, -0.1098,\n",
       "            0.0240,  0.1765, -0.1420,  0.1364,  0.0386,  0.1907, -0.0508,\n",
       "           -0.0314, -0.1573, -0.1077,  0.2398,  0.1828,  0.1684,  0.0593,\n",
       "           -0.0156, -0.1035,  0.0888,  0.0505,  0.2468,  0.0548,  0.2234,\n",
       "            0.0029, -0.0345, -0.1753, -0.0671,  0.2718,  0.0409,  0.1545,\n",
       "           -0.1321, -0.0412, -0.0211,  0.1073,  0.0273,  0.2178,  0.3091,\n",
       "            0.0604, -0.0381, -0.2390, -0.2914, -0.1965,  0.0524,  0.0255,\n",
       "            0.1768]]], device='cuda:0', grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(next_input, h, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 14, 32])\n",
      "Hidden: torch.Size([3, 1, 1, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0492,  0.0935,  0.1818,  0.1779, -0.1556, -0.1263,  0.1913,  0.0110,\n",
       "         0.3083,  0.0604, -0.0022,  0.0829, -0.0466, -0.0852, -0.0333,  0.0906,\n",
       "        -0.1912, -0.2740, -0.3841, -0.0205,  0.4372,  0.2543, -0.4319,  0.0114,\n",
       "         0.3794, -0.1230, -0.0715,  0.0517, -0.2004,  0.0962,  0.3339, -0.0496],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0492,  0.0935,  0.1818,  0.1779, -0.1556, -0.1263,  0.1913,\n",
       "           0.0110,  0.3083,  0.0604, -0.0022,  0.0829, -0.0466, -0.0852,\n",
       "          -0.0333,  0.0906, -0.1912, -0.2740, -0.3841, -0.0205,  0.4372,\n",
       "           0.2543, -0.4319,  0.0114,  0.3794, -0.1230, -0.0715,  0.0517,\n",
       "          -0.2004,  0.0962,  0.3339, -0.0496]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input: torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "embedded = enc.dropout(enc.embedding(x))\n",
    "h_init = enc.initHidden(len(x))\n",
    "o, h = enc.gru(embedded, h_init)\n",
    "# o, h = enc(x)\n",
    "\n",
    "h = h.view(n_layers, n_directions, batch_size, hidden_dim)\n",
    "\n",
    "print(f\"Output: {o.shape}\\nHidden: {h.shape}\")\n",
    "display(o[0, -1, :])\n",
    "display(h[-1].view(1, batch_size, -1))\n",
    "\n",
    "print(f\"Decoder input: {h[-1].view(batch_size, -1).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirec = True\n",
    "hidden_dim_dec = hidden_dim\n",
    "n_directions = 2 if bidirec else 1\n",
    "hidden_dim_enc = hidden_dim * n_directions if bidirec else hidden_dim\n",
    "\n",
    "enc = Encoder_SEQ(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=tech_dataset.vocab_size, n_layers=n_layers, bidirec=bidirec, device=device).to(device)\n",
    "att = Attention(hidden_dim_enc, hidden_dim).to(device)\n",
    "dec = AttnDecoder_SEQ(embedding_dim=embedding_dim, vocab_size=tech_dataset.vocab_size, hidden_dim=hidden_dim, hidden_dim_enc=hidden_dim_enc, attention=att, n_layers=n_layers, device=device, max_len=tech_dataset.seq_len).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 14, 64])\n",
      "Hidden: torch.Size([6, 1, 32])\n",
      "\n",
      "\n",
      "Forward path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.3894,  0.1263,  0.3037,  0.1269, -0.2423, -0.0099, -0.2339, -0.1918,\n",
       "         0.2486,  0.1912,  0.1601,  0.1636,  0.0296,  0.0112, -0.1474, -0.3327,\n",
       "        -0.3583,  0.0165,  0.1912,  0.1198, -0.0237, -0.4782, -0.4266,  0.1147,\n",
       "        -0.1303,  0.0557,  0.2897, -0.2572, -0.0884, -0.1820,  0.0453, -0.1080],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.3894,  0.1263,  0.3037,  0.1269, -0.2423, -0.0099, -0.2339, -0.1918,\n",
       "         0.2486,  0.1912,  0.1601,  0.1636,  0.0296,  0.0112, -0.1474, -0.3327,\n",
       "        -0.3583,  0.0165,  0.1912,  0.1198, -0.0237, -0.4782, -0.4266,  0.1147,\n",
       "        -0.1303,  0.0557,  0.2897, -0.2572, -0.0884, -0.1820,  0.0453, -0.1080],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0863,  0.0435,  0.0377,  0.1924,  0.4576, -0.2691, -0.1307, -0.3650,\n",
       "         0.0121, -0.0415, -0.0392, -0.0167, -0.1014, -0.0982,  0.0960,  0.0190,\n",
       "         0.0186, -0.2130, -0.2207, -0.1993, -0.1893,  0.2042, -0.1854,  0.2084,\n",
       "        -0.1118,  0.0477, -0.1088,  0.1508, -0.1061, -0.3245, -0.0222, -0.1679],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0863,  0.0435,  0.0377,  0.1924,  0.4576, -0.2691, -0.1307, -0.3650,\n",
       "         0.0121, -0.0415, -0.0392, -0.0167, -0.1014, -0.0982,  0.0960,  0.0190,\n",
       "         0.0186, -0.2130, -0.2207, -0.1993, -0.1893,  0.2042, -0.1854,  0.2084,\n",
       "        -0.1118,  0.0477, -0.1088,  0.1508, -0.1061, -0.3245, -0.0222, -0.1679],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input: torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "embedded = enc.dropout(enc.embedding(x))\n",
    "h_init = enc.initHidden(len(x))\n",
    "o, h = enc.gru(embedded, h_init)\n",
    "# o, h = enc(x)\n",
    "print(f\"Output: {o.shape}\\nHidden: {h.shape}\\n\\n\")\n",
    "\n",
    "h = h.view(n_layers, n_directions, batch_size, hidden_dim)\n",
    "\n",
    "print(\"Forward path\")\n",
    "display(o[0, -1, :hidden_dim])\n",
    "display(h[-1, 0, 0, :])\n",
    "print(\"Backward path\")\n",
    "display(o[0, 0, hidden_dim:])\n",
    "display(h[-1, -1, 0, :])\n",
    "\n",
    "print(f\"Decoder input: {h[-1].view(batch_size, -1).shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
