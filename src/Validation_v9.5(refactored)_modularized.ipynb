{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4578eaf5",
   "metadata": {},
   "source": [
    "# 신뢰성 검증 함수 모듈화\n",
    "\n",
    "기존 `validate_reliability` 함수를 여러 개의 작은 함수로 모듈화하여 코드의 가독성과 재사용성을 높였습니다. 모듈화된 함수들은 다음과 같은 기능을 수행합니다:\n",
    "\n",
    "1. **입력 데이터 준비**: 모델에 입력될 데이터를 준비\n",
    "2. **인코딩 및 초기 예측**: 모델을 통한 데이터 인코딩 및 초기 예측\n",
    "3. **순방향 참조 분석**: 특허의 인용 관계 분석\n",
    "4. **잠재 공간 최적화**: 경사 하강법을 통한 잠재 벡터 최적화\n",
    "5. **IPC 생성 및 검증**: 생성된 IPC 코드의 검증\n",
    "6. **결과 분석 및 수집**: 분석 결과 수집\n",
    "\n",
    "아래는 모듈화된 함수들의 구현입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0775348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from utils import to_device\n",
    "\n",
    "def prepare_input_data(tech_dataset, used_test_index_TC, idx, model):\n",
    "    \"\"\"\n",
    "    입력 데이터를 준비하고 모델 장치에 로드합니다.\n",
    "    \"\"\"\n",
    "    # 클래스와 클레임 데이터 인코딩\n",
    "    input_class = torch.tensor(tech_dataset.tokenizers[\"class_enc\"].encode(tech_dataset.X_class[used_test_index_TC][idx])).unsqueeze(0)\n",
    "    input_claim = tech_dataset.tokenize(tech_dataset.tokenizers[\"claim_enc\"], tech_dataset.X_claim[used_test_index_TC][idx])\n",
    "    input_claim = {k: v.unsqueeze(0) for k, v in input_claim.items()}\n",
    "    \n",
    "    # 배치 입력 생성 및 모델 장치로 전송\n",
    "    batch_input = {\"class\": torch.tensor(input_class), \"claim\": input_claim}\n",
    "    input_inf = to_device(batch_input, model.device)\n",
    "    \n",
    "    return input_inf, input_class\n",
    "\n",
    "def encode_and_predict(model, input_inf):\n",
    "    \"\"\"\n",
    "    입력 데이터를 인코딩하고 초기 예측을 수행합니다.\n",
    "    \"\"\"\n",
    "    enc_outputs, z, mu, logvar = model.encode(input_inf)\n",
    "    pred_outputs = model.predict(z)\n",
    "    \n",
    "    return enc_outputs, z, mu, logvar, pred_outputs\n",
    "\n",
    "def analyze_forward_references(used_test_data_TC, used_rawdata, total_data, idx, n_TC):\n",
    "    \"\"\"\n",
    "    순방향 참조를 분석하여 참조된 특허의 IPC 코드와 인용 수를 가져옵니다.\n",
    "    \"\"\"\n",
    "    # 순방향 참조가 있는지 확인\n",
    "    if used_test_data_TC.iloc[idx][\"TC5\"] <= 0:\n",
    "        return False, None, None\n",
    "    \n",
    "    # 순방향 참조 정보 가져오기\n",
    "    forward_refs = used_rawdata.loc[used_test_data_TC.iloc[idx][\"patent_number\"]][\"forward_refs\"].split(\";\")\n",
    "    ref_info = total_data.loc[[ref for ref in forward_refs if ref in total_data.index]]\n",
    "    \n",
    "    if len(ref_info) == 0:\n",
    "        return False, None, None\n",
    "        \n",
    "    # 참조된 특허들의 IPC 코드와 인용 수\n",
    "    ref_ipcs = ref_info[\"patent_classes\"].apply(lambda x: set(x))\n",
    "    ref_FCs = ref_info[\"TC\" + str(n_TC)]\n",
    "    \n",
    "    return True, ref_ipcs, ref_FCs\n",
    "\n",
    "def decode_original_text(tech_dataset, input_class):\n",
    "    \"\"\"\n",
    "    원본 IPC 코드를 디코딩합니다.\n",
    "    \"\"\"\n",
    "    tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "    org_text = tokenizer.decode_batch(input_class.cpu().detach().numpy())[0]\n",
    "    org_text = org_text[org_text.index(tokenizer.sos_token)+1:org_text.index(tokenizer.eos_token)]\n",
    "    \n",
    "    return org_text\n",
    "\n",
    "def check_same_ipcs(org_text, ref_ipcs):\n",
    "    \"\"\"\n",
    "    원본 IPC와 참조된 특허들의 IPC가 동일한지 확인합니다.\n",
    "    \"\"\"\n",
    "    return set(org_text) == set(np.concatenate(ref_ipcs.apply(lambda x: list(x)).values))\n",
    "\n",
    "def breakdown(ipcs):\n",
    "    \"\"\"\n",
    "    IPC 코드를 다양한 레벨(섹션, 클래스, 서브클래스, 전체)로 분류합니다.\n",
    "    \"\"\"\n",
    "    return ([ipc[0] for ipc in ipcs], [ipc[:3] for ipc in ipcs], [ipc[:4] for ipc in ipcs], ipcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd18f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_latent_space(model, z, enc_outputs, tech_dataset, L1_threshold, n_iter, step_size):\n",
    "    \"\"\"\n",
    "    경사 하강법을 통해 잠재 공간을 최적화하여 L1_threshold 이상의 인용 수를 갖는 IPC 코드를 생성합니다.\n",
    "    \"\"\"\n",
    "    tokenizer = tech_dataset.tokenizers[\"class_dec\"]\n",
    "    optimized = False\n",
    "    gen_text = None\n",
    "    FC_estimated = 0\n",
    "    \n",
    "    # 경사 하강법을 통한 최적화 반복\n",
    "    for i in range(n_iter):\n",
    "        pred_outputs = model.predict(z)\n",
    "        z.retain_grad()\n",
    "        FC_estimated = np.round(np.exp(pred_outputs[0,1].item()), 4)  # 예상 인용 수\n",
    "        \n",
    "        # L1 오차 계산 및 역전파\n",
    "        L1_error = (1 - torch.exp(pred_outputs[0,1]))\n",
    "        L1_error.backward(retain_graph=True)\n",
    "        \n",
    "        # 경사 방향으로 잠재 벡터 업데이트\n",
    "        grad_for_update = step_size * z.grad\n",
    "        z_ = z - grad_for_update\n",
    "        \n",
    "        z.grad.zero_()\n",
    "        \n",
    "        # 새 잠재 벡터로 IPC 코드 생성\n",
    "        dec_outputs = model.decode(z_, enc_outputs, dec_inputs=None)\n",
    "        dec_outputs = dec_outputs.argmax(-1)\n",
    "        \n",
    "        # 생성된 IPC 코드 디코딩\n",
    "        gen_text = tokenizer.decode_batch(dec_outputs.cpu().detach().numpy())[0]\n",
    "        if tokenizer.eos_token in gen_text:\n",
    "            gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:gen_text.index(tokenizer.eos_token)]\n",
    "        else:\n",
    "            gen_text = gen_text[gen_text.index(tokenizer.sos_token)+1:]\n",
    "            \n",
    "        # 생성된 IPC 코드 정제\n",
    "        if gen_text != []:\n",
    "            gen_text = [gen_text[0]] + list(np.array(gen_text[1:])[np.unique(gen_text[1:], return_index=True)[1]])\n",
    "            gen_text = set(gen_text)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 충분한 인용 수가 예상되면 최적화 종료\n",
    "        if FC_estimated >= L1_threshold:\n",
    "            optimized = True\n",
    "            break\n",
    "            \n",
    "        z = z_\n",
    "        \n",
    "    return optimized, gen_text, FC_estimated, z\n",
    "\n",
    "def validate_generated_ipc(gen_text, ref_ipcs, ref_FCs):\n",
    "    \"\"\"\n",
    "    생성된 IPC 코드와 참조된 특허들의 IPC 코드를 비교하여 검증합니다.\n",
    "    \"\"\"\n",
    "    inclusions = [None, None, None, None]\n",
    "    higher_impacts = [None, None, None, None]\n",
    "    similar_refs = [None, None, None, None]\n",
    "    unsimilar_refs = [None, None, None, None]\n",
    "    \n",
    "    # IPC 코드 분류\n",
    "    gen_text_breakdown = breakdown(gen_text)\n",
    "    ref_ipcs_breakdown = (\n",
    "        ref_ipcs.apply(lambda x: breakdown(x)[0]),\n",
    "        ref_ipcs.apply(lambda x: breakdown(x)[1]),\n",
    "        ref_ipcs.apply(lambda x: breakdown(x)[2]),\n",
    "        ref_ipcs\n",
    "    )\n",
    "    \n",
    "    # 각 레벨에서 검증 수행\n",
    "    for i in range(4):\n",
    "        if inclusions[i] is not None:\n",
    "            continue\n",
    "            \n",
    "        temp_gen_text = gen_text_breakdown[i]\n",
    "        temp_ref_ipcs = ref_ipcs_breakdown[i]\n",
    "        \n",
    "        # 생성된 IPC와 일치하는 참조 찾기\n",
    "        hit_index = temp_ref_ipcs.apply(lambda x: 1 if set(x) == set(temp_gen_text) else 0) == 1\n",
    "        similar_refs[i] = temp_ref_ipcs[hit_index].index\n",
    "        unsimilar_refs[i] = temp_ref_ipcs[~hit_index].index\n",
    "        \n",
    "        # 참조가 없는 경우\n",
    "        if len(similar_refs[i]) == 0:\n",
    "            inclusions[i] = 0\n",
    "            higher_impacts[i] = None\n",
    "        # 모든 참조가 일치하는 경우\n",
    "        elif len(unsimilar_refs[i]) == 0:\n",
    "            inclusions[i] = 1\n",
    "            similar_mean_FC = np.mean(ref_FCs.loc[similar_refs[i]])\n",
    "            higher_impacts[i] = 1 if similar_mean_FC > 0 else 0\n",
    "        # 일부 참조가 일치하는 경우\n",
    "        else:\n",
    "            inclusions[i] = 1\n",
    "            similar_mean_FC = np.mean(ref_FCs.loc[similar_refs[i]])\n",
    "            unsimilar_mean_FC = np.mean(ref_FCs.loc[unsimilar_refs[i]])\n",
    "            \n",
    "            if similar_mean_FC >= unsimilar_mean_FC:\n",
    "                higher_impacts[i] = 1 if similar_mean_FC > 0 else None\n",
    "            else:\n",
    "                higher_impacts[i] = 0\n",
    "    \n",
    "    return inclusions, higher_impacts, similar_refs, unsimilar_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_reliability(model=None, idx=None, L1_threshold=0.5, n_iter=30, step_size=40):\n",
    "    \"\"\"\n",
    "    생성된 IPC 코드의 신뢰성을 검증합니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 사용할 모델\n",
    "        idx: 현재 검증할 샘플의 인덱스\n",
    "        L1_threshold: L1 임계값\n",
    "        n_iter: 최적화 반복 횟수\n",
    "        step_size: 경사 하강법의 단계 크기\n",
    "        \n",
    "    Returns:\n",
    "        counters: (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs, cnt_diff_ipcs)\n",
    "        results: 검증 결과 또는 None (실패 시)\n",
    "    \"\"\"\n",
    "    # 카운터 초기화\n",
    "    cnt_nonexist = 0\n",
    "    cnt_noFC = 0\n",
    "    cnt_diverge = 0\n",
    "    cnt_same_ipcs = 0\n",
    "    cnt_diff_ipcs = 0\n",
    "    \n",
    "    # 1. 입력 데이터 준비\n",
    "    input_inf, input_class = prepare_input_data(tech_dataset, used_test_index_TC, idx, model)\n",
    "    \n",
    "    # 2. 모델 인코딩 및 초기 예측\n",
    "    enc_outputs, z, mu, logvar, pred_outputs = encode_and_predict(model, input_inf)\n",
    "    \n",
    "    # 3. 순방향 참조 분석\n",
    "    ref_exists, ref_ipcs, ref_FCs = analyze_forward_references(used_test_data_TC, used_rawdata, total_data, idx, n_TC)\n",
    "    \n",
    "    if not ref_exists:\n",
    "        if used_test_data_TC.iloc[idx][\"TC5\"] <= 0:\n",
    "            cnt_noFC += 1\n",
    "        else:\n",
    "            cnt_nonexist += 1\n",
    "        return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs, cnt_diff_ipcs), None\n",
    "    \n",
    "    # 4. 원본 IPC 코드 디코딩\n",
    "    org_text = decode_original_text(tech_dataset, input_class)\n",
    "    \n",
    "    # 5. 원본 IPC와 참조 IPC가 동일한지 확인\n",
    "    if check_same_ipcs(org_text, ref_ipcs):\n",
    "        cnt_same_ipcs += 1\n",
    "    \n",
    "    # 6. 잠재 공간 최적화를 통한 IPC 코드 생성\n",
    "    optimized, gen_text, FC_estimated, z = optimize_latent_space(model, z, enc_outputs, tech_dataset, L1_threshold, n_iter, step_size)\n",
    "    \n",
    "    if not optimized:\n",
    "        cnt_diverge += 1\n",
    "        return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs, cnt_diff_ipcs), None\n",
    "    \n",
    "    # 7. 생성된 IPC 코드 검증\n",
    "    inclusions, higher_impacts, similar_refs, unsimilar_refs = validate_generated_ipc(gen_text, ref_ipcs, ref_FCs)\n",
    "    \n",
    "    # 8. 최종 결과 수집\n",
    "    cnt_diff_ipcs += 1\n",
    "    results = {\n",
    "        \"index\": idx,\n",
    "        \"patent_id\": used_test_data_TC.iloc[idx][\"patent_number\"],\n",
    "        \"org_text\": org_text,\n",
    "        \"gen_text\": gen_text,\n",
    "        \"ref_ipcs\": ref_ipcs,\n",
    "        \"ref_FCs\": ref_FCs,\n",
    "        \"inclusions\": inclusions,\n",
    "        \"higher_impacts\": higher_impacts,\n",
    "        \"FC_estimated\": FC_estimated,\n",
    "        \"similar_refs\": similar_refs,\n",
    "        \"unsimilar_refs\": unsimilar_refs\n",
    "    }\n",
    "    \n",
    "    return (cnt_nonexist, cnt_noFC, cnt_diverge, cnt_same_ipcs, cnt_diff_ipcs), results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9363d1",
   "metadata": {},
   "source": [
    "## 모듈화 후 성능 테스트\n",
    "\n",
    "모듈화된 함수를 사용하여 이전과 동일한 결과를 얻는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시: 모듈화된 함수 테스트\n",
    "test_idx = 0  # 테스트할 샘플 인덱스\n",
    "\n",
    "# 기존 함수와 모듈화된 함수의 결과 비교\n",
    "original_counters, original_results = validate_reliability(model=model, idx=test_idx)\n",
    "\n",
    "print(\"테스트 샘플:\", test_idx)\n",
    "if original_results is not None:\n",
    "    print(\"원본 IPC:\", original_results[\"org_text\"])\n",
    "    print(\"생성된 IPC:\", original_results[\"gen_text\"])\n",
    "    print(\"예상 인용 수:\", original_results[\"FC_estimated\"])\n",
    "    print(\"IPC 포함 여부:\", original_results[\"inclusions\"])\n",
    "    print(\"더 높은 영향력 여부:\", original_results[\"higher_impacts\"])\n",
    "else:\n",
    "    print(\"결과 없음. 원인:\", original_counters)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
