{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/'\n",
    "master_dir = '/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer, Predictor\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict, to_device\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"class+claim\",\n",
    "    data_file = \"collection_[H01L,H10][2017].csv\",\n",
    "    target_ipc=\"H01L\",\n",
    "    pred_type=\"classification\",\n",
    "    n_TC = 5,\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    batch_size=16,\n",
    "    max_epochs=50,\n",
    "    use_accelerator=None,\n",
    "    do_save=True,\n",
    "    n_gpus=4,\n",
    "    light=True,\n",
    "#     config_file=os.path.join(root_dir, \"configs\", \"USED_configs\", \"[CONFIGS]2023-04-11_00:39.json\"),\n",
    "    config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "data_dir = os.path.join(master_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "    configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "elif len(configs.data.target_ipc) > 5:\n",
    "    configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir,\n",
    "                        \"pretrained_enc\": configs.model.pretrained_enc,\n",
    "                        \"pretrained_dec\": configs.model.pretrained_dec})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_hidden = configs.model.d_hidden = None\n",
    "    d_latent = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_hidden = configs.model.d_hidden\n",
    "    d_latent = 64\n",
    "\n",
    "    key_components = {\"data\": [\"target_ipc\", \"pred_type\", \"max_seq_len\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_hidden\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\", \"take_last_h\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.model.update({\"d_latent\": d_latent})\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset...\n",
      "\n",
      "\n",
      "\n",
      "Tokenizer is trained and saved\n",
      "65.6316 sec elapsed for loading patents for class [H01L]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "org_config_keys_temp = copy.copy(org_config_keys[\"data\"])\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"use_pretrained_tokenizer\"))\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"data_file\"))\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys_temp])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        tech_dataset.rawdata = None\n",
    "        pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")\n",
    "\n",
    "configs.model.update({\"tokenizers\": tech_dataset.tokenizers,\n",
    "                        \"n_enc_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_dec_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                        \"i_padding\": tech_dataset.tokenizers[\"class_enc\"].token_to_id(\"<PAD>\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number\n",
       "9853235                    [H01L51/52, H01L27/32, H05B33/04]\n",
       "9854199    [H04N5/76, G11B27/00, G11B27/024, G11B27/032, ...\n",
       "9851599    [G02F1/1335, G02B5/20, G02F1/1343, G09G3/34, G...\n",
       "9851864    [G06F17/21, G06F17/30, G06F3/041, G06F3/0481, ...\n",
       "9852488    [A63F9/24, A63F13/00, G06F17/00, G06F19/00, G0...\n",
       "                                 ...                        \n",
       "9537605                                 [H04K3/00, H04B1/04]\n",
       "9538636    [H05K1/02, H05K1/03, H05K1/14, H05K1/18, H05K3...\n",
       "9536977    [H01L29/66, H01L21/332, H01L21/336, H01L21/823...\n",
       "9534772    [H01L33/62, F21K99/00, F21V19/00, F21V23/00, F...\n",
       "9532585    [A61K35/60, A23D9/007, A61K36/534, A61K36/752,...\n",
       "Name: ipcs, Length: 33875, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_dataset.X_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = tech_dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 24389, Validation: 6098, Test: 3388\n"
     ]
    }
   ],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.1, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models, train_utils, parallel, utils\n",
    "importlib.reload(models)\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(parallel)\n",
    "importlib.reload(utils)\n",
    "from train_utils import build_model\n",
    "from models import CLS2CLS\n",
    "from utils import to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizers=tech_dataset.tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "batch_data = to_device(batch_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = final_model.module(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dec_outputs': tensor([[[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [-1.5503e-01, -2.4224e-01,  1.4459e-02,  ...,  7.2252e-02,\n",
       "            8.0703e-01,  4.5656e-01],\n",
       "          [ 2.8623e-01, -1.0580e-01, -9.4797e-02,  ...,  2.1181e-02,\n",
       "           -8.3069e-02,  1.6214e-01],\n",
       "          ...,\n",
       "          [ 2.8654e-01,  1.1257e-01, -3.2799e-01,  ...,  5.1421e-01,\n",
       "           -7.5088e-02, -1.0709e-01],\n",
       "          [ 3.0195e-01,  2.4482e-01,  6.6970e-02,  ..., -7.9493e-01,\n",
       "           -2.9784e-01,  5.3738e-01],\n",
       "          [ 9.1799e-01, -5.8607e-03,  1.3725e-01,  ..., -3.1421e-01,\n",
       "           -1.9132e-01, -1.3829e-01]],\n",
       " \n",
       "         [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [-1.5678e-01, -1.4966e-01, -6.4586e-02,  ...,  1.6719e-01,\n",
       "            4.3984e-01, -1.7677e-01],\n",
       "          [-1.9271e-01, -5.8035e-02, -2.1910e-01,  ..., -3.7587e-01,\n",
       "            2.6471e-02, -4.6421e-01],\n",
       "          ...,\n",
       "          [ 3.9806e-02, -2.9529e-01,  2.2305e-01,  ...,  2.6370e-01,\n",
       "            4.3087e-05, -1.1394e-01],\n",
       "          [-4.3083e-01,  3.2966e-01, -2.4087e-01,  ...,  3.5628e-01,\n",
       "            3.1045e-01,  8.0504e-01],\n",
       "          [ 8.2258e-01, -2.8586e-01, -2.0203e-01,  ..., -3.8477e-01,\n",
       "           -2.3897e-01,  9.3922e-02]],\n",
       " \n",
       "         [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [-9.1549e-02, -3.6238e-01, -4.4059e-01,  ...,  1.9153e-01,\n",
       "            5.2201e-01,  2.1898e-01],\n",
       "          [ 4.0642e-01,  1.0866e-01, -5.8692e-01,  ..., -3.8085e-01,\n",
       "           -1.6508e-01, -4.1791e-01],\n",
       "          ...,\n",
       "          [ 2.7853e-01,  3.7871e-01,  5.2552e-01,  ..., -4.8051e-01,\n",
       "            2.7125e-01, -3.4663e-01],\n",
       "          [-6.5541e-02,  1.0975e-01,  1.3020e-01,  ...,  2.5390e-01,\n",
       "            3.1729e-01, -2.9879e-01],\n",
       "          [ 4.7566e-01, -6.5533e-01,  3.0275e-01,  ..., -4.3781e-01,\n",
       "           -1.2387e-01,  2.8315e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [ 7.0367e-02,  2.7606e-01, -1.8770e-01,  ...,  2.8774e-01,\n",
       "            4.2701e-01,  2.0685e-01],\n",
       "          [-2.6937e-01,  1.2054e-03,  8.8026e-01,  ..., -3.9200e-02,\n",
       "            1.0277e+00, -3.9333e-01],\n",
       "          ...,\n",
       "          [-2.2941e-01, -2.3504e-02, -6.5680e-01,  ..., -1.4755e-01,\n",
       "           -2.5214e-01, -9.2937e-02],\n",
       "          [ 3.4095e-01,  3.6940e-02,  2.0347e-01,  ..., -5.3151e-01,\n",
       "            3.9740e-02, -2.3852e-01],\n",
       "          [ 7.6488e-01, -3.5256e-01,  7.9469e-02,  ..., -3.4808e-02,\n",
       "           -9.0215e-02, -1.9087e-01]],\n",
       " \n",
       "         [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [-3.1787e-02, -6.7342e-02, -2.4974e-01,  ...,  3.1132e-01,\n",
       "            7.0969e-01,  5.8489e-01],\n",
       "          [-1.4453e-01, -8.0752e-01,  6.1751e-01,  ..., -9.6604e-02,\n",
       "            1.0860e+00,  2.1988e-01],\n",
       "          ...,\n",
       "          [ 2.2476e-01,  6.0334e-02,  1.8834e-01,  ..., -1.6824e-01,\n",
       "            1.4098e-01,  3.2529e-01],\n",
       "          [ 1.2347e-01,  1.4723e-01,  2.3928e-01,  ..., -7.3630e-01,\n",
       "            6.3743e-01, -1.5850e-01],\n",
       "          [ 4.7264e-01, -3.6219e-01,  1.6370e-01,  ..., -2.8528e-01,\n",
       "           -2.7653e-01,  2.5100e-01]],\n",
       " \n",
       "         [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "            1.0000e+00,  1.0000e+00],\n",
       "          [-2.3534e-01, -2.7072e-01, -4.6964e-01,  ..., -1.4341e-01,\n",
       "            1.5341e-01,  8.3109e-01],\n",
       "          [-2.9066e-01, -1.9497e-01, -3.5599e-01,  ..., -6.9316e-01,\n",
       "           -5.2862e-02, -8.2661e-03],\n",
       "          ...,\n",
       "          [-1.4251e-01, -1.3724e-01, -9.1219e-02,  ..., -9.7104e-02,\n",
       "            4.1470e-01,  3.1094e-01],\n",
       "          [-3.5823e-01, -4.4868e-01,  4.1540e-01,  ..., -4.8159e-01,\n",
       "            1.8224e-01,  7.8348e-02],\n",
       "          [ 5.7249e-01, -2.2000e-01,  1.3641e-01,  ..., -2.8680e-01,\n",
       "           -3.5678e-01, -3.4339e-02]]], device='cuda:0', grad_fn=<CopySlices>),\n",
       " 'z': tensor([[ 1.9065, -3.3051, -1.5559,  ...,  1.8725, -0.9791,  1.0985],\n",
       "         [ 1.3030, -1.0894, -2.0535,  ...,  0.7469, -0.2958,  0.8724],\n",
       "         [-2.5056,  0.9561,  0.1492,  ...,  2.1630, -0.4399,  0.6465],\n",
       "         ...,\n",
       "         [ 0.1448,  0.4164, -0.5618,  ..., -1.1141, -1.1881,  0.1843],\n",
       "         [-0.5277,  0.0131, -0.7584,  ...,  0.5769, -1.4856,  1.1717],\n",
       "         [ 1.4803, -2.5359, -0.1412,  ...,  0.6070, -0.2015,  0.1123]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'pred_outputs': tensor([[-0.7557, -0.6343],\n",
       "         [-0.8262, -0.5758],\n",
       "         [-0.8204, -0.5803],\n",
       "         [-0.7997, -0.5968],\n",
       "         [-0.8256, -0.5762],\n",
       "         [-0.8010, -0.5958],\n",
       "         [-0.7905, -0.6044],\n",
       "         [-0.7314, -0.6563],\n",
       "         [-0.8197, -0.5808],\n",
       "         [-0.8826, -0.5340],\n",
       "         [-0.7484, -0.6408],\n",
       "         [-0.7538, -0.6360],\n",
       "         [-0.8139, -0.5854],\n",
       "         [-0.7633, -0.6276],\n",
       "         [-0.7126, -0.6741],\n",
       "         [-0.6913, -0.6950]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " 'mu': tensor([[-0.1880, -0.4037, -0.6915,  ...,  0.8102, -0.5505,  0.5526],\n",
       "         [-0.1635, -0.2549, -0.6593,  ...,  0.7928, -0.7553,  0.3782],\n",
       "         [-0.3156, -0.1375, -0.6792,  ...,  1.0078, -0.5636,  0.9152],\n",
       "         ...,\n",
       "         [-0.2237, -0.2126, -0.5697,  ...,  0.7408, -0.5973,  0.5040],\n",
       "         [-0.1359, -0.5750, -0.4217,  ...,  1.1563, -0.5669,  0.6282],\n",
       "         [-0.2325, -0.4587, -0.5686,  ...,  1.0792, -0.3341,  0.5755]],\n",
       "        device='cuda:0', grad_fn=<MmBackward0>),\n",
       " 'logvar': tensor([[ 0.3993,  0.6753, -0.4479,  ...,  0.1330, -0.4895, -1.2613],\n",
       "         [ 0.4733,  0.6559, -0.7315,  ...,  0.0533, -0.8130, -1.3626],\n",
       "         [ 0.2518,  0.7637, -0.4486,  ..., -0.2111, -0.9237, -1.3722],\n",
       "         ...,\n",
       "         [ 0.6653,  0.8673, -0.6355,  ..., -0.0290, -0.4659, -1.3320],\n",
       "         [ 0.4337,  0.8663, -0.5708,  ..., -0.1423, -0.5139, -1.1540],\n",
       "         [ 0.6257,  0.8046, -0.6564,  ...,  0.0296, -0.6805, -1.2677]],\n",
       "        device='cuda:0', grad_fn=<MmBackward0>)}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = batch_data[\"text_inputs\"]\n",
    "dec_inputs = batch_data[\"text_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs = {}\n",
    "enc_outputs[\"claim\"], *_ = final_model.module.encoders[\"claim\"](**enc_inputs[\"claim\"])\n",
    "enc_outputs[\"class\"], *_ = final_model.module.encoders[\"class\"](enc_inputs[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 128])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs[\"class\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = {}\n",
    "pooled[\"claim\"] = final_model.module.pool(enc_outputs[\"claim\"])\n",
    "pooled[\"class\"] = final_model.module.pool(enc_outputs[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_cat = torch.cat(list(pooled.values()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, mu, logvar = final_model.module.calculate_latent(pooled_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input = torch.tensor(np.tile([final_model.module.tokenizers[\"class_enc\"].vocab_w2i[\"<SOS>\"]], configs.train.batch_size), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x448 and 384x14552)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23493/2409664322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dissertation/1_tech_gen_impact/class2class/Tech_Gen/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, enc_outputs)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x448 and 384x14552)"
     ]
    }
   ],
   "source": [
    "o,h = final_model.module.decoder(next_input, z, enc_outputs[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = next_input.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = z\n",
    "hidden = hidden.unsqueeze(0).repeat(final_model.module.config.n_layers, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = final_model.module.decoder.dropout(final_model.module.decoder.embedding(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs[\"class\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_last = hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 192])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 192])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_ = hidden_last.unsqueeze(1).repeat(1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 192])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 128])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs[\"class\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 320])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((hidden_, enc_outputs[\"class\"]), dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = torch.tanh(final_model.module.decoder.attention.attn(torch.cat((hidden_, enc_outputs[\"class\"]), dim=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 64])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = final_model.module.decoder.attention.v(energy).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 100])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = torch.bmm(a, enc_outputs[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_input = torch.cat((embedded, weighted), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 256])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 192])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.model.d_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "o,h = final_model.module.decoder.gru(gru_input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 192])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = torch.cat((embedded.squeeze(1), weighted.squeeze(1), o.squeeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=384, out_features=14552, bias=True)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.module.decoder.fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.module.decoder.d_hidden + final_model.module.decoder.config.d_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params=configs.model\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "from utils import loss_KLD, KLDLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_recon = torch.nn.CrossEntropyLoss(ignore_index=model_params['i_padding'])\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.CrossEntropyLoss()\n",
    "loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.NLLLoss()\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.BCELoss()\n",
    "loss_kld = KLDLoss()\n",
    "\n",
    "loss_recon = DataParallelCriterion(loss_recon, device_ids=model_params['device_ids'])\n",
    "loss_y = DataParallelCriterion(loss_y, device_ids=model_params['device_ids'])\n",
    "loss_kld = DataParallelCriterion(loss_kld, device_ids=model_params['device_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kld.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_params[\"model_type\"] == \"enc-pred-dec\":\n",
    "    loss_f = {\"recon\": loss_recon, \"y\": loss_y, \"KLD\": loss_KLD}\n",
    "elif model_params[\"model_type\"] == \"enc-dec\":\n",
    "    loss_f = {\"recon\": loss_recon, \"KLD\": loss_KLD}\n",
    "elif model_params[\"model_type\"] == \"enc-pred\":\n",
    "    loss_f = {\"y\": loss_y}\n",
    "else:\n",
    "    loss_f = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = {\"text_inputs\": to_device(batch_data[\"text_inputs\"], device), \"text_outputs\": to_device(batch_data[\"text_outputs\"], device), \"targets\": to_device(batch_data[\"targets\"], device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"]) # omit <eos> from target sequence\n",
    "outputs_recon = [output[\"dec_outputs\"].permute(0,2,1) for output in outputs]\n",
    "outputs_z = [output[\"z\"] for output in outputs] # outputs_z: n_gpus * (minibatch, d_hidden)\n",
    "outputs_y = [output[\"pred_outputs\"] for output in outputs] # outputs_y: n_gpus * (minibatch, n_outputs)\n",
    "outputs_mu = [output[\"mu\"] for output in outputs]\n",
    "outputs_logvar = [output[\"logvar\"] for output in outputs]\n",
    "# dict_outputs = {\"recon\": outputs_recon, \"y\": outputs_y, \"z\": outputs_z}\n",
    "dict_outputs = {\"recon\": outputs_recon, \"y\": outputs_y, \"z\": outputs_z, \"mu\": outputs_mu, \"logvar\": outputs_logvar}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kld.module(dict_outputs[\"mu\"][0], dict_outputs[\"logvar\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict_outputs[\"mu\"]\n",
    "targets = dict_outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_ = [torch.cat([target.to(device) for target in targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, kwargs = loss_kld.scatter([targets_], kwargs=None, device_ids=loss_kld.device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.tensor([1.2, 0.3], device=device): print(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if targets_: print(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data[\"text_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(targets[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas = loss_kld.replicate(loss_kld.module, loss_kld.device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replicas[0](inputs[0], targets_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon = [output for output in dict_outputs[\"recon\"]]\n",
    "trues_recon = batch_data[\"text_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f[\"KLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logvar = dict_outputs[\"logvar\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = dict_outputs[\"mu\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.5 * torch.sum((1 + logvar - mu.pow(2) - logvar.exp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "torch.sum(torch.tensor([loss_f[\"KLD\"](mu=dict_outputs[\"mu\"][i], logvar=dict_outputs[\"logvar\"][i]) for i in range(configs.train.n_gpus)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDLoss(_Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\", log_target: bool = False) -> None:\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "        self.log_target = log_target\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return loss_KLD(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f_kld = KLDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataParallelCriterion(loss_f_kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = dict_outputs[\"y\"]\n",
    "trues_y = batch_data[\"targets\"].to(dtype=preds_y[0].dtype) if model_params[\"n_outputs\"]==1 else batch_data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f[\"y\"](preds_y, trues_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_f[\"recon\"](preds_recon, trues_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1])\n",
    "pos_weight = class_weights[0]/class_weights[1]\n",
    "final_model = train_model(final_model, train_loader, val_loader, configs.model, configs.train, class_weights=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    print(\"Validate model on train dataset\")\n",
    "    # trues_recon_train, preds_recon_train, trues_y_train, preds_y_train = validate_model(final_model, whole_loader, configs.model, configs.train)\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, mp=mp, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "print(\"Validate model on test dataset\")\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, mp=mp, batch_size=64, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=configs.data.pred_type)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    confmat_y_res = pd.concat([confmat_y_train, confmat_y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (temp) Pre-trained model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        x = self.l1(input_ids=input_ids, attention_mask=mask)\n",
    "        hidden_state = x[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        \n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BERTClass().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer(tech_dataset.data['claims'][:100].tolist(), add_special_tokens=True, max_length=256, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input_ids\": torch.tensor(out.input_ids, dtype=torch.long, device=device),\n",
    "         \"mask\": torch.tensor(out.attention_mask, dtype=torch.long, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = m(inputs[\"input_ids\"], inputs[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pytorch_model_summary.summary(m.to(device), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = build_model(configs.model, tokenizer=tech_dataset.tokenizer)\n",
    "if os.path.exists(final_model_path):\n",
    "    best_states = torch.load(final_model_path)\n",
    "else:\n",
    "    raise Exception(\"Model need to be trained first\")\n",
    "converted_states = OrderedDict()\n",
    "for k, v in best_states.items():\n",
    "    if 'module' not in k:\n",
    "        k = 'module.'+k\n",
    "    else:\n",
    "        k = k.replace('features.module.', 'module.features.')\n",
    "    converted_states[k] = v\n",
    "final_model.load_state_dict(converted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy predictor\n",
    "temp_path = os.path.join(model_dir, \"temp\", \"temp.ckpt\")\n",
    "predictor = Predictor(final_model.module.config).to(final_model.module.device)\n",
    "torch.save(final_model.module.predictor.state_dict(), temp_path)\n",
    "predictor.load_state_dict(torch.load(temp_path, map_location=final_model.module.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(root_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_train_data = pd.read_excel(os.path.join(result_path, \"[DATASET]2023-04-11_00:39.xlsx\"), sheet_name=\"TRAIN_dataset\")\n",
    "used_test_data = pd.read_excel(os.path.join(result_path, \"[DATASET]2023-04-11_00:39.xlsx\"), sheet_name=\"TEST_dataset\")\n",
    "used_train_index = tech_dataset.data.index.get_indexer(pd.Index(used_train_data[\"number\"]))\n",
    "used_test_index = tech_dataset.data.index.get_indexer(pd.Index(used_test_data[\"number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tech_dataset.data.iloc[used_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_claims = tech_dataset.X[used_test_index]\n",
    "text_inputs = tech_dataset.tokenizer.encode(input_claims[0])\n",
    "batch_inf = {\"input_ids\": torch.tensor([tech_dataset.tokenizer.encode(input_claims[0]).ids]), \"attention_mask\": torch.tensor(tech_dataset.tokenizer.encode(input_claims[0]).attention_mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_inf = to_device(batch_inf, final_model.module.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_info(tensor):\n",
    "  info = []\n",
    "  for name in ['requires_grad', 'is_leaf', 'retains_grad', 'grad_fn', 'grad']:\n",
    "    info.append(f'{name}({getattr(tensor, name, None)})')\n",
    "  info.append(f'tensor({str(tensor)})')\n",
    "  return ' '.join(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs = final_model.module.encode(input_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs = predictor(enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs[0,1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs_ = enc_outputs + step_size * enc_outputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_outputs = predictor(enc_outputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_outputs = final_model.module.decode(input_inf, enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.module.tokenizer.decode_batch(dec_outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_tensor_info(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor(inputs)[0,-1,-1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_tensor_info(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instant_dataset = Subset(tech_dataset, np.random.choice(np.arange(len(tech_dataset)), 1000))\n",
    "data_loader = DataLoader(instant_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = to_device(batch_data[\"text_inputs\"], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, *_ = final_model.module.encoder(**text_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = enc_outputs[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon = []\n",
    "\n",
    "if str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"transformers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].convert_tokens_to_ids(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "elif str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"tokenizers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].token_to_id(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "    \n",
    "for i in range(configs.model['n_dec_seq']-1):\n",
    "    dec_outputs, *_ = final_model.module.decoder(preds_recon_batch, text_inputs[\"input_ids\"], enc_outputs)\n",
    "    pred_tokens = dec_outputs.argmax(2)[:,-1].unsqueeze(1)\n",
    "    preds_recon_batch = torch.cat([preds_recon_batch, pred_tokens], axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "preds_recon.append(preds_recon_batch[:,1:].cpu().detach().numpy())\n",
    "preds_recon = np.concatenate(preds_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(\"TRUE(keywords): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_inputs\"][\"input_ids\"].cpu().detach().numpy()))[0])\n",
    "\n",
    "display(\"TRUE(org): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_outputs\"][\"input_ids\"].cpu().detach().numpy()))[0])\n",
    "\n",
    "display(\"PRED: \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs_ = torch.normal(enc_outputs, torch.tile(torch.tensor(2), dims=enc_outputs.size()).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon_ = []\n",
    "\n",
    "if str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"transformers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].convert_tokens_to_ids(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "elif str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"tokenizers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].token_to_id(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "    \n",
    "for i in range(configs.model['n_dec_seq']-1):\n",
    "    dec_outputs, *_ = final_model.module.decoder(preds_recon_batch, text_inputs[\"input_ids\"], enc_outputs_)\n",
    "    pred_tokens = dec_outputs.argmax(2)[:,-1].unsqueeze(1)\n",
    "    preds_recon_batch = torch.cat([preds_recon_batch, pred_tokens], axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "preds_recon_.append(preds_recon_batch[:,1:].cpu().detach().numpy())\n",
    "preds_recon_ = np.concatenate(preds_recon_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "print(\"TRUE(keywords): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_inputs\"][\"input_ids\"].cpu().detach().numpy()))[i])\n",
    "\n",
    "print(\"TRUE(org): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_outputs\"][\"input_ids\"].cpu().detach().numpy()))[i])\n",
    "\n",
    "print(\"PRED: \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[i])\n",
    "\n",
    "print(\"PRED(modified): \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon_, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
