{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/Transformer/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model\n",
    "from utils import token2class, DotDict\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"claim\",\n",
    "    target_ipc=\"\",\n",
    "    pred_type=\"classification\",\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    max_epochs=2,\n",
    "    use_accelerator=None,\n",
    "    do_save=False,\n",
    "    n_gpus=4,\n",
    "    light=True,\n",
    "    eval_train_set=False)\n",
    "\n",
    "config_file = \"configs_light.json\" if args.light else \"configs.json\"\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "    configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "elif len(configs.data.target_ipc) > 5:\n",
    "    configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "    # configs.model.update({\"use_accelerator\": configs.train.use_accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else 2,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_hidden = configs.model.d_hidden = None\n",
    "    d_latent = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_hidden = configs.model.d_hidden\n",
    "    d_latent = configs.model.n_enc_seq * configs.model.d_hidden\n",
    "    key_components = {\"data\": [\"target_ipc\", \"pred_type\", \"max_seq_len\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_hidden\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.model.update({\"d_latent\": d_latent})\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickled dataset...\n",
      "Pickled dataset loaded\n",
      "2.227 sec elapsed for loading patents for class [ALL]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys[\"data\"]])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        tech_dataset.rawdata = None\n",
    "        pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")\n",
    "\n",
    "configs.model.update({\"tokenizer\": tech_dataset.tokenizer,\n",
    "                        \"n_enc_vocab\": tech_dataset.tokenizer.get_vocab_size(),\n",
    "                        \"n_dec_vocab\": tech_dataset.tokenizer.get_vocab_size(),\n",
    "                        \"n_enc_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_dec_seq\": tech_dataset.max_seq_len,\n",
    "                        \"i_padding\": tech_dataset.tokenizer.token_to_id(\"<PAD>\")})\n",
    "configs.model.update({\"d_latent\": configs.model.n_enc_seq * configs.model.d_hidden})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 55847, Validation: 13962, Test: 29919\n"
     ]
    }
   ],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.3, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-1: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs.train.do_tune:\n",
    "    configs.train.update({\"tuned_model_path\": os.path.join(model_dir,\"hparam_tuning\")})\n",
    "    optuna_obj = lambda trial: objective_cv(trial, dataset=tech_dataset, cv_idx=cv_idx, model_params=configs.model, train_params=configs.train)\n",
    "\n",
    "    opt_sampler = TPESampler()\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(optuna_obj, n_trials=configs.train.n_trials, gc_after_trial=True)\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    print(f\"Best trial:\\n  CrossEntropyLoss: {study.best_trial.value}\\n  Params:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    configs.train.update({k: v for k,v in best_params.items() if k in configs.train.keys()})\n",
    "    configs.model.update({k: v for k,v in best_params.items() if k in configs.model.keys()})\n",
    "    config_name = f\"{configs.model.n_layers}layers_{configs.model.d_embedding}emb_{configs.model.d_hidden}hid_{configs.model.n_directions}direc_{np.round(configs.train.learning_rate, 4)}lr_{configs.train.batch_size}batch_{configs.train.max_epochs}ep\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model][{configs.data.target_ipc}]{config_name}.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizer=tech_dataset.tokenizer)\n",
    "# x_input, _ = next(iter(train_loader))\n",
    "# if re.search(\"^1.\", torch.__version__) is not None:\n",
    "#     print(pytorch_model_summary.summary(final_model.module, torch.zeros(x_input.shape, device=device, dtype=torch.long), torch.zeros(x_input.shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))\n",
    "# else:\n",
    "#     print(\"INFO: pytorch-model-summary does not support PyTorch 2.0, so just print model structure\")\n",
    "#     print(final_model)\n",
    "#     torch._dynamo.config.verbose = True\n",
    "#     torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                   Parent Layers       Layer (type)          Input Shape         Param #     Tr. Param #\n",
      "========================================================================================================================================================\n",
      "                                                             Transformer/Encoder        Embedding-1             [1, 256]          80,000          80,000\n",
      "                                                             Transformer/Encoder        Embedding-2             [1, 256]           8,224               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-3         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-4         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-5         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention          Dropout-6     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-7         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Dropout-8         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer        LayerNorm-9         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-10         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-11         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-12         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-13         [1, 256, 32]              64              64\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-14         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-15         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-16         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-17     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-18         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention         Dropout-19         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-20         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-21         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-22         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-23         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-24         [1, 256, 32]              64              64\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-25         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-26         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-27         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-28     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-29         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention         Dropout-30         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-31         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-32         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-33         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-34         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-35         [1, 256, 32]              64              64\n",
      "                                                           Transformer/Predictor          Linear-36            [1, 8192]         262,176         262,176\n",
      "                                                           Transformer/Predictor       LeakyReLU-37              [1, 32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-38              [1, 32]              66              66\n",
      "                                                             Transformer/Decoder       Embedding-39             [1, 256]          80,000          80,000\n",
      "                                                             Transformer/Decoder       Embedding-40             [1, 256]           8,224               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-41         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-42         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-43         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-44     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-45         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-46         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-47         [1, 256, 32]              64              64\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-48         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-49         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-50         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-51     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-52         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-53         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-54         [1, 256, 32]              64              64\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-55         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-56         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet         Dropout-57         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-58         [1, 256, 32]              64              64\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-59         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-60         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-61         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-62     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-63         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-64         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-65         [1, 256, 32]              64              64\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-66         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-67         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-68         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-69     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-70         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-71         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-72         [1, 256, 32]              64              64\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-73         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-74         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet         Dropout-75         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-76         [1, 256, 32]              64              64\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-77         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-78         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-79         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-80     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-81         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-82         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-83         [1, 256, 32]              64              64\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-84         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-85         [1, 256, 32]           2,112           2,112\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-86         [1, 256, 32]           2,112           2,112\n",
      "   Transformer/Decoder/DecoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-87     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention          Linear-88         [1, 256, 64]           2,080           2,080\n",
      "                             Transformer/Decoder/DecoderLayer/MultiHeadAttention         Dropout-89         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-90         [1, 256, 32]              64              64\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-91         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet          Conv1d-92         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Decoder/DecoderLayer/PoswiseFeedForwardNet         Dropout-93         [1, 256, 32]               0               0\n",
      "                                                Transformer/Decoder/DecoderLayer       LayerNorm-94         [1, 256, 32]              64              64\n",
      "                                                             Transformer/Decoder          Linear-95         [1, 256, 32]          82,500          82,500\n",
      "========================================================================================================================================================\n",
      "Total params: 610,566\n",
      "Trainable params: 594,118\n",
      "Non-trainable params: 16,448\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_input, _ = tech_dataset.__getitem__(0)\n",
    "    x_input = torch.tensor(x_input, device=device).unsqueeze(0)\n",
    "    print(pytorch_model_summary.summary(final_model.module, torch.zeros(x_input.shape, device=device, dtype=torch.long), torch.zeros(x_input.shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:170% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 01:29:26.884149: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:59,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                maxwell_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      58.307ms        20.40%      58.307ms     809.819us           0 b           0 b           0 b           0 b            72  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      32.956ms        11.53%      32.956ms     343.292us           0 b           0 b           0 b           0 b            96  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      31.086ms        10.88%      31.086ms     518.100us           0 b           0 b           0 b           0 b            60  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      30.449ms        10.65%      30.449ms      90.622us           0 b           0 b           0 b           0 b           336  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      29.710ms        10.39%      29.710ms     825.278us           0 b           0 b           0 b           0 b            36  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      27.132ms         9.49%      27.132ms     753.667us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      26.502ms         9.27%      26.502ms     736.167us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      17.460ms         6.11%      17.460ms     485.000us           0 b           0 b           0 b           0 b            36  \n",
      "                               maxwell_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      10.252ms         3.59%      10.252ms     179.860us           0 b           0 b           0 b           0 b            57  \n",
      "                                  sgemm_32x32x32_NT_vec         0.00%       0.000us         0.00%       0.000us       0.000us       5.564ms         1.95%       5.564ms      73.211us           0 b           0 b           0 b           0 b            76  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 97.941ms\n",
      "Self CUDA time total: 285.830ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaDeviceSynchronize        48.49%      47.489ms        48.49%      47.489ms      47.489ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                      model_feedforward         0.88%     859.000us        39.69%      38.876ms      38.876ms       0.000us         0.00%     858.000us     858.000us          -4 b        -268 b      -4.50 Gb      -4.51 Gb             1  \n",
      "                                   DataParallel.forward        34.10%      33.400ms        38.80%      38.001ms      38.001ms       0.000us         0.00%     858.000us     858.000us          -4 b          -4 b       8.67 Mb           0 b             1  \n",
      "                                       cudaLaunchKernel        11.60%      11.357ms        12.36%      12.104ms      11.473us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1055  \n",
      "                                              Broadcast         1.35%       1.324ms         3.72%       3.643ms       3.643ms       0.000us         0.00%     699.000us     699.000us           0 b           0 b       7.18 Mb      -2.39 Mb             1  \n",
      "                          aten::unflatten_dense_tensors         0.50%     485.000us         1.54%       1.511ms     251.833us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                            aten::copy_         0.35%     345.000us         0.98%     962.000us      80.167us     814.000us         0.28%     814.000us      67.833us           0 b           0 b           0 b           0 b            12  \n",
      "                                                Scatter         0.11%     106.000us         0.98%     956.000us     478.000us       0.000us         0.00%     159.000us      79.500us           0 b           0 b       1.50 Mb           0 b             2  \n",
      "                                               aten::to         0.01%       8.000us         0.83%     812.000us     135.333us       0.000us         0.00%     159.000us      26.500us           0 b           0 b       1.50 Mb           0 b             6  \n",
      "                                         aten::_to_copy         0.02%      23.000us         0.82%     804.000us     134.000us       0.000us         0.00%     159.000us      26.500us           0 b           0 b       1.50 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 97.941ms\n",
      "Self CUDA time total: 285.830ms\n",
      "\n",
      "Epoch: 01 | Time: 1m 3s\n",
      "Avg train loss: 19.388688, Avg val loss: 17.963624 (recon loss: 12.662813, y loss: 5.300811)\n",
      "\n",
      "Validation loss decreased (inf --> 17.963624).  Saving model ...\n",
      "\n",
      "Epoch 2\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:47,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                maxwell_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      58.321ms        20.35%      58.321ms     810.014us           0 b           0 b           0 b           0 b            72  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      32.972ms        11.50%      32.972ms     343.458us           0 b           0 b           0 b           0 b            96  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      31.402ms        10.96%      31.402ms     523.367us           0 b           0 b           0 b           0 b            60  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      30.686ms        10.71%      30.686ms      91.327us           0 b           0 b           0 b           0 b           336  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      29.699ms        10.36%      29.699ms     824.972us           0 b           0 b           0 b           0 b            36  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      27.134ms         9.47%      27.134ms     753.722us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      26.490ms         9.24%      26.490ms     735.833us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      17.601ms         6.14%      17.601ms     488.917us           0 b           0 b           0 b           0 b            36  \n",
      "                               maxwell_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      10.229ms         3.57%      10.229ms     179.456us           0 b           0 b           0 b           0 b            57  \n",
      "                                  sgemm_32x32x32_NT_vec         0.00%       0.000us         0.00%       0.000us       0.000us       5.602ms         1.95%       5.602ms      73.711us           0 b           0 b           0 b           0 b            76  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 99.230ms\n",
      "Self CUDA time total: 286.600ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaDeviceSynchronize        50.00%      49.611ms        50.00%      49.611ms      49.611ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                      model_feedforward         0.72%     719.000us        38.28%      37.989ms      37.989ms       0.000us         0.00%     859.000us     859.000us          -4 b          -4 b      -4.50 Gb      -4.51 Gb             1  \n",
      "                                   DataParallel.forward        32.90%      32.650ms        37.54%      37.252ms      37.252ms       0.000us         0.00%     859.000us     859.000us          -4 b          -4 b       8.67 Mb           0 b             1  \n",
      "                                       cudaLaunchKernel        11.50%      11.415ms        11.68%      11.588ms      10.573us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1096  \n",
      "                                              Broadcast         1.37%       1.364ms         3.71%       3.682ms       3.682ms       0.000us         0.00%     699.000us     699.000us           0 b           0 b       7.18 Mb      -2.39 Mb             1  \n",
      "                          aten::unflatten_dense_tensors         0.47%     471.000us         1.54%       1.532ms     255.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                            aten::copy_         0.34%     338.000us         0.93%     925.000us      77.083us     814.000us         0.28%     814.000us      67.833us           0 b           0 b           0 b           0 b            12  \n",
      "                                                Scatter         0.10%     104.000us         0.93%     918.000us     459.000us       0.000us         0.00%     160.000us      80.000us           0 b           0 b       1.50 Mb           0 b             2  \n",
      "                                               aten::to         0.01%       7.000us         0.78%     776.000us     129.333us       0.000us         0.00%     160.000us      26.667us           0 b           0 b       1.50 Mb           0 b             6  \n",
      "                                         aten::_to_copy         0.02%      24.000us         0.77%     769.000us     128.167us       0.000us         0.00%     160.000us      26.667us           0 b           0 b       1.50 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 99.230ms\n",
      "Self CUDA time total: 286.600ms\n",
      "\n",
      "Epoch: 02 | Time: 0m 51s\n",
      "Avg train loss: 17.440438, Avg val loss: 17.007802 (recon loss: 11.739834, y loss: 5.267968)\n",
      "\n",
      "Validation loss decreased (17.963624 --> 17.007802).  Saving model ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "if configs.train.do_tune:\n",
    "    best_states = torch.load(os.path.join(configs.train.tuned_model_path,f\"[HPARAM_TUNING]{study.best_trial.number}trial.ckpt\"))\n",
    "    converted_states = OrderedDict()\n",
    "    for k, v in best_states.items():\n",
    "        if 'module' not in k:\n",
    "            k = 'module.'+k\n",
    "        else:\n",
    "            k = k.replace('features.module.', 'module.features.')\n",
    "        converted_states[k] = v\n",
    "    final_model.load_state_dict(converted_states)\n",
    "else:\n",
    "    final_model = train_model(final_model, train_loader, val_loader, configs.model, configs.train)\n",
    "torch.save(final_model.state_dict(), final_model_path) # Finalize\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Subprocess:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_15753/612833506.py\", line 13, in inference_mp\n",
      "TypeError: 'module' object is not callable\n",
      "Process Subprocess:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_15753/612833506.py\", line 13, in inference_mp\n",
      "TypeError: 'module' object is not callable\n",
      "Process Subprocess:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_15753/612833506.py\", line 13, in inference_mp\n",
      "TypeError: 'module' object is not callable\n",
      "Process Subprocess:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home2/glee/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_15753/612833506.py\", line 13, in inference_mp\n",
      "TypeError: 'module' object is not callable\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15753/1872778934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mval_res_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model_mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrues_recon_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mpreds_recon_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrues_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15753/1872778934.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mval_res_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model_mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrues_recon_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mpreds_recon_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrues_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_res_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.9/site-packages/multiprocess/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconvert_to_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'true'"
     ]
    }
   ],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=\"classification\")\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15753/2235509928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (temp) BART experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "# model = BartModel.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_input = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(ex_input[\"input_ids\"], num_beams=2, min_length=0, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(ex_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.logits.argmax(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
