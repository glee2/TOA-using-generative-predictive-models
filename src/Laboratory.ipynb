{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/class2class/Tech_Gen/'\n",
    "master_dir = '/home2/glee/dissertation/1_tech_gen_impact/master/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer, Predictor\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict, to_device\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"class\",\n",
    "    data_file = \"collection_[H01L,H10][2017].csv\",\n",
    "    target_ipc=\"H01L\",\n",
    "    pred_type=\"classification\",\n",
    "    n_TC = 5,\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    batch_size=16,\n",
    "    max_epochs=50,\n",
    "    use_accelerator=None,\n",
    "    do_save=True,\n",
    "    n_gpus=4,\n",
    "    light=True,\n",
    "#     config_file=os.path.join(root_dir, \"configs\", \"USED_configs\", \"[CONFIGS]2023-04-11_00:39.json\"),\n",
    "    config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "data_dir = os.path.join(master_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "    configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "elif len(configs.data.target_ipc) > 5:\n",
    "    configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_hidden = configs.model.d_hidden = None\n",
    "    d_latent = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_hidden = configs.model.d_hidden\n",
    "    d_latent = 64\n",
    "\n",
    "    key_components = {\"data\": [\"target_ipc\", \"pred_type\", \"max_seq_len\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_hidden\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\", \"take_last_h\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.model.update({\"d_latent\": d_latent})\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset...\n",
      "19.1998 sec elapsed for loading patents for class [H01L]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "org_config_keys_temp = copy.copy(org_config_keys[\"data\"])\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"use_pretrained_tokenizer\"))\n",
    "org_config_keys_temp.pop(org_config_keys_temp.index(\"data_file\"))\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys_temp])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        tech_dataset.rawdata = None\n",
    "        pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")\n",
    "\n",
    "configs.model.update({\"tokenizers\": tech_dataset.tokenizers,\n",
    "                        \"n_enc_vocab\": tech_dataset.tokenizers[\"enc\"].vocab_size,\n",
    "                        \"n_dec_vocab\": tech_dataset.tokenizers[\"dec\"].vocab_size,\n",
    "                        \"n_enc_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_dec_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                        \"i_padding\": tech_dataset.tokenizers[\"enc\"].token_to_id(\"<PAD>\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'collection_[H01L,H10][2017].csv'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.data.data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(os.path.join(data_dir, configs.data.data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rawdata_dropna = rawdata.dropna(axis=0, subset=['main ipc', 'sub ipc', 'claims'])[['number','main ipc','sub ipc','claims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = configs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdata_dropna[[\"number\"]].copy(deep=True)\n",
    "\n",
    "assert self.ipc_level in [1,2,3], f\"Not implemented for an IPC level {self.ipc_level}\"\n",
    "if self.ipc_level == 1:\n",
    "    data['main_ipc'] = rawdata_dropna['main ipc'].apply(lambda x: x[:3])\n",
    "    data['sub_ipc'] = rawdata_dropna['sub ipc'].apply(lambda x: list(np.unique([xx[:3] for xx in x.split(\";\")])))\n",
    "elif self.ipc_level == 2:\n",
    "    data['main_ipc'] = rawdata_dropna['main ipc'].apply(lambda x: x[:4])\n",
    "    data['sub_ipc'] = rawdata_dropna['sub ipc'].apply(lambda x: list(np.unique([xx[:4] for xx in x.split(\";\")])))\n",
    "elif self.ipc_level == 3:\n",
    "    data['main_ipc'] = rawdata_dropna['main ipc'].apply(lambda x: x)\n",
    "    data['sub_ipc'] = rawdata_dropna['sub ipc'].apply(lambda x: list(np.unique([xx for xx in x.split(\";\")])))\n",
    "data[\"ipcs\"] = data.apply(lambda x: [x[\"main_ipc\"]]+x[\"sub_ipc\"], axis=1)\n",
    "seq_len = data['sub_ipc'].apply(lambda x: len(x)).max() + 3 # SOS - main ipc - sub ipcs - EOS\n",
    "self.max_seq_len = seq_len if self.max_seq_len < seq_len else self.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"claims\"] = rawdata_dropna.loc[data.index][\"claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>main_ipc</th>\n",
       "      <th>sub_ipc</th>\n",
       "      <th>ipcs</th>\n",
       "      <th>claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9853235</td>\n",
       "      <td>H01L51/52</td>\n",
       "      <td>[H01L27/32, H05B33/04]</td>\n",
       "      <td>[H01L51/52, H01L27/32, H05B33/04]</td>\n",
       "      <td>1. A display device comprising: a light emitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9854199</td>\n",
       "      <td>H04N5/76</td>\n",
       "      <td>[G11B27/00, G11B27/024, G11B27/032, G11B27/034...</td>\n",
       "      <td>[H04N5/76, G11B27/00, G11B27/024, G11B27/032, ...</td>\n",
       "      <td>1. A method for a digital video recorder, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9851599</td>\n",
       "      <td>G02F1/1335</td>\n",
       "      <td>[G02B5/20, G02F1/1343, G09G3/34, G09G3/36, G09...</td>\n",
       "      <td>[G02F1/1335, G02B5/20, G02F1/1343, G09G3/34, G...</td>\n",
       "      <td>1. A color display device for displaying an n-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9851864</td>\n",
       "      <td>G06F17/21</td>\n",
       "      <td>[G06F17/30, G06F3/041, G06F3/0481, G06F3/0485,...</td>\n",
       "      <td>[G06F17/21, G06F17/30, G06F3/041, G06F3/0481, ...</td>\n",
       "      <td>1. A method comprising: identifying content to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9852488</td>\n",
       "      <td>A63F9/24</td>\n",
       "      <td>[A63F13/00, G06F17/00, G06F19/00, G06Q50/34, G...</td>\n",
       "      <td>[A63F9/24, A63F13/00, G06F17/00, G06F19/00, G0...</td>\n",
       "      <td>1. A computer implemented method of managing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37425</th>\n",
       "      <td>9537605</td>\n",
       "      <td>H04K3/00</td>\n",
       "      <td>[H04B1/04]</td>\n",
       "      <td>[H04K3/00, H04B1/04]</td>\n",
       "      <td>1. An ultra-wideband, high-power, solid-state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37426</th>\n",
       "      <td>9538636</td>\n",
       "      <td>H05K1/02</td>\n",
       "      <td>[H05K1/03, H05K1/14, H05K1/18, H05K3/00, H05K3...</td>\n",
       "      <td>[H05K1/02, H05K1/03, H05K1/14, H05K1/18, H05K3...</td>\n",
       "      <td>1. An apparatus comprising: a substrate compri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37427</th>\n",
       "      <td>9536977</td>\n",
       "      <td>H01L29/66</td>\n",
       "      <td>[H01L21/332, H01L21/336, H01L21/8238, H01L29/739]</td>\n",
       "      <td>[H01L29/66, H01L21/332, H01L21/336, H01L21/823...</td>\n",
       "      <td>1. A semiconductor device comprising: a precur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37428</th>\n",
       "      <td>9534772</td>\n",
       "      <td>H01L33/62</td>\n",
       "      <td>[F21K99/00, F21V19/00, F21V23/00, F21V23/04, F...</td>\n",
       "      <td>[H01L33/62, F21K99/00, F21V19/00, F21V23/00, F...</td>\n",
       "      <td>1. A lighting apparatus comprising: a pluralit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37429</th>\n",
       "      <td>9532585</td>\n",
       "      <td>A61K35/60</td>\n",
       "      <td>[A23D9/007, A61K36/534, A61K36/752, A61K9/48]</td>\n",
       "      <td>[A61K35/60, A23D9/007, A61K36/534, A61K36/752,...</td>\n",
       "      <td>1. A capsule for delivering an odoriferous oil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33875 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        number    main_ipc                                            sub_ipc  \\\n",
       "0      9853235   H01L51/52                             [H01L27/32, H05B33/04]   \n",
       "1      9854199    H04N5/76  [G11B27/00, G11B27/024, G11B27/032, G11B27/034...   \n",
       "4      9851599  G02F1/1335  [G02B5/20, G02F1/1343, G09G3/34, G09G3/36, G09...   \n",
       "5      9851864   G06F17/21  [G06F17/30, G06F3/041, G06F3/0481, G06F3/0485,...   \n",
       "6      9852488    A63F9/24  [A63F13/00, G06F17/00, G06F19/00, G06Q50/34, G...   \n",
       "...        ...         ...                                                ...   \n",
       "37425  9537605    H04K3/00                                         [H04B1/04]   \n",
       "37426  9538636    H05K1/02  [H05K1/03, H05K1/14, H05K1/18, H05K3/00, H05K3...   \n",
       "37427  9536977   H01L29/66  [H01L21/332, H01L21/336, H01L21/8238, H01L29/739]   \n",
       "37428  9534772   H01L33/62  [F21K99/00, F21V19/00, F21V23/00, F21V23/04, F...   \n",
       "37429  9532585   A61K35/60      [A23D9/007, A61K36/534, A61K36/752, A61K9/48]   \n",
       "\n",
       "                                                    ipcs  \\\n",
       "0                      [H01L51/52, H01L27/32, H05B33/04]   \n",
       "1      [H04N5/76, G11B27/00, G11B27/024, G11B27/032, ...   \n",
       "4      [G02F1/1335, G02B5/20, G02F1/1343, G09G3/34, G...   \n",
       "5      [G06F17/21, G06F17/30, G06F3/041, G06F3/0481, ...   \n",
       "6      [A63F9/24, A63F13/00, G06F17/00, G06F19/00, G0...   \n",
       "...                                                  ...   \n",
       "37425                               [H04K3/00, H04B1/04]   \n",
       "37426  [H05K1/02, H05K1/03, H05K1/14, H05K1/18, H05K3...   \n",
       "37427  [H01L29/66, H01L21/332, H01L21/336, H01L21/823...   \n",
       "37428  [H01L33/62, F21K99/00, F21V19/00, F21V23/00, F...   \n",
       "37429  [A61K35/60, A23D9/007, A61K36/534, A61K36/752,...   \n",
       "\n",
       "                                                  claims  \n",
       "0      1. A display device comprising: a light emitti...  \n",
       "1      1. A method for a digital video recorder, comp...  \n",
       "4      1. A color display device for displaying an n-...  \n",
       "5      1. A method comprising: identifying content to...  \n",
       "6      1. A computer implemented method of managing b...  \n",
       "...                                                  ...  \n",
       "37425  1. An ultra-wideband, high-power, solid-state ...  \n",
       "37426  1. An apparatus comprising: a substrate compri...  \n",
       "37427  1. A semiconductor device comprising: a precur...  \n",
       "37428  1. A lighting apparatus comprising: a pluralit...  \n",
       "37429  1. A capsule for delivering an odoriferous oil...  \n",
       "\n",
       "[33875 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 24389, Validation: 6098, Test: 3388\n"
     ]
    }
   ],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.1, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import models, train_utils, parallel\n",
    "# importlib.reload(models)\n",
    "# importlib.reload(train_utils)\n",
    "# importlib.reload(parallel)\n",
    "# from train_utils import build_model\n",
    "# from models import SEQ2SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizers=tech_dataset.tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params=configs.model\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "from utils import loss_KLD, KLDLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_recon = torch.nn.CrossEntropyLoss(ignore_index=model_params['i_padding'])\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.CrossEntropyLoss()\n",
    "loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.NLLLoss()\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "# loss_y = torch.nn.MSELoss() if model_params['n_outputs']==1 else torch.nn.BCELoss()\n",
    "loss_kld = KLDLoss()\n",
    "\n",
    "loss_recon = DataParallelCriterion(loss_recon, device_ids=model_params['device_ids'])\n",
    "loss_y = DataParallelCriterion(loss_y, device_ids=model_params['device_ids'])\n",
    "loss_kld = DataParallelCriterion(loss_kld, device_ids=model_params['device_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLDLoss()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_kld.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_params[\"model_type\"] == \"enc-pred-dec\":\n",
    "    loss_f = {\"recon\": loss_recon, \"y\": loss_y, \"KLD\": loss_KLD}\n",
    "elif model_params[\"model_type\"] == \"enc-dec\":\n",
    "    loss_f = {\"recon\": loss_recon, \"KLD\": loss_KLD}\n",
    "elif model_params[\"model_type\"] == \"enc-pred\":\n",
    "    loss_f = {\"y\": loss_y}\n",
    "else:\n",
    "    loss_f = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = {\"text_inputs\": to_device(batch_data[\"text_inputs\"], device), \"text_outputs\": to_device(batch_data[\"text_outputs\"], device), \"targets\": to_device(batch_data[\"targets\"], device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model(batch_data[\"text_inputs\"], batch_data[\"text_outputs\"]) # omit <eos> from target sequence\n",
    "outputs_recon = [output[\"dec_outputs\"].permute(0,2,1) for output in outputs]\n",
    "outputs_z = [output[\"z\"] for output in outputs] # outputs_z: n_gpus * (minibatch, d_hidden)\n",
    "outputs_y = [output[\"pred_outputs\"] for output in outputs] # outputs_y: n_gpus * (minibatch, n_outputs)\n",
    "outputs_mu = [output[\"mu\"] for output in outputs]\n",
    "outputs_logvar = [output[\"logvar\"] for output in outputs]\n",
    "# dict_outputs = {\"recon\": outputs_recon, \"y\": outputs_y, \"z\": outputs_z}\n",
    "dict_outputs = {\"recon\": outputs_recon, \"y\": outputs_y, \"z\": outputs_z, \"mu\": outputs_mu, \"logvar\": outputs_logvar}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1641, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_kld.module(dict_outputs[\"mu\"][0], dict_outputs[\"logvar\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict_outputs[\"mu\"]\n",
    "targets = dict_outputs[\"logvar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_ = [torch.cat([target.to(device) for target in targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, kwargs = loss_kld.scatter([targets_], kwargs=None, device_ids=loss_kld.device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15365/2569823812.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "if torch.tensor([1.2, 0.3], device=device): print(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2333e-01,  5.3464e-02, -4.2547e-02,  ...,  4.6852e-02,\n",
       "         -7.5298e-02, -1.7926e-02],\n",
       "        [-5.3685e-02,  7.9206e-02, -7.2477e-02,  ...,  6.3355e-04,\n",
       "         -9.3319e-02, -1.5820e-02],\n",
       "        [-1.3475e-01,  9.7913e-02, -2.4637e-02,  ..., -1.4057e-02,\n",
       "          1.1413e-04, -9.9982e-03],\n",
       "        ...,\n",
       "        [-9.2506e-02,  9.0090e-02, -2.3219e-02,  ...,  3.0975e-02,\n",
       "         -9.5019e-02,  3.2163e-02],\n",
       "        [-4.9186e-02,  1.5572e-01, -8.0533e-02,  ...,  3.5850e-02,\n",
       "         -1.1785e-01, -7.3595e-02],\n",
       "        [-1.5770e-01,  7.0231e-02, -4.7816e-02,  ...,  1.4363e-02,\n",
       "         -3.7096e-02,  1.3177e-02]], device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15365/3504247894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtargets_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "if targets_: print(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data[\"text_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(targets[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas = loss_kld.replicate(loss_kld.module, loss_kld.device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9502, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicas[0](inputs[0], targets_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1233,  0.0535, -0.0425, -0.0633, -0.0475, -0.0671,  0.0361, -0.1124,\n",
       "         -0.0715,  0.0257,  0.0482, -0.1333, -0.0455, -0.0790,  0.0204, -0.1194,\n",
       "          0.0841,  0.0734, -0.1319, -0.0379, -0.0823, -0.1566, -0.0455,  0.1286,\n",
       "         -0.0811, -0.0679,  0.2031, -0.0143,  0.1159,  0.0118,  0.0786,  0.0560,\n",
       "          0.0005, -0.0017,  0.0430, -0.0288,  0.0041, -0.0293, -0.0495, -0.0807,\n",
       "         -0.0561, -0.1178, -0.0184,  0.0392,  0.0717, -0.0468,  0.0250, -0.1086,\n",
       "         -0.0104, -0.0262,  0.0104,  0.0147,  0.0989, -0.0621, -0.0231, -0.1607,\n",
       "          0.0064, -0.0489, -0.1360,  0.0032, -0.0452, -0.0911, -0.0026,  0.1276,\n",
       "         -0.0055,  0.0242,  0.0226, -0.0165,  0.1711, -0.0196,  0.0282,  0.0876,\n",
       "         -0.1013,  0.0638, -0.0384, -0.0071, -0.0916, -0.0182, -0.0700, -0.0340,\n",
       "          0.0382, -0.0007, -0.0089, -0.1037,  0.0080,  0.0901,  0.1261,  0.0390,\n",
       "         -0.1373, -0.2139, -0.1331,  0.1462, -0.0198, -0.0724, -0.0046, -0.0109,\n",
       "          0.0306, -0.0428,  0.0259,  0.0953, -0.0060,  0.0845,  0.0372,  0.0127,\n",
       "          0.0451, -0.0264,  0.1426,  0.0762,  0.0757, -0.0169, -0.0764,  0.0418,\n",
       "         -0.1502, -0.0727,  0.1333,  0.0771,  0.0315,  0.1438, -0.0703, -0.1323,\n",
       "          0.0353,  0.0680,  0.0586,  0.0736, -0.0640,  0.0469, -0.0753, -0.0179]],\n",
       "       device='cuda:0', grad_fn=<ScatterBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon = [output for output in dict_outputs[\"recon\"]]\n",
    "trues_recon = batch_data[\"text_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f[\"KLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logvar = dict_outputs[\"logvar\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = dict_outputs[\"mu\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.5 * torch.sum((1 + logvar - mu.pow(2) - logvar.exp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "torch.sum(torch.tensor([loss_f[\"KLD\"](mu=dict_outputs[\"mu\"][i], logvar=dict_outputs[\"logvar\"][i]) for i in range(configs.train.n_gpus)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDLoss(_Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\", log_target: bool = False) -> None:\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "        self.log_target = log_target\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return loss_KLD(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f_kld = KLDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataParallelCriterion(loss_f_kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = dict_outputs[\"y\"]\n",
    "trues_y = batch_data[\"targets\"].to(dtype=preds_y[0].dtype) if model_params[\"n_outputs\"]==1 else batch_data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f[\"y\"](preds_y, trues_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_f[\"recon\"](preds_recon, trues_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1])\n",
    "pos_weight = class_weights[0]/class_weights[1]\n",
    "final_model = train_model(final_model, train_loader, val_loader, configs.model, configs.train, class_weights=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    print(\"Validate model on train dataset\")\n",
    "    # trues_recon_train, preds_recon_train, trues_y_train, preds_y_train = validate_model(final_model, whole_loader, configs.model, configs.train)\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, mp=mp, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "print(\"Validate model on test dataset\")\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, mp=mp, batch_size=64, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=configs.data.pred_type)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    confmat_y_res = pd.concat([confmat_y_train, confmat_y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (temp) Pre-trained model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        x = self.l1(input_ids=input_ids, attention_mask=mask)\n",
    "        hidden_state = x[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        \n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BERTClass().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer(tech_dataset.data['claims'][:100].tolist(), add_special_tokens=True, max_length=256, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input_ids\": torch.tensor(out.input_ids, dtype=torch.long, device=device),\n",
    "         \"mask\": torch.tensor(out.attention_mask, dtype=torch.long, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = m(inputs[\"input_ids\"], inputs[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pytorch_model_summary.summary(m.to(device), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = build_model(configs.model, tokenizer=tech_dataset.tokenizer)\n",
    "if os.path.exists(final_model_path):\n",
    "    best_states = torch.load(final_model_path)\n",
    "else:\n",
    "    raise Exception(\"Model need to be trained first\")\n",
    "converted_states = OrderedDict()\n",
    "for k, v in best_states.items():\n",
    "    if 'module' not in k:\n",
    "        k = 'module.'+k\n",
    "    else:\n",
    "        k = k.replace('features.module.', 'module.features.')\n",
    "    converted_states[k] = v\n",
    "final_model.load_state_dict(converted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy predictor\n",
    "temp_path = os.path.join(model_dir, \"temp\", \"temp.ckpt\")\n",
    "predictor = Predictor(final_model.module.config).to(final_model.module.device)\n",
    "torch.save(final_model.module.predictor.state_dict(), temp_path)\n",
    "predictor.load_state_dict(torch.load(temp_path, map_location=final_model.module.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(root_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_train_data = pd.read_excel(os.path.join(result_path, \"[DATASET]2023-04-11_00:39.xlsx\"), sheet_name=\"TRAIN_dataset\")\n",
    "used_test_data = pd.read_excel(os.path.join(result_path, \"[DATASET]2023-04-11_00:39.xlsx\"), sheet_name=\"TEST_dataset\")\n",
    "used_train_index = tech_dataset.data.index.get_indexer(pd.Index(used_train_data[\"number\"]))\n",
    "used_test_index = tech_dataset.data.index.get_indexer(pd.Index(used_test_data[\"number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tech_dataset.data.iloc[used_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_claims = tech_dataset.X[used_test_index]\n",
    "text_inputs = tech_dataset.tokenizer.encode(input_claims[0])\n",
    "batch_inf = {\"input_ids\": torch.tensor([tech_dataset.tokenizer.encode(input_claims[0]).ids]), \"attention_mask\": torch.tensor(tech_dataset.tokenizer.encode(input_claims[0]).attention_mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_inf = to_device(batch_inf, final_model.module.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_info(tensor):\n",
    "  info = []\n",
    "  for name in ['requires_grad', 'is_leaf', 'retains_grad', 'grad_fn', 'grad']:\n",
    "    info.append(f'{name}({getattr(tensor, name, None)})')\n",
    "  info.append(f'tensor({str(tensor)})')\n",
    "  return ' '.join(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs = final_model.module.encode(input_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs = predictor(enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs[0,1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs_ = enc_outputs + step_size * enc_outputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_outputs = predictor(enc_outputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_outputs = final_model.module.decode(input_inf, enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.module.tokenizer.decode_batch(dec_outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_tensor_info(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor(inputs)[0,-1,-1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_tensor_info(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instant_dataset = Subset(tech_dataset, np.random.choice(np.arange(len(tech_dataset)), 1000))\n",
    "data_loader = DataLoader(instant_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.unique(tech_dataset.Y[whole_idx], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = to_device(batch_data[\"text_inputs\"], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs, *_ = final_model.module.encoder(**text_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = enc_outputs[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_model.module.predictor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon = []\n",
    "\n",
    "if str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"transformers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].convert_tokens_to_ids(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "elif str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"tokenizers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].token_to_id(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "    \n",
    "for i in range(configs.model['n_dec_seq']-1):\n",
    "    dec_outputs, *_ = final_model.module.decoder(preds_recon_batch, text_inputs[\"input_ids\"], enc_outputs)\n",
    "    pred_tokens = dec_outputs.argmax(2)[:,-1].unsqueeze(1)\n",
    "    preds_recon_batch = torch.cat([preds_recon_batch, pred_tokens], axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "preds_recon.append(preds_recon_batch[:,1:].cpu().detach().numpy())\n",
    "preds_recon = np.concatenate(preds_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(\"TRUE(keywords): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_inputs\"][\"input_ids\"].cpu().detach().numpy()))[0])\n",
    "\n",
    "display(\"TRUE(org): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_outputs\"][\"input_ids\"].cpu().detach().numpy()))[0])\n",
    "\n",
    "display(\"PRED: \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs_ = torch.normal(enc_outputs, torch.tile(torch.tensor(2), dims=enc_outputs.size()).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_recon_ = []\n",
    "\n",
    "if str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"transformers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].convert_tokens_to_ids(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "elif str(configs.model[\"tokenizer\"].__class__).split(\"\\'\")[1].split(\".\")[0] == \"tokenizers\":\n",
    "    preds_recon_batch = torch.tile(torch.tensor(configs.model['tokenizer'].token_to_id(\"<SOS>\"), device=device), dims=(text_inputs[\"input_ids\"].shape[0],1)).to(device=device)\n",
    "    \n",
    "for i in range(configs.model['n_dec_seq']-1):\n",
    "    dec_outputs, *_ = final_model.module.decoder(preds_recon_batch, text_inputs[\"input_ids\"], enc_outputs_)\n",
    "    pred_tokens = dec_outputs.argmax(2)[:,-1].unsqueeze(1)\n",
    "    preds_recon_batch = torch.cat([preds_recon_batch, pred_tokens], axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "preds_recon_.append(preds_recon_batch[:,1:].cpu().detach().numpy())\n",
    "preds_recon_ = np.concatenate(preds_recon_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "print(\"TRUE(keywords): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_inputs\"][\"input_ids\"].cpu().detach().numpy()))[i])\n",
    "\n",
    "print(\"TRUE(org): \"+pd.Series(configs.model.tokenizer.decode_batch(batch_data[\"text_outputs\"][\"input_ids\"].cpu().detach().numpy()))[i])\n",
    "\n",
    "print(\"PRED: \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[i])\n",
    "\n",
    "print(\"PRED(modified): \"+pd.Series(configs.model.tokenizer.decode_batch(preds_recon_, skip_special_tokens=False)).apply(lambda x: x.split(\"<EOS>\")[0])[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
