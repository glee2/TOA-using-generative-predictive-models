{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.169609Z",
     "start_time": "2023-02-15T04:51:00.326000Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '/home2/glee/dissertation/1_tech_gen_impact/Transformer/Tech_Gen/'\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "sys.path.append(\"/share/tml_package\")\n",
    "from tml import utils\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import DataParallel as DP\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset, Dataset\n",
    "from accelerate import Accelerator\n",
    "import pytorch_model_summary\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from optuna.integration import SkoptSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data import TechDataset, CVSampler\n",
    "from models import Transformer\n",
    "from train_utils import EarlyStopping, perf_eval, objective_cv, build_model, train_model, validate_model_mp\n",
    "from utils import token2class, DotDict\n",
    "\n",
    "from cleantext.sklearn import CleanTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:41.201542Z",
     "start_time": "2023-02-15T04:52:41.175879Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_type=\"claim\",\n",
    "    data_file = \"collection_[H01L,H10][2017].csv\",\n",
    "    target_ipc=\"H01L\",\n",
    "    pred_type=\"classification\",\n",
    "    n_TC = 5,\n",
    "    use_pretrained_tokenizer=False,\n",
    "    do_train=None,\n",
    "    do_tune=None,\n",
    "    n_folds=None,\n",
    "    max_epochs=2,\n",
    "    use_accelerator=None,\n",
    "    do_save=False,\n",
    "    n_gpus=3,\n",
    "    light=True,\n",
    "    config_file=None,\n",
    "    eval_train_set=False)\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "model_dir = os.path.join(root_dir, \"models\")\n",
    "result_dir = os.path.join(root_dir, \"results\")\n",
    "config_dir = os.path.join(root_dir, \"configs\")\n",
    "\n",
    "if args.config_file is not None:\n",
    "    config_file = args.config_file\n",
    "else:\n",
    "    config_file = os.path.join(config_dir, \"configs_light.json\") if args.light else os.path.join(config_dir, \"configs.json\")\n",
    "configs = DotDict().load(config_file)\n",
    "org_config_keys = {key: list(configs[key].keys()) for key in configs.keys()}\n",
    "\n",
    "instant_configs = {key: value for (key, value) in vars(args).items() if value is not None} # if any argument passed when main.py executed\n",
    "instant_configs_for_update = {configkey: {key: value for (key,value) in instant_configs.items() if key in org_config_keys[configkey]} for configkey in org_config_keys.keys()}\n",
    "for key, value in configs.items():\n",
    "    value.update(instant_configs_for_update[key])\n",
    "\n",
    "regex_ipc = re.compile('[A-Z](?![\\\\D])')\n",
    "if regex_ipc.match(configs.data.target_ipc) is None:\n",
    "    configs.data.update({\"target_ipc\": \"ALL\"})\n",
    "elif len(configs.data.target_ipc) > 5:\n",
    "    configs.data.update({\"target_ipc\": configs.data.target_ipc[:4]})\n",
    "\n",
    "if configs.model.model_type == \"enc-pred-dec\":\n",
    "    configs.train.loss_weights[\"recon\"] = configs.train.loss_weights[\"recon\"] / sum(configs.train.loss_weights.values())\n",
    "    configs.train.loss_weights[\"y\"] = 1 - configs.train.loss_weights[\"recon\"]\n",
    "elif configs.model.model_type == \"enc-pred\":\n",
    "    configs.train.loss_weights = {\"recon\": 0, \"y\": 1}\n",
    "elif configs.model.model_type == \"enc-dec\":\n",
    "    configs.train.loss_weights = {\"recon\": 1, \"y\": 0}\n",
    "\n",
    "if configs.train.use_accelerator:\n",
    "    accelerator = Accelerator()\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    device = accelerator.device\n",
    "\n",
    "    configs.train.update({\"accelerator\": accelerator})\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        gpu_usages = [np.sum([float(usage.split(\"uses\")[-1].replace(\" \",\"\").replace(\"MB\",\"\")) for usage in torch.cuda.list_gpu_processes(id).split(\"GPU memory\") if not usage==\"\" and \"no processes are running\" not in usage]) for id in device_ids]\n",
    "        device_ids = np.argsort(gpu_usages)[:configs.train.n_gpus]\n",
    "        device_ids = list(map(lambda x: torch.device('cuda', x),list(device_ids)))\n",
    "        device = device_ids[0] # main device\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        device_ids = []\n",
    "\n",
    "configs.data.update({\"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"result_dir\": result_dir})\n",
    "configs.train.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"root_dir\": root_dir,\n",
    "                        \"data_dir\": data_dir,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"use_keywords\": configs.data.use_keywords,\n",
    "                        \"early_stop_patience\": int(0.3*configs.train.max_epochs)})\n",
    "configs.model.update({\"device\": device,\n",
    "                        \"device_ids\": device_ids,\n",
    "                        \"n_directions\": 2 if configs.model.bidirec else 1,\n",
    "                        \"use_accelerator\": configs.train.use_accelerator})\n",
    "\n",
    "## Set hyperparameters for model training (To be TUNED)\n",
    "if configs.train.do_train and configs.train.do_tune:\n",
    "    n_layers = configs.model.n_layers = None\n",
    "    d_embedding = configs.model.d_embedding = None\n",
    "    d_hidden = configs.model.d_hidden = None\n",
    "    d_latent = None\n",
    "    learning_rate = configs.train.learning_rate = None\n",
    "    batch_size = configs.train.batch_size = None\n",
    "    config_name = \"HPARAM_TUNING\"\n",
    "    final_model_path = None\n",
    "else:\n",
    "    n_layers = configs.model.n_layers\n",
    "    d_embedding = configs.model.d_embedding\n",
    "    d_hidden = configs.model.d_hidden\n",
    "    d_latent = configs.model.n_enc_seq * configs.model.d_hidden\n",
    "\n",
    "    key_components = {\"data\": [\"target_ipc\", \"pred_type\", \"max_seq_len\", \"vocab_size\"], \"model\": [\"n_layers\", \"d_hidden\", \"d_embedding\", \"d_ff\", \"n_head\", \"d_head\"], \"train\": [\"learning_rate\", \"batch_size\", \"max_epochs\"]}\n",
    "    config_name = \"\"\n",
    "    for key in key_components.keys():\n",
    "        for component in key_components[key]:\n",
    "            config_name += \"[\"+str(configs[key][component])+component+\"]\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model]{config_name}.ckpt\")\n",
    "\n",
    "configs.model.update({\"d_latent\": d_latent})\n",
    "configs.train.update({\"config_name\": config_name,\n",
    "                        \"final_model_path\": final_model_path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Dataset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:55.403544Z",
     "start_time": "2023-02-15T04:52:41.241617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickled dataset...\n",
      "Pickled dataset loaded\n",
      "0.1079 sec elapsed for loading patents for class [H01L]\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "dataset_config_name = \"-\".join([str(key)+\"=\"+str(value) for (key,value) in configs.data.items() if key in org_config_keys[\"data\"]])\n",
    "dataset_path = os.path.join(data_dir, \"pickled_dataset\", \"[tech_dataset]\"+dataset_config_name+\".pickle\")\n",
    "if os.path.exists(dataset_path) and args.do_save is False:\n",
    "    print(\"Load pickled dataset...\")\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        tech_dataset = pickle.load(f)   # Load pickled dataset if dataset with same configuration already saved\n",
    "    print(\"Pickled dataset loaded\")\n",
    "else:\n",
    "    print(\"Make dataset...\")\n",
    "    tech_dataset = TechDataset(configs.data)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        tech_dataset.rawdata = None\n",
    "        pickle.dump(tech_dataset, f)\n",
    "tend = time.time()\n",
    "print(f\"{np.round(tend-tstart,4)} sec elapsed for loading patents for class [{configs.data.target_ipc}]\")\n",
    "\n",
    "configs.model.update({\"tokenizer\": tech_dataset.tokenizer,\n",
    "                        \"n_enc_vocab\": tech_dataset.tokenizer.get_vocab_size(),\n",
    "                        \"n_dec_vocab\": tech_dataset.tokenizer.get_vocab_size(),\n",
    "                        \"n_enc_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_dec_seq\": tech_dataset.max_seq_len,\n",
    "                        \"n_outputs\": 1 if configs.data.pred_type==\"regression\" else tech_dataset.n_outputs,\n",
    "                        \"i_padding\": tech_dataset.tokenizer.token_to_id(\"<PAD>\")})\n",
    "configs.model.update({\"d_latent\": configs.model.n_enc_seq * configs.model.d_hidden})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples\n",
      "Train: 25505, Validation: 6377, Test: 3543\n"
     ]
    }
   ],
   "source": [
    "sampler = CVSampler(tech_dataset, n_folds=configs.train.n_folds, test_ratio=0.1, stratify=True)\n",
    "cv_idx = sampler.get_idx_dict()\n",
    "print(f\"#Samples\\nTrain: {len(cv_idx[0]['train'])}, Validation: {len(cv_idx[0]['val'])}, Test: {len(cv_idx[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-1: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs.train.do_tune:\n",
    "    configs.train.update({\"tuned_model_path\": os.path.join(model_dir,\"hparam_tuning\")})\n",
    "    optuna_obj = lambda trial: objective_cv(trial, dataset=tech_dataset, cv_idx=cv_idx, model_params=configs.model, train_params=configs.train)\n",
    "\n",
    "    opt_sampler = TPESampler()\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(optuna_obj, n_trials=configs.train.n_trials, gc_after_trial=True)\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    print(f\"Best trial:\\n  CrossEntropyLoss: {study.best_trial.value}\\n  Params:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    configs.train.update({k: v for k,v in best_params.items() if k in configs.train.keys()})\n",
    "    configs.model.update({k: v for k,v in best_params.items() if k in configs.model.keys()})\n",
    "    config_name = f\"{configs.model.n_layers}layers_{configs.model.d_embedding}emb_{configs.model.d_hidden}hid_{configs.model.n_directions}direc_{np.round(configs.train.learning_rate, 4)}lr_{configs.train.batch_size}batch_{configs.train.max_epochs}ep\"\n",
    "    final_model_path = os.path.join(model_dir, f\"[Final_model][{configs.data.target_ipc}]{config_name}.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-2: Dataset construction and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Construct datasets\n",
    "train_idx = cv_idx[0]['train']\n",
    "val_idx = cv_idx[0]['val']\n",
    "test_idx = cv_idx[0]['test']\n",
    "whole_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "train_dataset = Subset(tech_dataset, train_idx)\n",
    "val_dataset = Subset(tech_dataset, val_idx)\n",
    "test_dataset = Subset(tech_dataset, test_idx)\n",
    "whole_dataset = Subset(tech_dataset, whole_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=configs.train.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.train.batch_size if len(val_idx)>configs.train.batch_size else len(val_idx), shuffle=True, num_workers=4, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.train.batch_size if len(test_idx)>configs.train.batch_size else len(test_idx), shuffle=False, num_workers=4)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=configs.train.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "## Load best model or build model\n",
    "final_model = build_model(configs.model, tokenizer=tech_dataset.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                   Parent Layers       Layer (type)          Input Shape         Param #     Tr. Param #\n",
      "========================================================================================================================================================\n",
      "                                                             Transformer/Encoder        Embedding-1             [1, 256]          80,000          80,000\n",
      "                                                             Transformer/Encoder        Embedding-2             [1, 256]           8,224               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-3         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-4         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-5         [1, 256, 32]           4,224           4,224\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention          Dropout-6     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention           Linear-7        [1, 256, 128]           4,128           4,128\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Dropout-8         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer        LayerNorm-9         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-10         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-11         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-12         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-13         [1, 256, 32]              64              64\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-14         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-15         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-16         [1, 256, 32]           4,224           4,224\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-17     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-18        [1, 256, 128]           4,128           4,128\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention         Dropout-19         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-20         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-21         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-22         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-23         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-24         [1, 256, 32]              64              64\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-25         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-26         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-27         [1, 256, 32]           4,224           4,224\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-28     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-29        [1, 256, 128]           4,128           4,128\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention         Dropout-30         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-31         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-32         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-33         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-34         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-35         [1, 256, 32]              64              64\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-36         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-37         [1, 256, 32]           4,224           4,224\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-38         [1, 256, 32]           4,224           4,224\n",
      "   Transformer/Encoder/EncoderLayer/MultiHeadAttention/ScaledDotProductAttention         Dropout-39     [1, 4, 256, 256]               0               0\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention          Linear-40        [1, 256, 128]           4,128           4,128\n",
      "                             Transformer/Encoder/EncoderLayer/MultiHeadAttention         Dropout-41         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-42         [1, 256, 32]              64              64\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-43         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet          Conv1d-44         [1, 32, 256]           1,056           1,056\n",
      "                          Transformer/Encoder/EncoderLayer/PoswiseFeedForwardNet         Dropout-45         [1, 256, 32]               0               0\n",
      "                                                Transformer/Encoder/EncoderLayer       LayerNorm-46         [1, 256, 32]              64              64\n",
      "                                                           Transformer/Predictor          Linear-47         [1, 256, 32]              33              33\n",
      "                                                           Transformer/Predictor         Softmax-48          [1, 256, 1]               0               0\n",
      "                                                           Transformer/Predictor          Linear-49                 [32]           1,056           1,056\n",
      "                                                           Transformer/Predictor            ReLU-50                 [32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-51                 [32]           1,056           1,056\n",
      "                                                           Transformer/Predictor            ReLU-52                 [32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-53                 [32]           1,056           1,056\n",
      "                                                           Transformer/Predictor            ReLU-54                 [32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-55                 [32]           1,056           1,056\n",
      "                                                           Transformer/Predictor            ReLU-56                 [32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-57                 [32]           1,056           1,056\n",
      "                                                           Transformer/Predictor            ReLU-58                 [32]               0               0\n",
      "                                                           Transformer/Predictor          Linear-59                 [32]              66              66\n",
      "========================================================================================================================================================\n",
      "Total params: 169,763\n",
      "Trainable params: 161,539\n",
      "Non-trainable params: 8,224\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_input, *_ = tech_dataset.__getitem__(0)\n",
    "    x_input = torch.tensor(x_input, device=device).unsqueeze(0)\n",
    "    print(pytorch_model_summary.summary(final_model.module, torch.zeros(x_input.shape, device=device, dtype=torch.long), torch.zeros(x_input.shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:38,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                maxwell_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us       7.621ms        20.58%       7.621ms     317.542us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.967ms        13.41%       4.967ms      35.227us           0 b           0 b           0 b           0 b           141  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us       4.469ms        12.07%       4.469ms     186.208us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       3.651ms         9.86%       3.651ms     101.417us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.173ms         8.57%       3.173ms     264.417us           0 b           0 b           0 b           0 b            12  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       2.904ms         7.84%       2.904ms     193.600us           0 b           0 b           0 b           0 b            15  \n",
      "                                  sgemm_32x32x32_NT_vec         0.00%       0.000us         0.00%       0.000us       0.000us       2.867ms         7.74%       2.867ms      53.093us           0 b           0 b           0 b           0 b            54  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.823ms         7.62%       2.823ms     235.250us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.669ms         7.21%       2.669ms     222.417us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     519.000us         1.40%     519.000us      14.417us           0 b           0 b           0 b           0 b            36  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 27.066ms\n",
      "Self CUDA time total: 37.030ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                      model_feedforward         1.97%     534.000us        73.38%      19.861ms      19.861ms       0.000us         0.00%     191.000us     191.000us          -4 b        -268 b    -522.60 Mb    -524.29 Mb             1  \n",
      "                                   DataParallel.forward        63.39%      17.158ms        71.36%      19.313ms      19.313ms       0.000us         0.00%     191.000us     191.000us          -4 b        -268 b       1.69 Mb           0 b             1  \n",
      "                                       cudaLaunchKernel        18.63%       5.043ms        19.36%       5.239ms      11.439us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           458  \n",
      "                                  cudaDeviceSynchronize         7.49%       2.026ms         7.49%       2.026ms       2.026ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                              Broadcast         2.68%     726.000us         6.59%       1.784ms       1.784ms       0.000us         0.00%     152.000us     152.000us           0 b           0 b       1.36 Mb    -631.50 Kb             1  \n",
      "                          aten::unflatten_dense_tensors         0.59%     160.000us         2.12%     573.000us     143.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                                Scatter         0.31%      85.000us         1.37%     370.000us     185.000us       0.000us         0.00%      39.000us      19.500us           0 b           0 b     340.00 Kb           0 b             2  \n",
      "                                            aten::copy_         0.85%     231.000us         1.33%     361.000us      45.125us     165.000us         0.45%     165.000us      20.625us           0 b           0 b           0 b           0 b             8  \n",
      "                                           aten::narrow         0.35%      94.000us         1.14%     308.000us       1.855us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           166  \n",
      "                                             aten::view         0.97%     262.000us         0.97%     262.000us       0.819us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           320  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 27.066ms\n",
      "Self CUDA time total: 37.030ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:01, 38.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 40s\n",
      "Avg train loss: 0.692499 (recon loss: 0.000000, y loss: 0.692499)\n",
      "Avg val loss: 0.692230 (recon loss: 0.000000, y loss: 0.692230)\n",
      "\n",
      "Validation loss decreased (inf --> 0.692230).  Saving model ...\n",
      "\n",
      "Epoch 2\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:31,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                maxwell_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us       7.610ms        20.56%       7.610ms     317.083us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.978ms        13.45%       4.978ms      35.305us           0 b           0 b           0 b           0 b           141  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us       4.471ms        12.08%       4.471ms     186.292us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       3.645ms         9.85%       3.645ms     101.250us           0 b           0 b           0 b           0 b            36  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.172ms         8.57%       3.172ms     264.333us           0 b           0 b           0 b           0 b            12  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       2.898ms         7.83%       2.898ms     193.200us           0 b           0 b           0 b           0 b            15  \n",
      "                                  sgemm_32x32x32_NT_vec         0.00%       0.000us         0.00%       0.000us       0.000us       2.862ms         7.73%       2.862ms      53.000us           0 b           0 b           0 b           0 b            54  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.821ms         7.62%       2.821ms     235.083us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.669ms         7.21%       2.669ms     222.417us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     520.000us         1.40%     520.000us      14.444us           0 b           0 b           0 b           0 b            36  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 26.751ms\n",
      "Self CUDA time total: 37.013ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                      model_feedforward         2.04%     546.000us        76.94%      20.581ms      20.581ms       0.000us         0.00%     191.000us     191.000us          -4 b        -268 b    -522.60 Mb    -524.29 Mb             1  \n",
      "                                   DataParallel.forward        66.74%      17.853ms        74.83%      20.019ms      20.019ms       0.000us         0.00%     191.000us     191.000us          -4 b          -4 b       1.69 Mb           0 b             1  \n",
      "                                       cudaLaunchKernel        21.38%       5.719ms        22.10%       5.912ms      12.797us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           462  \n",
      "                                              Broadcast         2.56%     685.000us         6.66%       1.781ms       1.781ms       0.000us         0.00%     152.000us     152.000us           0 b           0 b       1.36 Mb    -631.50 Kb             1  \n",
      "                          aten::unflatten_dense_tensors         0.65%     174.000us         2.22%     593.000us     148.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                                Scatter         0.33%      89.000us         1.44%     384.000us     192.000us       0.000us         0.00%      39.000us      19.500us           0 b           0 b     340.00 Kb           0 b             2  \n",
      "                                            aten::copy_         0.86%     231.000us         1.37%     366.000us      45.750us     165.000us         0.45%     165.000us      20.625us           0 b           0 b           0 b           0 b             8  \n",
      "                                           aten::narrow         0.32%      85.000us         1.13%     302.000us       1.819us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           166  \n",
      "                                             aten::view         1.13%     302.000us         1.13%     302.000us       0.944us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           320  \n",
      "                                               aten::to         0.02%       5.000us         0.99%     264.000us      66.000us       0.000us         0.00%      39.000us       9.750us           0 b           0 b     340.00 Kb           0 b             4  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 26.751ms\n",
      "Self CUDA time total: 37.013ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:01, 39.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 34s\n",
      "Avg train loss: 0.689878 (recon loss: 0.000000, y loss: 0.689878)\n",
      "Avg val loss: 0.685535 (recon loss: 0.000000, y loss: 0.685535)\n",
      "\n",
      "Validation loss decreased (0.692230 --> 0.685535).  Saving model ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "if configs.train.do_tune:\n",
    "    best_states = torch.load(os.path.join(configs.train.tuned_model_path,f\"[HPARAM_TUNING]{study.best_trial.number}trial.ckpt\"))\n",
    "    converted_states = OrderedDict()\n",
    "    for k, v in best_states.items():\n",
    "        if 'module' not in k:\n",
    "            k = 'module.'+k\n",
    "        else:\n",
    "            k = k.replace('features.module.', 'module.features.')\n",
    "        converted_states[k] = v\n",
    "    final_model.load_state_dict(converted_states)\n",
    "else:\n",
    "    final_model = train_model(final_model, train_loader, val_loader, configs.model, configs.train)\n",
    "torch.save(final_model.state_dict(), final_model_path) # Finalize\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_keywords, Y = next(iter(train_loader))\n",
    "src, trg, y = X_keywords.to(device), X.to(device), Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   18,   15,  ...,    1,    1,    1],\n",
       "        [   0,   18,   15,  ...,  282, 2118,    2],\n",
       "        [   0,   18,   15,  ...,  331,   13,    2],\n",
       "        ...,\n",
       "        [   0,   18,   15,  ...,    1,    1,    1],\n",
       "        [   0,   18,   15,  ...,    1,    1,    1],\n",
       "        [   0,   18,   15,  ...,    1,    1,    1]], device='cuda:1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0,\n",
       "        0, 0, 2, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 0,\n",
       "        2, 0, 0, 1, 2, 0, 0, 1], device='cuda:1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_dataset.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = final_model(src, trg[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_recon = [output[0] for output in outputs] # outputs_recon: n_gpus *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3-3: Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.eval_train_set:\n",
    "    ## Evaluation on train dataset\n",
    "    print(\"Validate model on train dataset\")\n",
    "    # trues_recon_train, preds_recon_train, trues_y_train, preds_y_train = validate_model(final_model, whole_loader, configs.model, configs.train)\n",
    "    val_res_train = validate_model_mp(final_model, whole_dataset, mp=mp, model_params=configs.model, train_params=configs.train)\n",
    "    trues_recon_train = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_recon_train = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_train.values()])\n",
    "    trues_y_train = np.concatenate([res[\"y\"][\"true\"] for res in val_res_train.values()])\n",
    "    preds_y_train = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_train.values()])\n",
    "\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_recon_train = perf_eval(\"TRAIN_SET\", trues_recon_train, preds_recon_train, configs=configs, pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "    eval_y_train = perf_eval(\"TRAIN_SET\", trues_y_train, preds_y_train, configs=configs, pred_type=configs.data.pred_type)\n",
    "    if configs.data.pred_type == \"classification\":\n",
    "        eval_y_train, confmat_y_train = eval_y_train\n",
    "else:\n",
    "    eval_recon_train = eval_y_train = None\n",
    "\n",
    "## Evaluation on test dataset\n",
    "print(\"Validate model on test dataset\")\n",
    "# trues_recon_test, preds_recon_test, trues_y_test, preds_y_test = validate_model(final_model, test_loader, configs.model, configs.train)\n",
    "val_res_test = validate_model_mp(final_model, test_dataset, mp=mp, batch_size=64, model_params=configs.model, train_params=configs.train)\n",
    "trues_recon_test = np.concatenate([res[\"recon\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_recon_test = np.concatenate([res[\"recon\"][\"pred\"] for res in val_res_test.values()])\n",
    "trues_y_test = np.concatenate([res[\"y\"][\"true\"] for res in val_res_test.values()])\n",
    "preds_y_test = np.concatenate([res[\"y\"][\"pred\"] for res in val_res_test.values()])\n",
    "\n",
    "eval_recon_test = perf_eval(\"TEST_SET\", trues_recon_test, preds_recon_test, configs=configs,  pred_type='generative', tokenizer=final_model.module.tokenizer)\n",
    "eval_y_test = perf_eval(\"TEST_SET\", trues_y_test, preds_y_test, configs=configs, pred_type=configs.data.pred_type)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    eval_y_test, confmat_y_test = eval_y_test\n",
    "\n",
    "eval_recon_res = pd.concat([eval_recon_train, eval_recon_test], axis=0)\n",
    "eval_y_res = pd.concat([eval_y_train, eval_y_test], axis=0)\n",
    "if configs.data.pred_type == \"classification\":\n",
    "    confmat_y_res = pd.concat([confmat_y_train, confmat_y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (temp) Pre-trained model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        x = self.l1(input_ids=input_ids, attention_mask=mask)\n",
    "        hidden_state = x[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        \n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "m = BERTClass().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer(tech_dataset.data['claims'][:100].tolist(), add_special_tokens=True, max_length=256, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input_ids\": torch.tensor(out.input_ids, dtype=torch.long, device=device),\n",
    "         \"mask\": torch.tensor(out.attention_mask, dtype=torch.long, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = m(inputs[\"input_ids\"], inputs[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 256, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                   Parent Layers       Layer (type)             Input Shape         Param #     Tr. Param #\n",
      "===========================================================================================================================================================\n",
      "                                            BERTClass/DistilBertModel/Embeddings        Embedding-1              [100, 256]      23,440,896      23,440,896\n",
      "                                            BERTClass/DistilBertModel/Embeddings        Embedding-2                [1, 256]         393,216         393,216\n",
      "                                            BERTClass/DistilBertModel/Embeddings        LayerNorm-3         [100, 256, 768]           1,536           1,536\n",
      "                                            BERTClass/DistilBertModel/Embeddings          Dropout-4         [100, 256, 768]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention           Linear-5         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention           Linear-6         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention           Linear-7         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Dropout-8     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention           Linear-9         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-10         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-11         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-12        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-13         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-14         [100, 256, 768]           1,536           1,536\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-15         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-16         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-17         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention         Dropout-18     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-19         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-20         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-21         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-22        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-23         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-24         [100, 256, 768]           1,536           1,536\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-25         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-26         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-27         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention         Dropout-28     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-29         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-30         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-31         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-32        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-33         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-34         [100, 256, 768]           1,536           1,536\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-35         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-36         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-37         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention         Dropout-38     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-39         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-40         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-41         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-42        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-43         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-44         [100, 256, 768]           1,536           1,536\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-45         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-46         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-47         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention         Dropout-48     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-49         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-50         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-51         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-52        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-53         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-54         [100, 256, 768]           1,536           1,536\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-55         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-56         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-57         [100, 256, 768]         590,592         590,592\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention         Dropout-58     [100, 12, 256, 256]               0               0\n",
      "   BERTClass/DistilBertModel/Transformer/TransformerBlock/MultiHeadSelfAttention          Linear-59         [100, 256, 768]         590,592         590,592\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-60         [100, 256, 768]           1,536           1,536\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-61         [100, 256, 768]       2,362,368       2,362,368\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN          Linear-62        [100, 256, 3072]       2,360,064       2,360,064\n",
      "                      BERTClass/DistilBertModel/Transformer/TransformerBlock/FFN         Dropout-63         [100, 256, 768]               0               0\n",
      "                          BERTClass/DistilBertModel/Transformer/TransformerBlock       LayerNorm-64         [100, 256, 768]           1,536           1,536\n",
      "                                                                       BERTClass          Linear-65              [100, 768]         590,592         590,592\n",
      "                                                                       BERTClass         Dropout-66              [100, 768]               0               0\n",
      "                                                                       BERTClass          Linear-67              [100, 768]           1,538           1,538\n",
      "===========================================================================================================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_model_summary.summary(m.to(device), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), torch.zeros(inputs[\"input_ids\"].shape, device=device, dtype=torch.long), show_input=True, max_depth=None, show_parent_layers=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
